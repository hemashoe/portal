post_id'post_id'title'description'source_link'body'image'images
0'723462'[Перевод] Можно ли доверять ответам на математические вопросы ChatGPT и другим языковым моделям?'Эта статья из серии постов на тему демистификации ИИ , в которых предпринимаются пытытки устранить двусмысленность жаргона и разоблачить мифы связанные с технологиями ИИ. ChatGPT и другие большие...'https://habr.com/ru/post/723462/'"ChatGPT на поле брани с продвинутой математикой

А как он справляется с элементарной математикой?

В поиске математических знаний

Точно настроенные ЯМ

В перспективе предстоит еще много работы

Эта статья из серии постов на тему демистификации ИИ , в которых предпринимаются пытытки устранить двусмысленность жаргона и разоблачить мифы связанные с технологиями ИИ. ChatGPT и другие большие языковые модели (LLM, в дальнейшем БЯМ, короче ЯМ —) доказали свою полезность для задач отличных от генерации текста. Однако в некоторых областях их эффективность вызывает вопросы. Одной из таких областей является математика, где ЯМ иногда могут предоставить правильные решения для достаточно сложных задачах, в то же время потерпеть неудачу в тривиальных.Существует немало исследований в которых изучаются возможности и ограничения ЯМ в математике. Недавняя работа проведенная исследователями из нескольких университетов показала, что возможности ChatGPT ниже уровня среднего аспирантов по математике. И отдельное исследование, проведенное профессором Нью-Йоркского университета Эрнестом Дэвисом показало, что ЯМ терпят неудачу при решении весьма простых математических задач заданных на естественном языке.Эти исследования помогают лучше понять разрыв в решении проблем людьми и глубокими нейронными сетями. Люди и ЯМ могут достигать одного и того же результата в определенных математических задачах, но их методы различаются. И это может оказаться критичным, когда речь заходит о доверии к ЯМ (и другим моделям глубокого обучения) при решении задач требующих планирования и рассуждений.Математика используется во многих областях науки, включая инженерных и социальных. Специалисты не математики, работающие в этих областях, могут обратиться к ChatGPT , чтобы получить ответы на математические вопросы.“Поскольку ChatGPT всегда формулирует свои ответы с высокой степенью уверенности, у этой группы людей могут возникнуть трудности с различением правильных ответов от неправильных математических рассуждений, что может привести к принятию неверных решений в дальнейшем”, — заявил в интервью TechTalks Саймон Фридер, исследователь машинного обучения из Оксфорда. “Поэтому важно информировать эти группы об ограничениях ChatGPT, чтобы не возникало чрезмерного доверия к результатам его использования”.Фридер является соавтором свежей статьи в которой исследуется способность ChatGPT имитировать навыки необходимые для занятия профессиональной математикой. Авторы собрали выборку данных GHOSTS состоящей из задач из различных областей, включая ответы на вычислительные задания, завершения математических доказательств, решения задач математических олимпиад, и поиска в математической литературе.Задачи были взяты из нескольких источников, включая учебники для выпускников, других математические выборок данных и корпусов знаний.Их результаты показывают, что ChatGPT выполнил многие задания на проходной балл. Например, что касается вопросов для аспирантов, исследователи отметили, что чат “никогда не показывал не понимания вопроса” (хотя можно поспорить о применимости термина “понимание” к ЯМ ), но выдавал ошибочные ответы. Фридер считает, что ChatGPT особенно заметно терпит неудачи в задачах, которые “требуют изобретательных доказательств”, таких как на олимпиадах.Чат также продемонстрировал очень плохие вычислительные способности. “Даже вычисление простых интегралов (первообразных) может быть затруднено, поскольку ChatGPT часто правильно находя функцию для первообразной упускал константу интегрирования”, — сказал Фридер.Одним из интересных выводов сделанных в статье является несоответствие между различными уровнями решения проблем. Например, в задачах с дырами в доказательствах (нашел статью на эту тему —) исследователи обнаружили, что ChatGPT часто “с легкостью выполняет сложные символьные задач”», но во многих случаях не справляется с базовой арифметикой или перестановкой выражений.“Нет области математики, в которой вы могли бы полностью доверять выводам ChatGPT (это справедливо и за пределами математики, из-за стохастической природы языковых моделей)”, — сказал Фридер. “Это общее ограничение языковых моделей заключающееся в том, что не существует строгих подходов гарантирующих корректность вывода, от чего также страдает ChatGPT”.Одной из проблем этого чата является его уверенность в ответах, даже когда он терпит неудачу и использует ошибочную логику. Это очень затрудняет его использование в качестве надежного источника математических знаний.“Кажется справедливым сказать, что ChatGPT непоследовательно плох в продвинутой математике: в то время как его рейтинги падают с математической сложностью вопроса, в нескольких случаях он действительно дает проницательные доказательства”, — пишут исследователи.В другой недавней статье Эрнест Дэвис исследует возможности и ограничения ЯМ в решении таких задач, как эта: “У Джорджа есть семь пенни, десятицентовик и три четвертака. У Харриет есть четыре пенни и четыре четвертака. Сначала Джордж дает Гарриет тридцать один цент мелочью; затем Гарриет возвращает ему ровно половину своих пенни. Сколько денег сейчас у Джорджа?”Это простые задачи с тремя свойствами: они требуют элементарных математических навыков, сформулированы на естественном языке и предполагают понимание здравого смысла Дэвис тестировал три различных подхода. В первом ЯМ просили напрямую выдать ответ. Второй подход заключался в том, чтобы модель генерировала программу, которая решает задачу. И третий — выводила формализованное представление, которое можно было ввести в систему автоматической проверки теорем. ЯМ плохо работали во всех трех подходах, хотя результаты были несколько лучше, когда их просили сгенерировать программу, которая может решить задачу.Итак, если ЯМ не могут выполнять задания из элементарной математики, почему они демонстрируют замечательные результаты в тестах, разработанных для оценки математических навыков ИИ?ЯМ добились заметного прогресса в лингвистике , в меньшей степени в здравом смысле и математике. Но, как указывает Дэвис в своей статье, ЯМ плохо умеют сочетать несколько навыков. Например, они в целом “гораздо хуже справляются с задачами, включающими две арифметические операции, чем с теми, которые требуют одной, как в задачах со словами, так и в чисто числовых”.Одно из важных замечаний Дэвиса заключается в том, что математические критерии разработанные для оценки систем ИИ взяты из тестов созданных для людей. Это может приводить к вводящим в заблуждение выводам. У людей базовые навыки становятся фундаментом на котором мы развиваем более продвинутые. Так, например, если человек может решать дифференциальные уравнения можно ожидать, что он будет не плохо ориентироваться в линейной алгебре.Но модели машинного обучения, такие как ЯМ, иногда могут находить ответы на сложные проблемы не приобретая тех же навыков, что и люди. Это может быть связано с тем, что ответы находятся непосредственно в обучающих данных (особенно когда модель обучается на очень большом корпусе данных). Или, что модели обнаруживают закономерности, которые могут приводить к правильным ответам во многих случаях, но не всегда.“[ЯМ] не могут надежно охватить ни одну область математики или какой-либо ее продвинутый раздел”, — сказал Дэвис TechTalks. В то же время “Вероятно, нет такой области математики, в которой вы никогда не получите правильного ответа, потому что иногда они могут выдать ответы, которые были в обучающей выборке”.Интересно, что Дэвис находит некоторые из тех же видов несоответствий, которые были отмечены и в предыдущей работе. Например, в то время как ChatGPT часто решает базовые и промежуточные математические задачи, иногда он терпит неудачу в очень простых задачах, таких как простой подсчет (возможно это связано с вероятностным выбором механизма сэмплирования модели, см. объяснение в этом переводе с примерами кода; поэтому при повторном запуске задачи в новой сессии возможно получение правильного ответа —).“Мое собственное ощущение таково, что если ЯМ не может решать простые арифметические задачи, то на самом деле нет особого смысла спрашивать насколько хорошо она справляется с задачами по теории мер, топологии или абстрактной линейной алгебре”, — сказал Дэвис.В тестах, которые провели Фридер и его коллеги, в которых ChatGPT показал особенно хорошие результаты были поиск текста по определению и обратный поиск определений по тексту запроса. По сути, он может служить очень хорошей поисковой системой для получения математических знаний, предоставляя описание тем и сопоставляя описание с основной концепцией.“[ChatGPT] особенно хорошо работает в качестве математической базы знаний: его можно использовать для эмуляции математической поисковой системы и для получения различных фактов о более сложных объектах”, — сказал Фридер. “Например, я сам узнал о представлении, которое называется ‘расплывчатой топологией’, входящем в более общее представление о слабой топологии. Сначала выбор слова показался странным, и я подумал, что это галлюцинация чата, пока не поискал в Интернете и не узнал из Википедии, что ” расплывчатая топология "" — правильное название для конкретного математического объекта.""Дэвис соглашается с тем, что ChatGPT и другие ЯМ могут быть хороши в подборе текста, что также наблюдается в других областях, таких как стандартизированные научные тесты . Но он также отметил, что еще предстоит выяснить насколько они сравнимы на практике с подобными возможностями Wikipedia и Mathworld, особенно поиске определений и обратном поиске определений.Для обратного поиска определений необходимо проверить насколько устойчива их система к переформулировкам определений из стандартного учебника, как сохраняющим смысл, где они должны быть успешными, так и изменяющим смысл, где они, предположительно, не должна быть успешными, и в идеале должны выдавать какое-то предупреждение”, — сказал Дэвис.В своей статье Фридер и его коллеги обнаружили, что модели глубокого обучения , разработанные для решения математических задач или ЯМ настроенные на больших математических выборках данных, гораздо более точны, чем ChatGPT.Одна из выдающихся работ — это модель глубокого обучения, разработанная исследователями ИИ Facebook Гийомом Ламплом и Франсуа Шартоном в 2019 году. Они создали систему для генерации обучающих наборов данных для контролируемого обучения интегрированию и дифференциальным уравнениям первого и второго порядка. Затем они обучили трансформаторную модель на этой выборке данных. Результаты их тестирования показали, что эта модель работает лучше, чем программы алгебры на основе правил, такие как MATLAB и Mathematica.Вторая модель — Minerva , большая языковая модель от Google, предварительно обученная на общих данных естественного языка и доработанная на данных устных математических задач, конкурсных математических заданиях, а также задачах из разных областей науки и техники. Как и ожидалось обе модели превзошли ChatGPT в решении математических задач.«Тонкая настройка на большем математическом наборе данных, вероятно, увеличила производительность», — сказал Фридер.Дэвис также согласился с тем, что точно настроенные трансформаторы, подобные разработанному Лэмплом и Чартоном, могут “иногда находить решения проблем, которые отсутствуют в стандартных системах, таких как Mathematica”. Но он отметил, что “те проблемы, которые смогли решить эти системы, почти никогда не представляли действительного математического интереса”. “Это может измениться”, — добавил он.Дэвис также отметил, что было несколько реальных случаев, когда системы ИИ были полезны математикам, включая систему глубокого обучения, которая обнаружила быстрые алгоритмы умножения матриц , и несколько систем, которые смогли помочь в теории графов. “Но такого рода помощь в значительной степени случайна”, — добавил он.В этой области еще много возможностей для открытий. При более точной настройке эти системы однажды могут стать надежными помощниками для людей не имеющих высшего образования в области математики. Но пока стоимость оценки результативности математических выводов ЯМ непомерно высока.Фридер и его коллеги открыли исходный код своего набора данных и фреймворка, который включает подробную систему оценки выходных данных модели и достоверности, коды ошибок и предупреждений, а также комментарии рецензентов. Процесс сбора и анализа данных потребовал ручной работы экспертов и не мог быть передан на аутсорсинг через такие платформы, как Amazon Mechanical Turk. Сделав его общедоступным они хотят “побудить сообщество вносить свой вклад и расширять эти наборы данных, чтобы их можно было использовать в качестве полезного ориентира для других ЯМ”, как пишут сами исследователи.Фридер и его соавторы также работают над новой статьей, в которой будут представлены результаты исследования возможности автоматического выполнения математики исключительно с помощью ЯМ. “Это даст эмпирический ответ на старый вопрос о том, нужно ли формализовать математику или нет, чтобы выполнять автоматические доказательства теорем”, — сказал он."'https://habr.com/share/publication/723462/d7badd6398c7d0f669bc84de994c0650/'"['https://habrastorage.org/r/w780q1/webt/uj/c6/g4/ujc6g4y1-p7yw3cq-v9p_rys7ea.jpeg', 'https://habrastorage.org/r/w780q1/webt/vv/lw/e6/vvlwe6rvtohl5oeguicsnsqhq00.jpeg', 'https://habr.com/share/publication/723462/d7badd6398c7d0f669bc84de994c0650/', 'https://mc.yandex.ru/watch/24049213']"
1'723458'Мобильная разработка за неделю #480 (13 — 19 марта)'В нашей новой подборке ошибки начинающих разработчиков и отсутствие работы у тех, кто работает, вкатывание в геймдев и выкатывание GPT-4, мобильные игры 2022 и многое другое. В нашем Telegram-канале...'https://habr.com/ru/post/723458/'В нашей новой подборке ошибки начинающих разработчиков и отсутствие работы у тех, кто работает, вкатывание в геймдев и выкатывание GPT-4, мобильные игры 2022 и многое другое. Предыдущий дайджест . Если у вас есть другие интересные материалы или вы нашли ошибку — пришлите, пожалуйста, в почту'https://habr.com/share/publication/723458/24efdf58a672cd327011a2388c3ff971/'"['https://habrastorage.org/r/w780q1/webt/xi/y5/h8/xiy5h8un5cbkfzk4nmceh6mnsoq.jpeg', 'https://habrastorage.org/r/w1560/files/967/16b/cb9/96716bcb926741e79bb1c284a88083ca.png', 'https://habrastorage.org/r/w1560/getpro/habr/post_images/708/1c6/34e/7081c634ec176ab6b953d9d19e82a09a.png', 'https://habrastorage.org/r/w48/getpro/habr/avatars/e7d/d1f/7ae/e7dd1f7ae26609981edce6deabc5d751.png', 'https://habrastorage.org/r/w780q1/getpro/habr/post_images/509/dc9/bde/509dc9bde69347ecbe0c21ff2973d7e7.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/post_images/853/812/9f5/8538129f5e7b404a720121cb9c3814db.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/post_images/e1a/3cf/2a8/e1a3cf2a8b65a0da69bbdd5c0ad040fe.png', 'https://habrastorage.org/files/377/ae0/333/377ae0333d0f4b7b97307c9eea5ee21a.gif', 'https://habrastorage.org/r/w1560/getpro/habr/post_images/f19/30a/c49/f1930ac4945596eb9707bc7a01bc5bdc.png', 'https://habrastorage.org/r/w1560/webt/ma/lx/8h/malx8hbgozt6lee8rmxmg96_s6a.png', 'https://habrastorage.org/getpro/habr/avatars/e7d/d1f/7ae/e7dd1f7ae26609981edce6deabc5d751.png', 'https://mc.yandex.ru/watch/24049213', 'https://habr.com/share/publication/723458/24efdf58a672cd327011a2388c3ff971/', 'https://habrastorage.org/getpro/habr/company/8e4/c4c/e8e/8e4c4ce8e0cccdabc4292f42980f7847.png']"
2'723456'Nintendo 2DS, мини-ПК HP EliteDesk 800 G4 и немецкая Библия 1848 года: что удалось откопать на испанской барахолке'Привет, Хабр! Погода в Валенсии установилась хорошая и надолго, поэтому я в это воскресенье снова отправился на свою любимую барахолку, о которой писал не раз и не два . Несмотря на то, что бываю там...'https://habr.com/ru/post/723456/'"Что я купил

Что это за штука?

Привет, Хабр! Погода в Валенсии установилась хорошая и надолго, поэтому я в это воскресенье снова отправился на свою любимую барахолку, о которой писал не раз не два . Несмотря на то, что бываю там часто, практически каждый раз попадаются очень интересные вещи, о которых иногда и не подумал бы, что они могут встретиться на блошином рынке. Этот раз — не исключение, так что вам должно понравиться. Все подробности — под катом. В самом конце — традиционный раздел «Что это за штука», где вместе пытаемся угадать предназначение некоторых устройств и приспособлений. Поехали!Начнем, пожалуй, с винила — пластинок на барахолке очень много. Вот пример того, что можно встретить под открытым небом — наверное, тут несколько килограммов пластинок.А вот еще немного — уже в более цивилизованной продаже, продавец хотя бы немного привел все это в порядок.Ну и несколько устройств, на которых пластинки можно воспроизводить — от очень старого до более-менее современных, хотя сегодня это уже тоже винтаж. Но еще не антиквариат.Ну и раз начали с музыки, то вот еще немного инструментов. Насколько хорош этот синтезатор, может, есть знатоки на Хабре?И вот еще один, попроще, как мне кажется.Потом попались на глаза старые мобильные телефоны — в свое время за такие можно было отдать правую руку. У моей знакомой был сотовый на второй картинке — как же он крут был много лет назад!Сегодня было много ноутбуков, вот, например, набор товаров у одного из продавцов. Неплохой выбор, хотя, конечно, и не для всех покупателей.И еще немного, тоже более-менее современные. Ну то есть не совсем древние девайсы, новыми их, конечно, назвать тоже не получится.Сегодня один из продавцов, он испанец, привез на рынок продавать роботы-пылесосы, все рабочие и многие вроде как новые. Народу вокруг толпилось много, поэтому не удалось спросить, где он их взял (большинство на такие вопросы реагирует нормально, поскольку не один я подобное спрашиваю).Вооот такая коллекция членистоногих, залитая в эпоксидку. Как в очень старой истории (она была про раков на рынке). Маленькие — по 3 евро, большие — по 5. Вся эта коллекция привлекла внимание многих посетителей барахолки. Мое тоже, поскольку раньше увлекался энтомологией, ну а насекомых в этой коллекции много. Правда, жаль всю эту братию, которая могла бы еще ходить, бегать, есть, а теперь вот приманивает внимание посетителей с барахолки, залитая эпоксидкой.Что еще интересного? Вот, сезон «Друзей», вполне себе вариант для подарка (если, конечно, у того, кому дарят, есть плеер).Немножечко… эээ… взрослых игр, скажем так. Есть инструменты и источник знаний (правда, они немного разных направлений, но все равно интересно).Еще попался на глаза вот такой микроскоп (продавали всего за 5 евро).И телескоп, который при мне относительно быстро осмотрел парень и он же его и купил за сумму что-то около 40 евро. Хороший ли это телескоп?Немножко винтажных камер, которые отдавали по 5 евро за штуку.Еще встретился вот такой GPS-приемник, с дефектом на ЖК-дисплее, но продавец уверял, что он рабочий. Продавали за 10 евро.Еще встретилась вот такая камера и куча бобин с пленками (это же они на втором снимке, верно?).Коллекционные (вроде бы) машинки. Кто знает, представляют ли они какую-то ценность? Коллекционную или денежную.Ну и еще немножечко контроллеров для PS3, а также Bluetooth-клавиатура. Такие зачастую используются для smart-TV.А еще встретилась мечта карпятника — набор удилищ с подставкой и кучей лесок, которые никто еще не открывал.Последнее, наверное, что опишу в этом разделе — аппарат для работы с экранами для мобильных телефонов. Подобные устройства есть у многих сервисных центров.А, чуть не забыл — у одного из продавцов был вот такой артефакт. Это, как он мне сказал, чернильная ручка, где все из золота. Открыл — действительно, ручка. Но насколько оно там все золотое — под вопросом, конечно. Выглядит очень кричаще, прям «лухари».Традиционно рассказываю о своих покупках, которые, чтобы не повторяться, не раскрываю в первом разделе. Так вот, почти сразу после входа на барахолку внимание привлекла вот эта книга. Она так и лежала на асфальте, это не я ее туда положил, а продавец.Сам я не религиозен, но увидел, что год публикации книги — 1848 год и решил купить. Это ж почти 200 лет уже этому изданию! Язык — немецкий, картинок нет, так что попробую продать (ну или подарю каким-нибудь знакомым, кто знает этот язык). В интернете посмотрел, стоимость этого издания — от 60 до 200 евро, видимо, в зависимости от того, насколько продавцам деньги нужны.Еще приобрел Nintendo 2DS — лежала, никем не замеченная, на краю «торговой точки» одного из продавцов. Купил всего за 5 евро — оказалось, что экраны целые, есть все кнопки, состояние, в целом, неплохое. Внутри — игра про покемонов и карта памяти на 4 ГБ. Все это уже отбивает стоимость покупки, но — я же увлекаюсь ремонтом техники.Как оказалось, проблема с этой консолью в том, что у нее отвалился порт зарядки. Мне даже новый искать не пришлось — он оказался внутри гаджета. Я быстренько его припаял, дополнительно укрепил. Проверка — и девайс после зарядки в течение минут 15 включился. Оказалось, все в рабочем состоянии, хоть сейчас играй. Картинка не моя, выкладываю просто чтобы напомнить, что такое эта самая 2DS из себя представляет.Потом неожиданно для себя увидел целую и нетронутую катушку пластика для 3D-принтера. Это какой-то особенный пластик, который изготавливается в Испании, и, по словам компании, его производящей, отличается от прочих видов пластика для печати. Как попробую — отпишусь, что получилось. Да, продавец на вопрос о цене сказал: «Сколько дашь». Ну я дал три евро, чему он очень обрадовался.Потом приобрел еще и мини-ПК. Обычно мы о них пишем на Хабре, а тут удалось увидеть один такой. Правда, не целый, а половиночку. Не знаю, что с ним случилось, такое впечатление, что кто-то в гневе разорвал две части устройства и выкинул. Одна часть продавалсь на барахолке, по цене в 5 евро. Где вторая — сложно сказать.Иногда ну очень хочется знать историю таких устройств — ведь поломать его, это нужно очень постараться. Из повреждений — оторван коннектор для кулера процессора и погнуты контакты на месте посадки процессора. И то, и другое поправимо. Плата — рабочая, во всяком случае, при подключении питания загораются светодиоды и спикер выдает сигнал об отсутствии чипа и/или ОЗУ.Жаль, у меня нет подходящего процессора, чтобы оценить, рабочая плата или нет, так бы можно было бы сделать рабочую станцию в открытом виде, благо, коннектор для HDD на месте. Кстати, когда снял крепление для жесткого диска, получил сюрприз — SSD на 256 GB. Рабочий, зашифрован битлокером. Отформатировал — и все работает.Ну и еще купил PSP без батареи и с разбитым экраном (у меня есть в запасниках и то, и другое, а также Sony Vaio PCG-71911M. У него разбит экран и клавиатура — такое впечатление, что пару раз бахнули молотком. Зато есть RAM на 4 GB и HDD на 320 GB. Не включается, может, отремонтирую, а может, на запчасти пущу, там материнка более-менее современная, SMD-компоненты могут пригодиться.Вот такое устройство, с надписями на немецком языке.Вообще ничего не понятно. Возможно, это просто часть чего-то. Но креплений или отсутствующих деталей я не заметил.Вот такая труба. Может, часть чего-то, а может, и самостоятельное приспособление.Да, вижу, что это монеты. Но выглядит так, словно кто-то нашел клад… и решил выставить находку на барахолке. Вот монеты поближе, возможно, кто-то разгадает, что это, и расскажет, представляют ли монетки ценность. Почти все носят следы окисления — вероятно, находились во влажной среде.Тут у меня одни вопросы.Удочка, да, но она просто огромная, это раз. И два — у нее есть вот такая ручка, как на фото. Это зачем?Ну а на сегодня все — не переключайтесь."'https://habr.com/share/publication/723456/cb0a6172e63b2b3b9d0747859b08076f/'"['https://habrastorage.org/r/w780q1/webt/9e/gt/xx/9egtxxmswwpsuayvm6gtewcsntw.jpeg', 'https://habrastorage.org/r/w780q1/webt/yk/ih/rc/ykihrc976vbfgfuprapqfghxgu8.jpeg', 'https://habrastorage.org/r/w780q1/webt/jz/hd/jn/jzhdjng8ys10g6nqqldx3cq3pp8.jpeg', 'https://habrastorage.org/r/w780q1/webt/z0/vr/rr/z0vrrr-bztuckdlhy_1xdioryqs.jpeg', 'https://habrastorage.org/r/w780q1/getpro/habr/post_images/e4f/58a/46c/e4f58a46c835a751cfab721ae6b719c1.jpg', 'https://habrastorage.org/r/w780q1/webt/ww/p4/e1/wwp4e1l1wapotyqx3ufu9cnskng.jpeg', 'https://habrastorage.org/r/w780q1/webt/uk/xl/-l/ukxl-lozdxr8xrizpxitrr4wojm.jpeg', 'https://habrastorage.org/r/w780q1/webt/ht/ka/gi/htkagie3bqfu9naaes1vbb0wgxy.jpeg', 'https://habrastorage.org/r/w780q1/webt/dw/1x/tp/dw1xtpgja5n5cuowybrwfxlfkru.jpeg', 'https://habrastorage.org/r/w780q1/webt/up/3p/gs/up3pgs3z4mshyzkkjwatllr4lis.jpeg', 'https://habrastorage.org/r/w780q1/webt/xa/12/p3/xa12p3hpmim-o0ozh38qfrh1rxa.jpeg', 'https://habrastorage.org/r/w780q1/webt/ke/ii/ls/keiils3ezo7tcr0aylcqmgo_8ui.jpeg', 'https://habrastorage.org/r/w780q1/webt/uq/w8/1m/uqw81mwi9vqghff_wit17tirhtg.jpeg', 'https://habrastorage.org/getpro/habr/company/66a/f7d/039/66af7d03979b6d18654293d8f1e72837.png', 'https://habrastorage.org/r/w780q1/webt/jh/6n/bl/jh6nblag7hwlu6c0-zamslkyz-o.jpeg', 'https://habrastorage.org/r/w780q1/webt/cx/v6/rl/cxv6rlcsmx6eyt_8qs_vxe-kp9g.jpeg', 'https://habrastorage.org/r/w780q1/webt/az/tx/_m/aztx_mlhoztka4riez1e1zgjkos.jpeg', 'https://habrastorage.org/r/w780q1/webt/kw/by/yb/kwbyybnnxnxmzkz-zkspvdnogzk.jpeg', 'https://habrastorage.org/r/w780q1/webt/yl/us/nf/ylusnff50yo53l6zbravme9liii.jpeg', 'https://habrastorage.org/r/w780q1/webt/zc/pp/nv/zcppnvumzyol30-ylhnjx8-wcwg.jpeg', 'https://habrastorage.org/r/w780q1/webt/cn/lm/td/cnlmtdpa3llg3rj7yyxdy5i3kly.jpeg', 'https://habrastorage.org/getpro/habr/avatars/126/32f/feb/12632ffebec0f851ba0ec665f3ed6c55.jpg', 'https://habrastorage.org/r/w780q1/webt/wo/o2/ik/woo2ikx8l18xmliu5emsvm8nuvm.jpeg', 'https://habrastorage.org/r/w780q1/webt/yo/wb/aa/yowbaaayx3x7qetp7jp1grlgzwc.jpeg', 'https://habrastorage.org/r/w780q1/webt/cb/gv/70/cbgv70oidvwwni7cfjcd6h60j9u.jpeg', 'https://habrastorage.org/r/w780q1/webt/6p/qw/u0/6pqwu0subzori_ms6knjr_9ul8w.jpeg', 'https://habrastorage.org/r/w1560/webt/st/sv/yn/stsvynwdldmibwd6lmucydsmryu.png', 'https://habrastorage.org/r/w780q1/webt/pv/gn/qz/pvgnqz-sgfeyh2y4mi1ewlfwcoe.jpeg', 'https://habrastorage.org/r/w780q1/webt/x7/f2/v7/x7f2v7_h-qx4cqf71p8xjzis4x8.jpeg', 'https://habrastorage.org/r/w780q1/webt/ol/ot/dz/olotdz_a2sta36l__91zryi5ndy.jpeg', 'https://habrastorage.org/r/w780q1/webt/th/41/ms/th41ms-5kqxn2dywnjhc10thali.jpeg', 'https://habrastorage.org/r/w780q1/webt/ay/07/if/ay07if8j3lxixcemzusdc9ghsj8.jpeg', 'https://habrastorage.org/r/w780q1/webt/j5/xd/ml/j5xdmlx-njlntnyxpjxp6p8wei0.jpeg', 'https://habrastorage.org/r/w780q1/webt/vp/ya/e-/vpyae-r_tbq5x5wrsqbcffc7srg.jpeg', 'https://habrastorage.org/r/w780q1/webt/9g/1k/mb/9g1kmb4ccxraz1pk1e3fghegvkc.jpeg', 'https://habrastorage.org/r/w780q1/webt/sr/tk/18/srtk18gcqgihzummnpl4q2e0gpa.jpeg', 'https://habrastorage.org/r/w780q1/webt/_0/va/1m/_0va1mnrcetmkvlzxxxvy9zcnva.jpeg', 'https://habrastorage.org/r/w48/getpro/habr/avatars/126/32f/feb/12632ffebec0f851ba0ec665f3ed6c55.jpg', 'https://habrastorage.org/r/w780q1/webt/sp/1j/d8/sp1jd8nilix6ixkbtk5fajmjkge.jpeg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w780q1/webt/iw/hk/f3/iwhkf3kzat5qzlgfa0l6m_-tfwu.jpeg', 'https://habrastorage.org/r/w780q1/webt/ga/st/mi/gastmiq1ssqn2b6iolg5m9fjpzm.jpeg', 'https://habrastorage.org/r/w780q1/webt/fl/x5/ko/flx5kogazn7fvlheogjfvrbywac.jpeg', 'https://habrastorage.org/r/w780q1/webt/uz/-w/ne/uz-wneoaotmvvulxrmr53tpevzm.jpeg', 'https://habrastorage.org/r/w780q1/webt/m5/vp/qh/m5vpqhi2nubn13k5hq7lujbv8ym.jpeg', 'https://habrastorage.org/r/w780q1/webt/fi/c6/lt/fic6lts7znnglv8aw_ab7p_gvqc.jpeg', 'https://habrastorage.org/r/w780q1/webt/yr/f6/pn/yrf6pn9oh8realnvs6we9opmii0.jpeg', 'https://habr.com/share/publication/723456/cb0a6172e63b2b3b9d0747859b08076f/', 'https://habrastorage.org/r/w780q1/webt/rt/wm/be/rtwmbeelkc1vdyz9p2b3j_cvzdg.jpeg', 'https://habrastorage.org/r/w780q1/webt/y2/oo/us/y2oous_3h3y-xvhukoybvrtvkv4.jpeg', 'https://habrastorage.org/r/w780q1/webt/c7/mh/c6/c7mhc6mpstgzuhe4jpjys0ckvbo.jpeg', 'https://habrastorage.org/r/w780q1/webt/lh/5i/bj/lh5ibjiht6yh1khqizx7zwgwzsu.jpeg', 'https://habrastorage.org/r/w780q1/webt/gz/ik/op/gzikopahcocm0ixhvassummopnk.jpeg', 'https://habrastorage.org/r/w780q1/webt/km/5h/65/km5h651dayv2ym1sdo51bcw01ho.jpeg', 'https://habrastorage.org/r/w780q1/webt/uh/78/2z/uh782z1gb4vhegnujk3kvnwq9yu.jpeg']"
3'723452'Ностальгические игры: Меч и Магия 8'Пробила меня на днях скупая ностальгическая слеза, и решил я достать со своей полки покрытую пылью коробочку с замечательной игрой «Меч и Магия 8: Эпоха Разрушителя». Почему её, а не седьмую часть?...'https://habr.com/ru/post/723452/'"Пробила меня на днях скупая ностальгическая слеза, и решил я достать со своей полки покрытую пылью коробочку с замечательной игрой «Меч и Магия 8: Эпоха Разрушителя».

Почему её, а не седьмую часть? Ведь по наполнению, размерам мира и сюжету шестая и седьмая части гораздо лучше. Если рассуждать логически, то восьмая часть выглядит как попытка срубить лёгкие деньги на популярной франшизе. А ведь вселенная и правда огромная! Чего уж там, вышло целых 10 номерных частей! Да еще и ответвление серии, которое для большей части населения нашей страны стало гораздо известнее родителя – Герои Меча и Магии (да, Герои произошли от Меча и Магии, как расширение вселенной). И других игр в этой вселенной было не мало…

Но в моём случае логика оказалась бессильна, так как именно с восьмой части я начал знакомство с серией и благодаря ей полюбил эту вселенную. (Забавно, но также у меня произошло и с серией Final Fantasy). Далее я постараюсь стряхнуть пыль с почти забытой линейки игр. Надеюсь, мой сказ побудит новых игроков сыграть в неё, а олдфагов вернуться в родную вселенную и вспомнить былое.

Кто

Создателями является студия New World Computing, которая славится своей номерной серией игр Might and Magic, Heroes of Might and Magic, а также King's Bounty (недавно получила вторую номерную часть благодаря компании 1С.)

Сюжет

Сюжет строится на том, что некая таинственная личность возвела огромный кристалл в центре прибрежного городка и затем исчезла, а по всему континенту начались разные катаклизмы: наводнения, пробуждающиеся вулканы, штормы из молний и огненные реки, смывающие деревни.

Главный герой является караванщиком, который прибыл на острова Кинжальной Раны, но начавшееся там извержение вулкана уничтожило все мосты, а вместе с ними - возможность вернуться на материк. Задача минимум – найти способ выбраться с этих злополучных островов, а после - попытаться понять происхождение всех этих стихийных бедствий, что приведёт игрока к неожиданной развязке. Мы будем спасать целые расы, выбирать сторону в войне некромантов и клириков солнца, заключать союзы и разбираться в том, что происходит и какова наша роль в этих событиях.

Шестая, седьмая и восьмая части Меча и Магии, а также Герои 1, 2 и 3 и «Хроники Героев», связаны между собой и происходят в одном мире. Потому вы будете частенько встречать не только знакомых героев, но и монстров из полюбившейся серии.

Геймплей

Игра встречает нас довольно посредственной графикой, даже по тем временам, а я напомню она вышла в начале 2000 года. Все модели монстров и многих других объектов являются спрайтами, то есть двухмерными изображениями. В наши дни такая графика может показаться архаичной, но это быстро перестаёт бросаться в глаза. Главное в игре - далеко не картинка, а замечательная ролевая система, захватывающий сюжет и большой, интересный мир.

Начинаете вы с создания героя, но в процессе самой игры вы можете нанять в команду дополнительно четырёх персонажей. Ваших подопечных необходимо прокачивать, находить всё более качественную экипировку, добывая разнообразные доспехи и оружие, а также артефакты. Вы можете собрать сбалансированную команду или же создать партию из одних магов/рыцарей. Игру можно пройти любым отрядом, даже одним персонажем!

Механика игры позволяет проводить битвы с монстрами как в режиме реального времени, так и в походовом режиме, позволяя игроку выбирать, что ему в данный момент удобнее. Обычно гораздо комфортнее включить походовый режим и вдумчиво отдать приказы своим подопечным. В юности я бился только в реальном времени, тактический режим меня сильно раздражал (особенно громкая мелодия смены режима). С годами я понял всю его ценность и удобство, а мелодия стала родной и близкой, поэтому сражаюсь почти всегда только в нём!

Звуковое сопровождение

Музыка гениального Пола Ромера всё так же красива, как и во всех предыдущих частях серии, но, на мой взгляд, сильно проигрывает старшим братьям. Для меня её проблема заключается в том, что она не запоминается. При этом музыка не надоедает и уж тем более не «режет уши», что несомненно является положительным аспектом. Остальная озвучка игры, а также звуковые эффекты очень приятные, каждый персонаж озвучен и комментирует действия, происходящие с командой. Фразы многих героев запомнились мне на всю жизнь! И не просто их слова, а интонация, голос!

Интересный факт для фанатов Меча и Магии и Героев: а вы знали, что Пол Ромеро регулярно дает концерты с симфоническим оркестром по всему миру? Не обходит стороной и Россию. Так что если вы хотите окунуться в мелодии, которые долгое время были спутниками ваших приключений в волшебных мирах, созданных New World Computing — посетите концерт маэстро.

Ролевая система

Ролевая система довольно типична для игр такого жанра, с небольшими оговорками.

Игрок, выполняя квесты и убивая монстров, получает опыт, который, накапливаясь до определенной суммы, позволяет повысить уровень. Чтобы получить новый уровень, необходимо отправиться в город, в тренировочный центр, где за плату вас повысят. Если опыта накоплено много, можно разом подняться на несколько ступеней.

При переходе на новый уровень у вас повышаются характеристики, а также даются очки навыков. С ними не всё так просто. Они вкладываются не по одному, как во многих других играх, а с прогрессией. Пример: если у вас 6 уровень навыка, для следующего уровня нужно вложить еще 7 очков, для дальнейшего повышения – восемь, и так далее.

Но и это еще не всё. Каждому навыку можно обучиться до определенного звания. Для этого, набрав необходимое число очков (для всех навыков одинаковое), найдите нужного инструктора, который продвинет вас во владении навыком. Получив 4 очка, можно стать специалистом навыка, 7 очков – мастером, а набрав 10 очков – Великим мастером (ВМ). Повышение довольно сильно меняет ваши возможности. Например, став мастером во владении мечом, можно брать клинки в обе руки, а став ВМ в какой-либо из школ магии, можно использовать сильнейшие заклятия этой школы. Прогрессируя, вы сможете использовать даже базовые заклинания намного эффективнее, наполняя их новыми эффектами. К примеру, заклинание «Волшебное зрение» на базовом уровне позволяет вам видеть врагов на миникарте. Став специалистом магии, вы сможете видеть ещё и предметы, что лежат рядом с вами. На мастерском уровне – увидите интересные места на карте. Став Великим мастером, не будете тратить ману на это заклинание.

Остается добавить, что не каждый класс и не каждая раса может в совершенстве овладеть тем или иным навыком.

Поговорим о классах. Их зачем-то смешали с расами, чего не было в предыдущей части. Теперь их в игре 8: Минотавр, Вампир, Клирик, Некромант, Тролль, Рыцарь, Тёмный эльф и даже Дракон! У каждого свои достоинства и недостатки, которые вам при организации партии нужно учитывать, чтобы нивелировать. К примеру, только некромант способен стать ВМ магии стихий, клирик - ВМ магии Эго (школы духа, разума, тела), а тёмный эльф получить звание ВМ торговли. Выбирайте классы по душе, ведь как я говорил раньше, игру можно пройти любым составом партии!

Arcomage

Небольшая карточная мини-игра, которая появилась еще в 7 части, после чего настолько полюбилась фанатам, что была выпущена отдельной, самостоятельной игрой.

Аркомаг — это самая популярная карточная игра на Энроте. Объяснить это просто, ведь при довольно больших тактических возможностях игра сохраняет простой и интересный процесс. В этом противостоянии двух игроков, каждому из них раздается по 6 случайных карт, три типа ресурсов, две башни и две стены. Задачей каждого игрока является сокрушить башню оппонента либо накопить определённое количество ресурсов, случайное от таверны к таверне. Наверняка вы, как и большое количество игроков с Энрота, полюбите эту игру и проведёте за ней не один час. А если я к этому добавлю, что в восьмой части есть квест, который наградит вас очень хорошими артефактами за победу во всех тавернах, то играть станет еще приятнее =)

Мод

Для знакомства с игрой я настоятельно советую установить мод «World Of Enroth».

Он добавляет возможность обзора мышью, ведь изначально это можно делать лишь на клавиатуре. Сам мод, построенный на движке 8 части, объединил в себе сразу 3 игры — шестую, седьмую и восьмую - и дал возможность путешествовать между ними своей партией героев. Более того, для этого действия даже придумали сюжетное обоснование и ввели новый квест! Для фанатов 6 и 7 части скажу: поскольку мод сделан на основе 8 игры, все её игровые механики перекочевали в 6 и 7 части! Это значит, что в шестёрке теперь можно стать Великим Мастером навыков, а в семёрке можно полетать на драконе, взяв его в партию! Так как вы можете пройти одним набором героев сразу три игры, делая их в процессе очень сильными, в модификации добавили параметр, позволяющий поднять силу монстров, чтобы игра не казалась слишком простой. Я не буду перечислять все полезные особенности мода, вроде поддержки высоких разрешений экрана, возможности отключать интро при запуске игры, ускорения игры. Их великое множество. Я вам очень советую этот мод, играть станет в разы удобнее и приятнее!

Итог

Об этой замечательной игре можно рассказать много интересного и растянуть и без того длинный обзор еще сильнее, потому буду закругляться. Что же мы имеем в итоге? Большой мир, полный разных секретов и загадок, с богатой ролевой системой, а также интересной историей, вкупе с возможностью повстречать старых знакомых из «Героев». Большое количество разной магии: хождение по воде и полёт, боевая и лечащая магия, некромантия (да-да, можно создать себе армию мёртвых) и разная статусная магия. Пусть по современным меркам игра устарела и не является лучшей в серии, но она явно достойна того, чтобы с ней ознакомиться. Это сложно объяснить словами, но игры той эпохи дарят какой-то ламповый, тёплый геймплей и немного другие впечатления, нежели чем современные.

Понравился пост? Подпишитесь на телеграмм:

https://t.me/GamerOldfag

P.S.: ссылку на форум модификации, где можно найти сам мод, а так же патчи, советы и руссификаторы залил себе в телеграмм.

P.S.S.: я настолько большой фанат серии, что девушка сделала мне диораму."'https://habr.com/share/publication/723452/58ecb9151b0bf353c0ac31b8e69a780f/'"['https://habrastorage.org/r/w780q1/getpro/habr/upload_files/322/a85/8a9/322a858a9e4f29d864d9c1bba32041be.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/74c/276/3b8/74c2763b8deb0629576adab628f3e225.jpg', 'https://habrastorage.org/getpro/habr/upload_files/c6c/f42/24d/c6cf4224d43b2cafe29fe03772ba5b60.webp', 'https://habrastorage.org/r/w48/getpro/habr/avatars/a7d/ff0/0d1/a7dff00d1ac70a0f64500462fa1061f3.png', 'https://habrastorage.org/getpro/habr/upload_files/e88/5a8/6db/e885a86db823b663ccf41592df8549ee.webp', 'https://habrastorage.org/getpro/habr/avatars/a7d/ff0/0d1/a7dff00d1ac70a0f64500462fa1061f3.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/4bf/3c9/324/4bf3c93242a09d2762fbf8d0ccd027be.jpg', 'https://habrastorage.org/getpro/habr/upload_files/7ff/788/517/7ff788517fea3bd0ef90c4b0870f6ef0.webp', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/d0d/ac8/5a1/d0dac85a1a6b7dc5e43af2c619b4a8bb.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/cb8/997/e2e/cb8997e2ec60deb953ee06d1efd9dc4a.png', 'https://habr.com/share/publication/723452/58ecb9151b0bf353c0ac31b8e69a780f/']"
4'723434'[Перевод] Использовать unwrap() в Rust — это нормально'Предисловие Сравнительно недавно на Хабре была опубликована статья «Rust: ни в коем случае не используйте unwrap() в продакшене» . Мягко говоря, тезисы, высказываемые в данной статье, спорны и...'https://habr.com/ru/post/723434/'"Предисловие

Сравнительно недавно на Хабре была опубликована статья «Rust: ни в коем случае не используйте unwrap() в продакшене». Мягко говоря, тезисы, высказываемые в данной статье, спорны и содержат мало обоснования. Предлагаю читателям взглянуть на альтернативную точку зрения: почему использовать unwrap() в Rust — это нормально (в том числе и в продакшене). Автор оригинальной статьи — Эндрю Галлант.

Использовать unwrap() в Rust — это нормально

За день до выпуска Rust 1.0 я опубликовал запись в блоге, посвященную основам обработки ошибок. Особенно важный, но небольшой раздел, спрятанный в середине статьи, называется «разматывание стека — это не зло». В этом разделе кратко описано что, в общем-то, использование unwrap() допустимо, если оно находится в тестовом/демонстрационном коде или когда паника указывает на баг (ошибку программиста).

В целом, я до сих пор придерживаюсь этого убеждения. Это убеждение применяется на практике в стандартной библиотеке Rust и во многих основных крейтах экосистемы. (И эта практика предшествовала моему сообщению в блоге.) Тем не менее, по-прежнему существует широко распространенная путаница в отношении того, когда можно и когда нельзя использовать unwrap() . В этом посте я расскажу об этом более подробно и конкретно отвечу на ряд точек зрений, с которыми я сталкивался.

Этот пост в блоге написан как FAQ, но его следует читать последовательно. Каждый вопрос основывается на предыдущем.

Целевая аудитория: в первую очередь программисты на Rust, но я надеюсь, что предоставил достаточно контекста, чтобы изложенные здесь принципы были применимы к любому программисту. Хотя может быть сложно применить очевидное сопоставление к языкам с другими механизмами обработки ошибок, такими как исключения.

Какова моя точка зрения?

Я думаю, что полезно заранее изложить ряд тезисов, касаемых обработки ошибок и паники, которых я придерживаюсь. Таким образом, читатели точно узнают из чего я исхожу.

Паника не должна использоваться для обработки ошибок ни в приложениях, ни в библиотеках.

Допустимо использовать панику для обработки ошибок при прототипировании, в тестах, бенчмарках и примерах документации.

Если программа на Rust паникует, это сигнализирует о том, что в ней имеется баг. То есть правильные программы на Rust не паникуют.

Всегда есть способ определить ответственность, кто «виновен» в панике. Либо это вина функции, которая запаниковала, либо вина вызывающей стороны.

За пределами предметной области, которой требуются формальные методы (или что-то подобное) для доказательства правильности своих программ, невозможно или нецелесообразно перемещать каждый инвариант в систему типов.

Поэтому, когда в программе возникают инварианты времени выполнения, есть несколько подходов:

Можно сделать функцию частичной, вызвав панику на некотором подмножестве входных данных (т.е. нарушение предусловия). В этом случае, если функция паникует, значит баг на вызывающей стороне. Предположим, что инвариант никогда не нарушается, а если нарушается, то функция паникует (т.е. внутренний инвариант). В этом случае, если функция паникует, значит баг на вызываемой строне. В случае нарушения предусловия можно вернуться к вызывающему коду. (Например, возвращая ошибку через Result::Err ) Однако, это никогда не следует использовать в случае внутреннего нарушения инварианта, поскольку это приводит к утечке деталей реализации.

В приведенных выше случаях (1) и (2) нормально использовать unwrap() , expect() и синтаксис индексации слайса, среди прочего.

Предпочитайте функцию expect() вместо unwrap() , так как при возникновении паники она выдает более наглядные сообщения. Но используйте unwrap() , когда expect() приводит к излишнему шуму.

Остальная часть статьи будет подробнее объяснять эти тезисы.

Что такое unwrap()?

Поскольку идеи, изложенные в этом посте, не специфичны только для Rust, я думаю, важно рассказать что такое unwrap() на самом деле. unwrap() это метод, определенный как для Option<T> , так и для Result<T, E> , который возвращает внутреннее значение T в случае варианта Some или Ok соответственно и вызывает панику в противном случае. Их определения очень просты.

Для Option<T> :

impl<T> Option<T> { pub fn unwrap(self) -> T { match self { Some(val) => val, None => panic!(""called `Option::unwrap()` on a `None` value""), } } }

Для Result<T, E> :

impl<T, E> Result<T, E> { pub fn unwrap(self) -> T where E: fmt::Debug, { match self { Ok(t) => t, Err(e) => panic!(""called `Result::unwrap()` on an `Err` value: {:?}"", e), } } }

Ключевое напряжение, которое я пытаюсь разрешить в этом посте, это то, следует ли вообще использовать unwrap() и в какой степени.

Что значит «паниковать»?

Когда возникает паника, обычно происходит одна из двух вещей:

Процесс прерывается.

Если целевая архитектура это поддерживает, стек раскручивается. Если раскрутку стека не поймать, то это приведет к прерыванию процесса с сообщением и указанием источника паники.

Что именно произойдет, зависит от того, как программа была скомпилирована. Это можно контролировать с помощью параметра профиля panic в Cargo.toml .

Когда происходит раскрутка стека, можно поймать панику и что-нибудь с ней сделать. Например, веб-сервер может перехватывать панику, возникающую внутри обработчиков запросов, чтобы избежать остановки всего сервера. Другим примером является система тестирования, которая перехватывает панику, возникшую в тесте, чтобы можно было выполнить другие тесты и распечатать результаты вместо того, чтобы немедленно отключать всю систему.

Хотя паники можно использовать для обработки ошибок, обычно это считаются плохим тоном. Примечательно, что в языке нет хорошей поддержки использования паники для обработки ошибок, при этом, что особенно важно, раскрутка стека не гарантируется.

Когда паника вызывает раскрутку, которая нигде не перехватывается, вероятно, программа прервется как только весь стек будет раскручен, затем напечатает сообщение, содержащееся в объекте паники. (Я говорю «вероятно», потому что можно установить обработчики паники или ловушки паники.) Например:

fn main() { panic!(""Прощай, жестокий мир""); }

Запустив это, мы увидим:

$ cargo build $ ./target/debug/rust-panic thread 'main' panicked at 'Прощай, жестокий мир', src/main.rs:2:5 note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

В примечании говорится, что можно включить трассировку стека:

$ RUST_BACKTRACE=1 ./target/debug/rust-panic thread 'main' panicked at 'Прощай, жестокий мир', src/main.rs:2:5 stack backtrace: 0: rust_begin_unwind at /rustc/2c8cc343237b8f7d5a3c3703e3a87f2eb2c54a74/library/std/src/panicking.rs:575:5 1: core::panicking::panic_fmt at /rustc/2c8cc343237b8f7d5a3c3703e3a87f2eb2c54a74/library/core/src/panicking.rs:64:14 2: rust_panic::main at ./src/main.rs:2:5 3: core::ops::function::FnOnce::call_once at /rustc/2c8cc343237b8f7d5a3c3703e3a87f2eb2c54a74/library/core/src/ops/function.rs:250:5 note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.

Паники не очень полезны или дружелюбны в качестве сообщений об ошибках для конечного пользователя. Однако, паники обычно предоставляют программисту очень полезную отладочную информацию. Исходя из опыта, трассировки стека часто достаточно, чтобы точно понять, что пошло не так. Но вряд ли это будет полезно конечному пользователю. Например, было бы плохим тоном паниковать, если не удаётся открыть файл:

fn main() { let mut f = std::fs::File::open(""foobar"").unwrap(); std::io::copy(&mut f, &mut std::io::stdout()).unwrap(); }

Вот что происходит, когда мы запускаем такую программу:

$ ./target/debug/rust-panic thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Os { code: 2, kind: NotFound, message: «No such file or directory» }', src/main.rs:2:47 note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

Сообщение об ошибке не совсем бесполезно в этом сценарии, но оно не включает путь к файлу и не содержит окружающий контекст, информирующий пользователя о том, что приложение пыталось сделать когда оно столкнулось с ошибкой ввода-вывода. Оно также содержит много шума, который бесполезен для конечного пользователя.

Вывод:

Паники отлично подходит для программистов. Они содержат сообщение, трассировку стека и номера строк. Они сами по себе часто являются достаточной информацией для диагностики ошибок программиста.

Паника не так хороша для конечных пользователей. Это лучше, чем прерывание без какого-либо вывода, но сообщениям паники часто не хватает контекста, важного для конечных пользователей, при том, что пишутся эти сообщения специально для программистов.

Что такое обработка ошибок?

Обработка ошибок — это то, что делает программист в своем коде, когда что-то «идёт не так». Не вдаваясь в подробности, есть несколько разных способов обработки ошибок в Rust:

Можно прервать выполнение процесса с ненулевым кодом выхода. Можно запаниковать с ошибкой. Это может прервать процесс, а может и нет. Как описано в предыдущем разделе, это зависит от того, как была скомпилирована программа. Ошибки можно обрабатывать как значения, обычно с помощью типа Result<T, E> . Если ошибка всплывает на всем пути до main функции, можно напечатать ошибку в stderr, а затем прервать выполнение процесса.

Все три являются вполне допустимыми стратегиями обработки ошибок. Проблема в том, что первые два приводят к очень плохому взаимодействию с пользователем приложений в контексте программ на Rust. Поэтому (3) обычно считается лучшей практикой. Стандартная библиотека и все основные библиотеки экосистемы используют (3). Кроме того, насколько мне известно, все «популярные» приложения Rust также используют (3).

Одной из наиболее важных частей (3) является возможность добавлять дополнительный контекст к значениям ошибок, когда они возвращаются вызывающей стороне. Крейт anyhow помогает проще это делать. Вот фрагмент из незавершенного инструмента regex-cli , над которым я работаю:

use anyhow::Context; if let Some(x) = args.value_of_lossy(""warmup-time"") { let hdur: ShortHumanDuration = x.parse().context(""--warmup-time"")?; margs.bench_config.approx_max_warmup_time = Duration::from(hdur); }

Важным моментом здесь является x.parse().context(""--warmup-time"")? . Для тех, кто не знаком с Rust, поясню:

x — это Cow<'a, str> , тип, который является «либо владением String , либо заимствованием &str «. Cow означает «copy-on-write» (копирование при записи).

parse() это сокращение для вызова FromStr::from_str , который парсит строку в какой-либо другой тип данных. В данном случае этот тип — ShortHumanDuration . Поскольку парсинг строки может завершиться с ошибкой, функция parse() возвращает значение типа Result<T, E> .

context() поставляется трейтом anyhow::Context . Это называется «трейтом расширения», который добавляет методы к Result<T, E> . В данном случае context(""--warmup-time"") добавляет короткое сообщение в контекст ошибки.

Суффиксный оператор ? говорит: «Если Result<T, E> является Ok(T) , то отдай T в качестве результата выражения, иначе верни E как ошибку из текущей функции». (Обратите внимание, что это не точное описание того, что делает ? . См. раздел «оператор вопросительный знак» справочника по Rust для более подробной информации.)

Конечным результатом является то, что если передать недопустимое значение флагу --warmup-time , то сообщение об ошибке будет включать --warmup-time :

$ regex-cli bench measure --warmup-time '52 minutes' Error: --warmup-time Caused by: duration '52 minutes' not in '<decimal>(s|ms|us|ns)' format

Это дает понять, какая часть ввода, предоставленного пользователем, была проблематичной.

(Примечание: anyhow отлично подходит для кода, ориентированного на конечное приложение, но если кто-то создаёт библиотеку, предназначенную для использования другими, я бы предложил написать конкретные типы ошибок и предоставить соответствующую реализацию std::fmt::Display . Крейт thiserror избавляет от написания шаблонного кода, связанного с этим, но я бы предпочёл не использовать этот крейт, чтобы избежать зависимостей от процедурных макросов, если кто-то ещё не использует зависимости процедурных макросов для чего-то другого.)

Следует ли использовать unwrap() для обработки ошибок?

Довольно часто можно увидеть, как unwrap() используется для обработки ошибок в следующих трех сценариях:

Быстрые одноразовые программы, прототипирование или программы для личного использования. Поскольку единственным конечным пользователем является программист приложения, паника не обязательно является плохим пользовательским опытом. В тестах. В общем, Rust тесты падают, если паникуют, и проходят, если паники нет. Так что с unwrap() в этом контексте всё в порядке, поскольку вполне вероятно, что паника — это именно то, что нужно в любом случае. Обратите внимание, что можно вернуть Result из модульных тестов, что позволяет использовать оператор ? в тестах. В примерах документации. Раньше обработка ошибок как значений в документации требовала немного больше усилий, чем использование паники. Но теперь оператор ? можно использовать в тестах документации.

Лично у меня нет твердого мнения о том, следует ли использовать unwrap() в любом из вышеперечисленных случаях. Остановлюсь на каждом из пунктов:

Даже в быстрых программах или программах только для личного использования, я обращаюсь с ошибками как со значениями. anyhow делает это невероятно простым. Просто напишите cargo add anyhow , а затем используйте fn main() -> anyhow::Result<()> . Вот и всё. В данном контексте нет большого эргономического преимущества в использовании паники для обработки ошибок. anyhow будет даже предоставлять трассировку стека. Я широко использую unwrap() в тестах. Я редко, если когда-либо использую ? в модульных тестах.Возможно, это связано с тем, что я начал писать на Rust до того, как модульные тесты научились возвращать Result<T, E> . Я не вижу убедительного преимущества в том, чтобы изменить то, что я делаю и при этом писать более длинные сигнатуры. Обычно, в примерах документации, я стремился обращаться с ошибками как со значениями, а не паниковать. В частности, всё что нужно сделать, это добавить # Ok::<(), Box<dyn std::error::Error>>(()) в конец большинства примеров, и тогда можно будет использовать оператор ? . Это легко сделать и при этом, демонстрирует более идиоматичный код. С учетом сказанного, настоящая обработка ошибок имеет тенденцию добавлять контекст к ошибкам. Я бы счёл это идиоматичным, но тем не менее, я не делаю этого в примерах документации. Кроме того, примеры документации, как правило, нацелены на демонстрацию определённого аспекта API, и ожидать, что они будут совершенно идиоматичными во всех остальных аспектах — особенно если это отвлекает внимание от сути примера — кажется нереалистичным. Так что в целом, думаю, что хоть unwrap() в документации — это нормально, я бы предпочёл избежать этого, потому что это легко сделать.

Подводя итог, я бы сказал, что «не использовать unwrap() для обработки ошибок в Rust» — это хорошее первое приближение. Но разумные люди могут не согласиться с тем, следует ли использовать unwrap() в некоторых сценариях (как обсуждалось выше) из-за его краткости.

С учетом сказанного я считаю бесспорным утверждение о том, что unwrap() не следует использовать для обработки ошибок в библиотеках Rust или приложениях, которые предназначены для использования другими. Это оценочное суждение. С этим можно не согласиться, но думаю, что было бы трудно утверждать, что использование unwrap() для обработки ошибок приводит к хорошему пользовательскому опыту. Поэтому я считаю, что большинство людей согласны с тем, что: unwrap() и, в более общем смысле, паника — неадекватный метод обработки ошибок в Rust.

Как насчет «исправимых» и «неисправимых» ошибок?

Глава растбука «Обработка ошибок» популяризировала идею представления об ошибках как об «исправимых» и «неисправимых». То есть, если ошибка исправима, то следует рассматривать её как нормальное значение и использовать Result<T, E> . С другой стороны, если ошибка неисправима, то можно паниковать.

Лично я никогда не считал эту конкретную концепцию полезной. Проблема, на мой взгляд, заключается в неоднозначности определения того, является ли та или иная ошибка «исправимой» или нет. Что это в точности означает?

Я думаю, гораздо полезнее быть конкретным. То есть если происходит паника, значит где-то в программе баг. Если паника возникает внутри функции из-за того, что задокументированное предварительное условие не поддерживается, то ошибка лежит на вызывающей стороне. В противном случае проблема связана с реализацией этой функции.

Это все, что нужно знать, чтобы определить, рассматривать ли ошибки как значения или как панику. Некоторые примеры:

Является ли ошибкой, если программа не может открыть файл по пути, указанному пользователем? Нет. Поэтому рассматривайте эту ошибку как значение.

Является ли ошибкой, если программа не может построить регулярное выражение из статичного строкового литерала? Да. Программист написал это регулярное выражение. Оно должно быть правильным. Так что паника уместна.

Так что, никогда не следует паниковать?

В общем, да, правильные программы на Rust не должны паниковать.

Означает ли это, что если для обработки ошибок в быстром «скрипте» Rust использовалась паника, то это неправильно? Дэвид Толней предположил, что это граничит с формой парадокса Рассела, и я склонен с ним согласиться. В качестве альтернативы можно думать о скрипте или прототипе как будто его баги помечены как wontfix .

Так что, никогда не следует использовать unwrap() или expect()?

Нет! Такие методы, как unwrap() или expect() , паникуют только в том случае, если их значение не совпадает с ожидаемым. Если значение всегда совпадает с ожидаемым, то из этого следует, что unwrap() и expect() никогда не приведут к панике. Если паника всё-таки возникает, то это, как правило, соответствует нарушению ожиданий программиста. Другими словами, был нарушен инвариант времени выполнения, что привело к возникновению бага.

Это сильно отличается от «не используйте unwrap() для обработки ошибок». Ключевое отличие здесь в том, что мы ожидаем, что ошибки будут регулярно возникать, но мы совсем не ожидаем возникновение бага. И когда баг действительно случается, мы пытаемся его устранить (или объявить о ней как о проблеме, которая не будет исправлена).

Я думаю, что много путаницы вокруг unwrap() возникает из-за того, что люди из лучших побуждений говорят что-то вроде не используйте unwrap() , когда на самом деле они имеют в виду не используйте панику как стратегию обработки ошибок. Это вдвойне сбивает с толку со стороны другой группы людей, которые на самом деле буквально имеют в виду не использовать unwrap() , никогда, ни при каких обстоятельствах, до такой степени, что этого вообще не должно было существовать. Это трижды сбивает с толку со стороны ещё одной группы людей, которые говорят «не используйте unwrap()», но на самом деле имеют в виду «не используйте unwrap(), expect(), индексацию слайсов или любую другую паникующую функцию, даже если кто-то доказывает что паника невозможна».

Другими словами, в этом посте я пытаюсь решить две проблемы. Одной из них является проблема определения того, когда следует использовать unwrap() . Другая проблема — коммуникация. Это та область, где неточность приводит к странным непоследовательным советам.

Что такое инвариант времени выполнения?

Это то, что всегда должно быть правдой, но гарантия поддерживается во время выполнения, а не подтверждается во время компиляции.

Простым примером инварианта является целое число, которое никогда не равно нулю. Есть несколько способов установить это:

Используйте std::num::NonZeroUsize . Это поддерживает инвариант во время компиляции, поскольку конструкция типа гарантирует, что он не может быть равен нулю.

Используйте Option<usize> и полагайтесь на то, что вызывающая сторона предоставит None , когда внутренний usize равен 0 . Это поддерживает инвариант во время выполнения, поскольку конструкция Option<usize> не инкапсулирована.

Используйте usize и полагайтесь на то, что вызывающая сторона никогда не установит его равным 0 . Это также поддерживает инвариант во время выполнения.

(Примечание: std::num::NonZeroUsize имеет другие преимущества, помимо принудительного применения этого конкретного инварианта во время компиляции. А именно, он позволяет компилятору выполнять оптимизацию размещения памяти, где Option<NonZeroUsize> имеет тот же размер в памяти, что и usize .)

В этом случае, если вам нужен такой инвариант, как «целое число, которое никогда не равно нулю», то использование такого типа, как NonZeroUsize , является очень убедительным выбором с несколькими недостатками. Это вносит небольшой шум в код, когда необходимо использовать целое число, поскольку нужно вызывать get() , чтобы получить непосредственно usize , который необходим для выполнения таких вещей, как арифметика или использование его для индексации слайсов.

Так почему бы не сделать всё инвариантами времени компиляции?

В некоторых случаях это невозможно сделать. Мы рассмотрим это в следующем разделе.

В других случаях это можно сделать, но этого не делают по некоторым причинам. Одной из таких причин является сложность API.

Рассмотрим один реальный пример из моего крейта aho-corasick (который предоставляет реализацию алгоритм Ахо-Корасика). Его метод AhoCorasick::find_overlapping_iter вызывает панику, если автомат AhoCorasick не был создан во время выполнения с «типом совпадения» «стандарт». Другими словами, подпрограмма AhoCorasick::find_overlapping_iter накладывает задокументированное предварительное условие на вызывающую программу, обещая вызывать её только в том случае, если AhoCorasick был построен определенным образом. Я выбрал этот подход по нескольким причинам:

Перекрывающийся поиск имеет смысл только в том случае, если «тип соответствия» установлен как «стандартный».

Настройка «типа совпадения» почти всегда будет выполняться программистом, а не чем-то, что осуществляется через ввод.

Простота API.

Что я имею в виду под «простотой API»? Ну, эту панику можно убрать, переместив этот инвариант времени выполнения в инвариант времени компиляции. А именно, API мог бы предоставить, например, тип AhoCorasickOverlapping , и перекрывающиеся подпрограммы поиска были бы определены только для этого типа, а не для AhoCorasick . Следовательно, пользователи библиотеки никогда не смогут вызвать перекрывающую функцию поиска на неправильно сконфигурированном автомате. Компилятор просто не позволил бы этого.

Но это добавляет API много дополнительной площади соприкосновения. И делает это действительно пагубными способами. Например, тип AhoCorasickOverlapping по-прежнему хотел бы иметь нормальные неперекрывающиеся процедуры поиска, как это делает AhoCorasick . Теперь разумно захотеть иметь возможность писать подпрограммы, которые принимают любой тип автомата Ахо-Корасика и выполняют непересекающийся поиск. В этом случае либо крейт aho-corasick , либо программист, использующий крейт, должен определить какую-то общую абстракцию, чтобы сделать это возможным. Или, что более вероятно, скопировать некоторое количество кода.

Таким образом, я пришел к выводу, что лучше всего иметь один тип, который может делать всё, но может громко дать сбой для определенных методов при определенных конфигурациях. Дизайн API aho-corasick не приведет к тонким логическим ошибкам, которые молча выдают неверные результаты. Если допущена ошибка, то вызывающая сторона всё равно получит панику с чётким сообщением. Её будет легко исправить в этом месте.

Взамен мы получаем более простой API. Существует только один тип, который можно использовать для поиска. Не нужно отвечать на такие вопросы, как «подождите, какой тип я хочу? Теперь мне нужно понять и то, и другое, и попытаться собрать кусочки головоломки воедино». И если кто-то хочет написать одну универсальную подпрограмму, которая принимает любой автомат и выполняет непересекающийся поиск, то ей не нужны дженерики. Потому что есть только один тип.

Что делать, если инварианты нельзя вынести на уровень времени компиляции?

Рассмотрим, как можно реализовать поиск с использованием детерминированного конечного автомата (deterministic finite automaton — DFA). Базовая реализация состоит всего из нескольких строк, поэтому её легко включить сюда:

type StateID = usize; struct DFA { // Идентификатор начального состояния. Каждый поиск начинается здесь. start_id: StateID, // Таблица переходов по строкам. Для состояния 's' и байта 'b' // следующее состояние 's * 256 + b'. transitions: Vec<StateID>, // Соответствует ли конкретный идентификатор состояния состоянию совпадения. // Гарантируется, что длина будет равна количеству состояний. is_match_id: Vec<bool>, } impl DFA { // Возвращает true, если DFA сопоставляет весь `haystack`. // Этот метод всегда возвращает либо true, либо false для всех входных данных. // Никогда не паникует. fn is_match(&self, haystack: &[u8]) -> bool { let mut state_id = self.start_id; for &byte in haystack { // Умножаем на 256, потому что это размер алфавита нашего DFA. // Другими словами, каждое состояние имеет 256 переходов. По одному на каждый байт. state_id = self.transitions[state_id * 256 + usize::from(byte)]; if self.is_match_id[state_id] { return true; } } false } }

Здесь есть несколько мест, где может возникнуть паника:

state_id * 256 + byte может быть недействительным индексом в self.transitions .

state_id может быть недопустимым индексом в self.is_match_id .

Умножение state_id * 256 может вызывать панику в режиме отладки. В настоящее время в релизной сборке будет выполнено умножение с переполнением, но это может измениться на панику при переполнении в будущей версии Rust.

Точно так же сложение + usize::from(byte) может вызывать панику по той же причине.

Как можно гарантировать, что во время компиляции никогда не возникнет паника при выполнении арифметических операций или доступе к элементам слайса? Имейте в виду, что векторы transitions и is_match_id могут быть созданы на основе пользовательского ввода. Поэтому, как бы это ни было сделано, нельзя полагаться на то, что компилятор знает входные данные для DFA. Входными данными, на основе которых был построен DFA, может быть произвольный шаблон регулярного выражения.

Нет осуществимого способа вынести на уровень времени компиляции инвариант о том, что DFA строится и выполняет поиск правильно. Это должен быть инвариант времени выполнения. И кто отвечает за поддержание этого инварианта? Реализация, создающая DFA, и реализация, использующая DFA для выполнения поиска. Обе должны быть согласованы друг с другом. Другими словами, у них есть общий секрет: как DFA размещается в памяти. (Предупреждение: раньше я ошибался насчет невозможности впихнуть инварианты в систему типов. Я признаю здесь такую возможность, мое воображение невелико. Однако я вполне уверен, что это повлечет за собой немало церемоний и/или быть ограниченным в своем применении. Тем не менее, это было бы интересное упражнение, даже если оно не полностью отвечает всем требованиям.)

Если бы где-то возникла паника, что бы это значило? Это должно означать, что где-то в коде есть баг. И поскольку документация этого метода гарантирует, что он никогда не паникует, проблема должна быть связана с реализацией. Дело либо в том, как был построен DFA, либо в том, как выполняется поиск DFA.

Почему бы не вернуть ошибку вместо паники?

Вместо того, чтобы паниковать, когда что-то пошло не так, можно вернуть значение ошибки. Метод is_match из предыдущего раздела можно переписать так, чтобы вместо паники возвращалось сообщение об ошибке:

// Возвращает true, если DFA сопоставляет весь `haystack`. // Этот метод всегда возвращает либо `Ok(true)`, либо `Ok(false)` для всех входных данных. // Он никогда не возвращает ошибку `Err(&str)`, если его реализация корректна. fn is_match(&self, haystack: &[u8]) -> Result<bool, &'static str> { let mut state_id = self.start_id; for &byte in haystack { let row = match state_id.checked_mul(256) { None => return Err(""слишком большой идентификатор состояния""), Some(row) => row, }; let row_offset = match row.checked_add(usize::from(byte)) { None => return Err(""слишком большой индекс ряда""), Some(row_offset) => row_offset, }; state_id = match self.transitions.get(row_offset) { None => return Err(""неверный переход""), Some(&state_id) => state_id, }; match self.is_match_id.get(state_id) { None => return Err(""неверный идентификатор состояния""), Some(&true) => return Ok(true), Some(&false) => {} } } Ok(false) }

Обратите внимание, насколько усложнилась эта функция. И обратите внимание, насколько неуклюжей стала документация. Кто пишет такие вещи, как «эта документация совершенно неверна, если реализация некорректна»? Вы видели такое в какой-нибудь неэкспериментальной библиотеке? В этом нет особого смысла. И зачем возвращать ошибку, если документация гарантирует, что ошибка никогда не будет возвращена? Для ясности, кто-то может захотеть сделать это по причинам эволюции API (т.е. «Может быть, когда-нибудь метод вернет ошибку»), но этот метод никогда не вернёт ошибку ни при каких обстоятельствах в любом возможном сценарии в будущем.

Какая польза от такой рутины? Если бы мы были сторонниками steelman аргументации в пользу этого стиля написания кода, то думаю, что аргумент, лучше всего было бы ограничить определенной сферой применения высокой надежности. У меня лично нет большого опыта в этих областях, но я могу представить случаи, когда кто-то не хочет иметь какое-либо возможное ветвление в панику в окончательном скомпилированном бинарном файле где бы то ни было. Это даёт большую уверенность в том, в каком состоянии находится код в любой момент времени. Это также означает, что вы, вероятно, не сможете использовать стандартную библиотеку Rust или большинство основных крейтов экосистемы, поскольку все они будут иметь потенциальную панику где-то внутри. Другими словами, это очень дорогой стиль написания кода.

Действительно интересная часть этого подхода — включение инвариантов времени выполнения в значения ошибок — заключается в том, что на самом деле невозможно должным образом задокументировать условия ошибки. Хорошо задокументированные условия ошибки каким-то образом связывают входные данные функции с некоторым случаем отказа. Но это невозможно сделать для данного метода, потому что если бы можно было, то это было бы документированием бага!

Когда следует использовать unwrap(), даже если в этом нет необходимости?

Рассмотрим пример, в котором на самом деле можно было бы избежать использования unwrap() , а стоимость — лишь незначительная сложность кода. Этот адаптированный фрагмент кода был взят из крейта regex-syntax:

enum Ast { Empty(std::ops::Range<usize>), Alternation(Alternation), Concat(Concat), // ... и другие } // AST-представление регулярного выражения по типу 'a|b|...|z'. struct Alternation { // Байт смещается туда, где эта альтернация // встречается в конкретном синтаксисе. span: std::ops::Range<usize>, // AST каждой альтернации. asts: Vec<Ast>, } impl Alternation { /// Возвращает эту альтернацию как простейшее возможное 'Ast'. fn into_ast(mut self) -> Ast { match self.asts.len() { 0 => Ast::Empty(self.span), 1 => self.asts.pop().unwrap(), _ => Ast::Alternation(self), } } }

Фрагмент кода self.asts.pop().unwrap() вызовет панику, если вектор self.asts пуст. Но так как мы проверили, что его длина не равна нулю, он не может быть пустым, и поэтому unwrap() никогда не будет паниковать.

Но зачем здесь использовать unwrap() ? На самом деле мы могли бы написать это вообще без unwrap() :

fn into_ast(mut self) -> Ast { match self.asts.pop() { None => Ast::Empty(self.span), Some(ast) => { if self.asts.is_empty() { ast } else { self.asts.push(ast); Ast::Alternation(self) } } } }

Проблема здесь в том, что если pop() оставляет self.asts непустым, то мы на самом деле хотим создать Ast::Alternation , так как есть два или более подвыражения. Если есть ноль или одно подвыражение, то нам доступно более простое представление. Таким образом, в случае более чем одного подвыражения, после того, как мы извлекли одно из них, нам действительно нужно запушить его обратно в self.asts , прежде чем строить альтерацию.

В переписанном коде отсутствует функция unwrap() , что является преимуществом, но запутанно и странно. Исходный код намного проще, и нетрудно заметить, что unwrap() никогда не приведет к панике.

Почему бы не использовать expect() вместо unwrap()?

expect() похож на unwrap() , за исключением того, что он принимает параметр сообщения и включает это сообщение в вывод паники. Другими словами, он добавляет немного дополнительного контекста к сообщению паники, если она происходит.

Думаю, что в целом рекомендуется использовать expect() вместо unwrap() . Однако я не думаю, что стоит полностью запрещать unwrap() . Добавление контекста через expect() помогает информировать читателей кода о том, что автор рассмотрел соответствующие инварианты и написал сообщение о том, что именно ожидалось.

Однако сообщения expect() , как правило, короткие и не содержат полного обоснования того, почему использование expect() является корректным. Вот ещё один пример из крейта regex-syntax:

/// Парсит восьмеричное представление кодпоинта Unicode длиной до 3 цифр. /// Предполагается, что парсер будет расположен на первой восьмеричной цифре и /// будет продвигаться к первому символу, непосредственно следующему за восьмеричным числом. /// Также предполагается, что синтаксический разбор восьмеричной escape-последовательности включен. /// /// Предполагая, что предварительные условия соблюдены, эта функция никогда не может дать сбой. fn parse_octal(&self) -> ast::Literal { // См. задокументированные предварительные условия. assert!(self.parser().octal); assert!('0' <= self.char() && self.char() <= '7'); let start = self.pos(); // Парсим еще две цифры. while self.bump() && '0' <= self.char() && self.char() <= '7' && self.pos().offset - start.offset <= 2 {} let end = self.pos(); let octal = &self.pattern()[start.offset..end.offset]; // Парсинг восьмеричного числа не может завершиться с ошибкой, // поскольку код выше гарантирует валидное число. let codepoint = std::u32::from_str_radix(octal, 8).expect(""валидное восьмеричное число""); // Максимальное значение для трехзначного восьмеричного числа составляет 0o777 = 511, // и [0, 511] не имеет недопустимых скалярных значений Unicode. let c = std::char::from_u32(codepoint).expect(""скалярное значение Unicode""); ast::Literal { span: Span::new(start, end), kind: ast::LiteralKind::Octal, c, } }

Есть два варианта использования expect() . В каждом случае сообщение expect() в какой-то мере полезно, но основная суть того, почему в обоих случаях expect() работает, заключается в форме комментариев. Комментарии объясняют, почему операции from_str_radix и from_u32 никогда не вернут значение ошибки. Сообщение expect() просто даёт дополнительную подсказку, которая делает сообщение паники немного более полезным.

Использовать ли unwrap() или expect() — это вопрос личного выбора. В приведенном выше примере into_ast , думаю, expect() добавляет бессмысленный шум, потому что окружающий код и так тривиально показывает, почему unwrap() в данном случае это нормально. В таком случае даже нет смысла писать комментарий, говорящий об этом.

У expect() есть и другие стороны, которые добавляют больше шума. Вот некоторые примеры:

Regex::new(""..."").expect(""регулярное выражение валидно""); mutex.lock().expect(""мьютекс не отравлен""); slice.get(i).expect(""индекс валиден"");

Я утверждаю, что ничего из этого на самом деле не добавляет никакой информации к коду, а только делает его более многословным и зашумленным. Если вызов Regex::new завершается с ошибкой со статическим строковым литералом, то красивое сообщение об ошибке уже будет напечатано. Например, рассмотрим эту программу:

fn main() { regex::Regex::new(r""foo\p{glyph}bar"").unwrap(); }

И запустим её:

$ cargo run Finished dev [unoptimized + debuginfo] target(s) in 0.00s Running `target/debug/rust-panic` thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Syntax( ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ regex parse error: foo\p{glyph}bar ^^^^^^^^^ error: Unicode property not found ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ )', main.rs:4:36 note: run with `RUST_BACKTRACE=1` environment variable to display a backtrac

По сути, в определенный момент написание одного и того же сообщения expect() снова и снова для одних и тех же общих операций становится утомительным занятием. Вместо этого следует руководствоваться здравым смыслом, чтобы определить, следует ли использовать unwrap() или expect() в любой конкретной ситуации.

(Примечание: что касается примера с Regex , некоторые люди говорят, что недопустимое регулярное выражение в строковом литерале должно привести к сбою компиляции программы. На самом деле у Clippy есть линт для этого, но в целом для Regex::new невозможно сделать это с помощью средств const Rust. Если бы это было возможно, то большую часть языка Rust нужно было бы использовать внутри const контекста. Вместо этого можно было бы написать процедурный макрос, но Regex::new всё равно должен был бы существовать.)

Стоит ли установить линты против использования unwrap()?

Одним из распространенных аргументов против осмысленного подхода является то, что было бы неплохо убрать из уравнения человеческий фактор. Если кто-то предлагает добавить линт против unwrap(), то тем самым он заставляет каждого программиста писать что-то другое, кроме unwrap() . Мысль заключается в том, что если что-то усложняет этот шаг, то программисты могут более глубоко задуматься о том, может ли их код вызывать панику или нет. Необходимость писать expect() и придумывать сообщение, я согласен, задействует больше клеток мозга и, вероятно, приводит к тому, что программист более глубоко задумается о том, может ли возникнуть паника.

Хотя я не думаю, что такое возражение является совершенно необоснованным в определенных контекстах, я всё же выдвинул бы аргументы против.

Во-первых, как я уже упоминал, думаю, что во многих случаях expect() добавляет в код ненужный шум, который загромождает его и делает его более многословным. Во многих случаях либо сразу очевидно, почему unwrap() не запаникует, либо, если требуется более подробное обоснование, его скорее можно найти в комментарии, чем в сообщении expect() .

Во-вторых, unwrap() является идиоматичным. Для ясности, я делаю описательное высказывание. Я не говорю, что он должен быть идиоматичным. Я говорю, что он уже таким является, основываясь на его широком использовании как в стандартной библиотеке, так и в основных библиотеках экосистемы. Он широко распространён не только в моем собственном коде. Это свидетельствует о том, что unwrap() не вызывает проблем на практике, хотя я понимаю, что это утверждение имеет некоторые смешанные факторы.

В-третьих, есть много распространённых вещей, которые могут паниковать, при этом не требуя написания unwrap() :

Синтаксис индексации слайса. Например, slice[i] вызывает панику, когда выходит за пределы. Сообщение о панике немного лучше, чем то, что обычно можно увидеть с помощью slice.get(i).unwrap() , но всё равно это приведет к панике. Если кто-то запрещает unwrap() , потому что его легко бездумно писать, следует ли также запрещать синтаксис индексации слайса?

Переполнение в арифметических операциях в настоящее время переполняется в релизной сборке, но вызывает панику в отладочной. Не исключено, что в будущем он будет паниковать в релизной сборке. Если кто-то запрещает unwrap() из-за того, что его легко бездумно писать, следует ли также запрещать использование основных операторов, таких как + и * ? (То, что сегодня релизе нет паники, не означает, что ошибок в релизной сборке не возникает! Вполне вероятно, что арифметическое переполнение без вывода сообщения, вероятно, приведет к возникновению бага. Так почему бы не запретить его и не заставить людей использовать, например, wrapping_add и checked_add везде? Помните, мы не пытаемся избежать паники. Мы пытаемся избежать багов.)

При использовании RefCell для внутренней изменчивости его методы borrow() и borrow_mut() будут вызывать панику, если во время выполнения произойдет нарушение заимствования. Здесь применим тот же аргумент.

Аллокации сами по себе могут завершиться ошибкой, что в настоящее время приведет к прерыванию процесса. Что ещё хуже, чем паника. (Хотя, как я понимаю, желательно, чтобы неудачные аллокации вызывали панику, а не прерывание процесса.) Означает ли это, что нужно быть более осторожным и с аллокациями?

Очевидный пробел в моем аргументе — «не позволяйте совершенству быть врагом хорошего». Тот факт, что мы не можем или не будем возражать против других вещей, которые могут вызвать панику, не означает, что мы не должны пытаться улучшить ситуацию, запретив unwrap() . Но я бы сказал, что такие вещи, как синтаксис индексации слайса и арифметические операторы, достаточно распространены, поэтому запрет unwrap() не будет иметь заметного значения.

Наконец, в-четвертых, запрет unwrap() даёт некоторую ненулевую вероятность того, что вместо этого программисты начнут писать expect("""") . Или expect(""без паники"") , если expect("""") запрещено. Я уверен, что большинство людей знакомы с линтами, которые вдохновляют на такое поведение. Сколько раз вы видели комментарий к функции frob_quux , в котором говорилось: «Это frob для quux»? Этот комментарий, вероятно, существует только потому, что линтер сказал программисту поместить его туда.

Но, как я уже сказал, я понимаю, что разумные люди могут здесь не согласиться. У меня нет пуленепробиваемых аргументов против линта unwrap() . Я просто думаю, что игра не стоит свеч.

Чем же паника так хороша?

Паника — единственная причина, по которой баги часто не требуют запуска программ Rust в отладчике. Почему? Потому что многие баги приводят к панике, а паника выдаёт трассировку стека и номера строк, что является одной из самых важных вещей (но не единственной), которую предоставляет отладчик. Но их грандиозность этим не ограничивается. Если программа на Rust паникует в руках конечного пользователя, он может поделиться этим сообщением о панике и, вероятно, будет в состоянии установить RUST_BACKTRACE=1 , чтобы получить полную трассировку стека. Это легко сделать, и это особенно полезно в тех случаях, когда трудно воспроизвести ошибку

Поскольку паники очень полезны, имеет смысл использовать их везде, где это возможно:

Используйте assert! (и сопутствующие макросы) для агрессивной проверки предварительных условий и инвариантов времени выполнения. При проверке предварительных условий убедитесь, что сообщение паники относится к задокументированному предварительному условию, возможно, путем добавления пользовательского сообщения. Например, assert!(!xs.is_empty(), «ожидается, что параметр 'xs' не будет пустым») .

Используйте expect() , когда включение сообщения добавляет содержательный контекст к сообщению паники. Если метод expect() связан с предварительным условием, то важность чёткого сообщения паники возрастает.

Используйте unwrap() , когда expect() добавляет шум.

Используйте другие вещи, такие как синтаксис индексации слайса, когда недопустимый индекс указывает на ошибку в коде. (Что очень часто бывает.)

Конечно, когда это возможно, обычно предпочтительнее помещать инварианты времени выполнения в инварианты времени компиляции. Тогда не нужно беспокоиться об unwrap() или об assert! или о чём-то ещё. Инвариант поддерживается за счёт компиляции программы. Rust чрезвычайно хорошо подходит для преобразования множества инвариантов времени выполнения в инварианты времени компиляции. Более того, весь его механизм поддержания безопасности памяти в решающей степени зависит от этого.

Однако, как показано выше, либо не всегда возможно, либо не всегда желательно добавлять инварианты в систему типов. В таком случае, довольствуйтесь паникой."'https://habr.com/share/publication/723434/8cc23ab126e1c32480fe8dae7a13daae/'"['https://habr.com/share/publication/723434/8cc23ab126e1c32480fe8dae7a13daae/', 'https://habrastorage.org/getpro/habr/avatars/021/38e/e28/02138ee28f302f01e0830713b824588f.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w48/getpro/habr/avatars/021/38e/e28/02138ee28f302f01e0830713b824588f.png']"
5'723428'Telegram удалил нашего ChatGPT-бота на 27,000 пользователей без объяснения причин'Несколько недель назад мы с коллегой сделали ChatGPT-proxy бота в Telegram, который помогал в наших рабочих чатах и просто развлекал нас. Он написан на TypeScript и потрясающем фреймворке Grammy,...'https://habr.com/ru/post/723428/'"Несколько недель назад мы с коллегой сделали ChatGPT-proxy бота в Telegram, который помогал в наших рабочих чатах и просто развлекал нас. Он написан на TypeScript и потрясающем фреймворке Grammy, использует Open AI API, а именно модель gpt3.5-turbo, которая используется в оригинальном ChatGPT.

Telegram-бот ChatGPT

UPD: Telegram разбанил нашего бота

Немного о самом боте

Сам по себе бот является простым мостом между Telegram и ChatGPT, при этом он помнит предыдущие сообщения в чате, используя их в качестве контекста очередного вопроса. Кроме того, бот поддерживает групповые чаты. Причём у нас включен Privacy Mode в группах, так что бот видит только те сообщения, которые содержат команду /ask.

Бот поддерживает групповые чаты

Мы добавили много дополнительного функционала, например, боту можно отправить ссылку на любой сайт/статью, или даже YouTube-видео и задать вопрос, на который бот ответит, добавив в контекст субтитры или контент сайта, который бот получает, рендеря его в Puppeteer. В обоих случаях приходится мириться с ограничением контекста в 4096 токенов в GPT-3.5. В качестве решения нашёлся npm-пакет ts-textrank, который позволил нам суммаризировать содержимое текста до нужной длины, теряя при этом минимум информации, насколько это возможно.

Бот умеет смотреть видео на YouTube

Бот умеет ходить по ссылкам и читать статьи

Бот может общаться голосом







Также мы добавили возможность распознавания голоса через Google Cloud Speech API, но планируем перейти на более мощный Whisper от Open AI. Кстати, эту модель можно поднять хоть у себя дома на GPU, проект лежит на GitHub. Самый большой вариант этой модели, поддерживающий все языки, занимает ~10 GB видеопамяти.



Где распознавание голоса, там и синтезация. В 2023 году такие вещи делаются очень просто, достаточно установить соответствующий npm-пакет и вызвать 1 метод. Кстати, мы планируем генерировать русский голос через Yandex Speech Kit, который даёт гораздо более качественный результат, нежели Google Cloud Text To Speech API.



В итоге наш бот с точки зрения знаний всего и вся с большим отрывом заменил Siri, Алису от Яндекса и тому подобных современных голосовых помощников, и всё это в паре строчек кода, используя 3 npm пакета!

Наконец, в какой-то момент мы научили бота генерировать картинки по текстовому описанию через DALL·E. Единственная проблема состоит в том, что этот API поддерживает только английский язык. Не беда! У нас всегда есть GPT, который может принять инструкцию на русском и подробно проинструктировать своего собрата DALL·E на английском языке. Вообще, возможности применения GPT безграничные, боюсь представить что будет в будущем.

DALL·E потрясающе рисует котов и собак

Много чего ещё было добавлено в процессе. Например, настройка креативности ответов бота, набор готовых инструкций, которые задают роль бота в чате (Copilot, интервьювер, генератор бизнес идей, гопник и куча других), можно даже самому написать такую инструкцию через команду /prompt.

Deploy в production

В какой-то момент мы поняли что наш бот разлетелся по чатам наших коллег и друзей, а также по их коллегам и друзьям. Мы решили попробовать монетизировать этот проект, и начали готовить всё к запуску:

Нарисовали и сверстали красивый лендинг

Подключили платёжные системы для рекуррентных платежей

Задеплоили всю инфраструктуру в Google Cloud, используя исключительно Cloud Functons, Cloud Pub/Sub, Cloud SQL и Cloud Redis

Настроили CI/CD через GitHub Actions

Подготовили бота к большой нагрузке, выполнив Deployment Checklist в документации Grammy. Очень важно использовать вебхуки вместо long-polling'a, настроить ratelimiter, чтобы нашего бота не заспамили, а также хранение сессий в Redis.

Настроили Sentry для отслеживания runtime ошибок.

Накидали дашборд в Grafana для мониторинга основных метрик — количество запросов к Open AI API, их status code, latency, и т.д.

Добавили английский язык

Реализовали несколько платных планов с разными ограничениями и функционалом

Добились повышения лимитов биллинга в Open AI до $3200 в месяц.

В целом, инфраструктура получилась очень отказоустойчивой, минималистичной, предсказуемой, масштабируемой и относительно дешёвой (на самом деле пока что Google Cloud для нас бесплатный, поскольку там всем аккаунтам дают $300 при регистрации.)

Реклама

В первые дни мы получили около 5000 пользователей, купив пару постов в Telegram-пабликах, а также настроив таргет в яндексе. Спрос на этого бота у людей огромный. Те, кто купил подписку, пользовались им буквально каждый день.

Через неделю мы купили рекламу в Telegram-паблике на 3.7 млн. подписчиков и ~800 тысяч просмотров постов. Это принесло нам ещё 22000 пользователей.

Фиаско

Спустя чуть больше суток, бот просто пропал, будто его никогда и не существовало. В BotFather он тоже исчез. На саппорт Telegram можно не расчитывать, так как у мессенджера его, как известно, просто не существует. Сейчас мы находимся в полном непонимании что нам делать дальше, как можно вообще развивать какие-то проекты в Telegram, если в какой-то момент твой бизнес может просто исчезнуть, без каких-либо предупреждений и объяснений.

Есть подозрения, что кто-то убедил нашего бота прислать такой ответ, на который можно легко пожаловаться. Проблема в том, что мы не можем наложить никаких ограничений на ответы бота, поскольку это чёрный ящик и в данный момент существует огромное множество jailbreak-ов для обхода встроенной цензуры ChatGPT. Да, есть Moderation API, но, к сожалению, оно поддерживает только английский язык.

Послесловие

Telegram разблокировал нашего бота, но подобная ситуация может случиться с каждым. Поэтому небольшая инструкция как быть, если ваш бот в Телеграме просто испарился.



1) Немедленно обратиться в официальную поддержку ботов @BotSupport подробно описав весь кейс

2) В Телеграме, через меню перейти в раздел «Ask a Question» (Задать вопрос) и продублировать туда всю доступную информацию.

3) Продублировать информацию в чат разработчиков ботов - @BotTalk

4) Если проблему не получилось решить в течении суток-двое: прийдется искать другие пути - вроде публичных постов на Хабре, VC.

Желаем удачи всем тем, кто столкнулся с подобной проблемой. Поддержка сообщила что «Произошла ошибка на стороне Телеграма, которую уже поправили, больше не должно повториться». Вероятно, это жалобы-репорты от конкурентов, другие причины тяжело себе представить."'https://habrastorage.org/getpro/habr/upload_files/f5c/891/b5d/f5c891b5dd663b8b0b87ac25a1d6b0e4.png'"['https://habrastorage.org/r/w1560/getpro/habr/upload_files/f38/15c/559/f3815c559c8a692c8507fbd52d78caa8.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0a2/1e5/e2a/0a21e5e2a66e2923888ce14848a7a7d0.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/f45/609/cbf/f45609cbfa25fcec3a442aba967a8146.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c8f/aaa/a7f/c8faaaa7f35d8b95d95377f0a31276f1.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/f5c/891/b5d/f5c891b5dd663b8b0b87ac25a1d6b0e4.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/24b/c88/ec7/24bc88ec76e89995221506724a2dcf22.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/upload_files/f5c/891/b5d/f5c891b5dd663b8b0b87ac25a1d6b0e4.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/f3e/c9d/833/f3ec9d833189f244856ebf71329cb65f.png']"
6'723416'Мой опыт трудоустройства'Интро Привет, делюсь своим опытом трудоустройства в IT. Ссылки, примеры, без воды. Не претендую на знание лучшего совета, лишь поделюсь своим. Обязательно критикуйте меня и пишите свое мнение по...'https://habr.com/ru/post/723416/'"Интро

Привет, делюсь своим опытом трудоустройства в IT. Ссылки, примеры, без воды. Не претендую на знание лучшего совета, лишь поделюсь своим. Обязательно критикуйте меня и пишите свое мнение по каждому пункту, в споре рождается истина.

Поиск

В целом, ищите работу еще до того, как полностью расстанетесь с предыдущей. Важно не ""откуда"", а ""куда"". В пустоту уходить не стоит.

Перед поиском определитесь чего вы хотите, подробно и четко, чего определенно хочется и с чем согласен мириться в случае отсутствия. Вот несколько зацепок для размышления:

Условия работы: офис или удаленка, гибрид, фриланс, аутсорс и важно ли;

Взаимоотношения: ТК, СЗ, ИП и важно ли это в вашем случае;

Детали работы: программист игровой логики или интерфейса, художник концептов персонажей или уровней;

Доход (как правило по итогам собеседования);

Бонусы от работы: дмс, парковка, спорт, учеба, конференции.

Пример После года удаленки я точно хотел в офис и не мирился с другим, устройство по ТК РФ, ведь по сути никто никому ничего не должен в случае ГПХ или СЗ, стремление делать нечто большее, чем гиперказуалки на андроид, но точно хочу разрабатывать игровую логику, пожеланиями были парковка у офиса, спорт и дмс.

Доход стоит писать и говорить средним значением по рынку. Если ниже среднего - значит не ценишь себя, не уверен в своих знаниях, если выше - ""слишком высокие зарплатные ожидания"".

На доход отражается ваша компетентность. Оценка мидл вы или джуниор очень субъективна: мой коллега удивлялся, а точно ли мы работали в одном отделе, тогда же потенциальные работодатели ""останавливались на более опытных сотрудниках"". Не думайте о себе слишком хорошо, ведь всегда есть куда расти. Не думайте о себе слишком плохо, ведь синдром самозванца мешает жить. Не гадайте, спросите у непосредственного начальника или коллег объективную оценку ваших навыков, взгляд со стороны. Так же может помочь поиск в интернете, подсказывая что должен знать специалист в вашей области. Сухой и четкий список вопросов и развернутых ответов, которые по-хорошему знать, уметь, практиковать. Количество пробелов в знаниях и есть признак вашей компетентности. Вот пример вопросов на собес для юнити-разработчика.

В лучшем случае, не спешите и тщательно выбирайте место работы. Идите от лучшего варианта места работы, который учитывает все ваши пожелания, к худшему. Но не стоит затягивать, поиск работы должен закончится результатом, а не попыткой.

Не устраивайте себе мини отпуск или возможность сделать ремонт в квартире, это отвлекает от важного. Поиск работы - не время для развлечений и отдыха. Вот отличные советы от SuperJob.

Резюме

Как по мне, резюме обязательно для серьезно настроенного специалиста. Это сухая выжимка, которая позволяет быстро ознакомиться с кандидатом, которых у работодателя могут быть сотни. Обязательные поля:

Фото - обычное, опрятное, без акцентов, не нужно показывать на фоне как вы любите футбол или путешествия;

Контакты - телега и/или почта, плюсом телефон, соцсети;

Опыт работы - место работы и стаж, пишите сюда свои публикации;

Стек инструментов;

Чем занимался на рабочем месте - конкретные обязанности, штатные и нештатные.

Делает резюме полноценным:

Подтверждение опыта - раздел, оправдывающий нахождение навыков в списке ваших навыков;

Вне работы, но смежные вещи - публикации, участие в конкурсах, репозитории и пул реквесты (если программист);

О себе как о личности - что приносит удовольствие вне работы, хобби, волонтерство, любимые вещи в жизни. Кстати, ""Главные в жизни вещи, это не вещи"".

Резюме должно быть правдивым. Не поздно, а рано вскроется обман, ведь первыми вопросами в собеседовании будут вопросы по резюме, а от них уже отталкиваются и задают доп. вопросы.

Содержит ключевые слова. Первый, кто видит ваше резюме и ""перекладывает на стол"" более компетентному сотруднику, это рекрутер, который не обязан знать тонкости вашей профессии. Он ищет по ключевым словам. Опыт работы и стек навыков, известные проекты и организации.

Пример Вот мое резюме, уместил на А4 все необходимые пункты. На второй странице дал ссылки на все последние выпущенные проекты, над которыми работал. Критикуй! Дай знать, что стоит поправить.

Случай На одном из собеседований тех. директор спросил про инструмент, указанный в резюме. Как оказалось, мои базовые познания оказались настолько базовыми, что он вежливо посоветовал удалить ключевое слово из списка навыков.

Общение

Откликайтесь. Не сидите и не ждите когда постучат в дверь. Работа нужна прежде всего вам, а работодатель всегда иметь долю вакантных мест.

Случай Сейчас правят баллом агрегаторы для поиска работы. Я искал место работы и у работодателей отображалось, кто смотрел их профиль. Некоторых я после изучения не рассматривал как варианты. Работодатель тоже не сидит и смотрит профили специалистов, что тоже отображается, только теперь у меня. Так мы и смотрели профили друг друга, пока не завязался разговор. Выяснились подробности работы и оказалось, что это отличный вариант!

Возьмите за правило, что сопроводительное письмо в отклике на вакансию обязательно к написанию. Это отличает вас от остальных кандидатов, это хороший тон. Сопровод должен быть индивидуальным, хотя-бы частично.

Пример ""Здравствуйте. Я делаю игры на Unity и C# больше года, разрабатывал игровые механики, ИИ, инструменты для Unity, работал в команде. Хотел бы работать в команде [название организации], интересна работа в офисе, жажду самореализации, повышения навыков! Посмотрел ваш проект [название проекта], хочу участвовать в разработке. [контакты] [резюме] [портфолио]""

Вежливость во всех случаях. Независимо от этапа общения и предлагаемых условий работы, от требований и ожиданий, от результата общения.

В статье от perelesoq приведенный пример меня удивил. ""Вы - нищенская контора, а ты - дура"" - недопустимый случай, это дно специалиста.

Диаметрально противоположный пример хорошего тона и перспектив будет в случае, если вы не готовы откликнуться, написать что-то подобное: ""сейчас я трудоустроен и не готов откликнуться, но давайте оставаться на связи, если что-то поменяется"".

Переходите на ""ты"" согласовано, а не по определению, проговорите этот вопрос вслух или дождитесь от собеседника (я так и поступаю).

Подготовка к собеседованию. К нему нужно готовиться. Знайте известные и последние проекты компании, чем занимаются сейчас и вообще, простые вопросы по типу есть ли офис (если спросите об этом, но в вакансии это и так написано, значит совсем не читали вакансию).

Случай В некоторых вакансиях в самом низу описания пишут: ""Если дочитали аж до этого момента, то ответьте, пожалуйста, в сопроводительном письме, что лучше: ios или android?"".

Вопросы лояльности. На вопросы лояльности нужно отвечать правильно. Это признак того, что ты знаешь чем будешь заниматься, а не проходил мимо. Тут все просто: если компания разрабатывает мобильные приложения, не стоит говорить ""я не терплю мобилки"", если вас нанимают на должность по разработке интерфейса, не стоит говорить ""я вообще-то разработчик игровой логики, но так уж и быть"". Возможно не стоит устраиваться в компании, работа в которой - это не то, что вы искали.

Случай Я хотел делать игры и ничего из себя тогда не представлял. На моем первом собеседовании я строил деловитый вид и выдал такое: ""...но я еще не определился чем бы хотел заниматься в жизни, программы или игры"". Меня не взяли. К слову, через полгода я еще раз попросился в эту организацию, и меня взяли без вопросов. Я так горел и инициативил, что закончил испытательный срок досрочно.

Пример из книги ""Говорят, в IT много платят"". Очень советую почитать. Если вы устраиваетесь в казино, то на вопрос ""не будете ли вы себя чувствовать виноватым в случае проигрыша большой суммы какого-либо клиента казино?"" ответом будет ""нет"", иначе зачем ты сюда пришел.

Во время знакомства, собеседования, стоит пользоваться веб-камерой, если это не очная встреча. Зачем? Человек - это социальное существо, которое имеет коммуникативные навыки. Даже самый лучший специалист, который напросто не умеет разговаривать с людьми и вести себя более-менее публично, будет вне коллектива. Лучше быть внешне опрятным и показать это работодателю, не бояться показать себя, можно заблюрить фон, лучше всего не иметь посторонних шумов.

Если чего-то не знаете, то лучше так и сказать, добавив что знаете аналогичный инструмент (если это так), также собеседующий может задать наводящий вопрос.

Собеседование идет в обоих направлениях. Точно ли вы понимаете куда попадете? Оцените место работы, сотрудников и их вопросы, поинтересуйтесь деталями, посмотрите на их ответы.

Чем конкретно будете заниматься (вакансия может гласить о новом не анонсированном проекте, но по факту ищут сотрудника на поддержание существующего проекта);

Порядок дальнейших действий (выполнить ТЗ, приехать в офис, привезти документы);

Как организована работа (в разговоре может выясниться, что моделлер, сценарист и программист - это один человек);

Какие инструменты используются (а они точно знают что такое Гит, мне показалось они не понимают что такое развертка модели);

График работы;

Есть ли переработки и часто ли (аналог шутки ""сколько стоит и почему так дорого?"").

В чате стоит отвечать прямо и без отпинываний по типу ""все есть в резюме"". Это тоже показатель вежливости и заинтересованности в вакансии. Мы люди и можем упускать детали, забыть или замотаться.

Тестовое задание

Уметь оценить сложность и время выполнения задачи - это тоже навык, который тоже проверяется. Не пренебрегайте принципами, оставайтесь грамотным специалистом, выполняя ТЗ.

Случай До IT я был инженером, в каждом кабинете была табличка ""Важность или срочность работ не является причиной нарушения техники безопасности"". Вас оценивают прежде всего как специалиста, граммотного сотрудника. Но везде есть исключения, да и совсем пренебрегать сроками не стоит.

Случай Я не выполнил тестовое задание в срок, но очень старался. По жизненному правилу ""лучше вовремя и неправильно, чем поздно, но идеально"" я отдал ко времени недовыполненную работу со словами ""не все пункты выполнил, но не стал пренебрегать правилами чистого кода"". Не надеялся на успех, но через дня 3-4 мне сказали, что подробно изучили проект и в фидбэке кроме мелких замечаний написали ""код написан чисто и грамотно, многое продумано и заложено"". Меня взяли на работу. Грамотность при выполнении работы ценилась выше чем покрытие всех задач. К слову, ТЗ было очень емкое и, мое предположение, по аналогии с ЕГЭ: 100 баллов - это асимптотическая цель, которую не достичь, но нужно к этому стремиться.

Настрой

Не переживайте из-за неудач при собесе или ТЗ, это абсолютно нормально, что возьмут на работу не с первой попытки. Нормально воспринимайте критику, оценивают вас как специалиста, а не как человека, не стоит принимать близко. Выносите уроки с каждого собеса и ТЗ и что-то меняйте в поведении, подучите теорию, подтягивайте навыки. ""Если делать те же действия, ничего не меняя, глупо надеяться на иной результат"".

Будьте позитивны, но не становитесь клоуном, пусть разговор будет легким, но содержательным.

Золотая середина - это в целом мой совет, который прослеживается во всей статье.

Если пошли по верхушкам, по самым желаемым вакансиям, как в начале статьи было написано, то шанс на удачу может быть невелик. На то они и верхушки, расстраиваться из-за неудачного собеса стоит еще меньше.

Итог

Повышайте свои навыки, готовьтесь к каждому этапу трудоустройства, прокрутите в голове советы, практикуйтесь говорить уверенно и понятно, не ждите стука в дверь и не парьтесь.

Комментируй, критикуй!"'https://habr.com/share/publication/723416/6c06d6c9c46a72e32467b512c4502665/'"['https://habrastorage.org/r/w48/getpro/habr/avatars/34f/333/f8d/34f333f8d2e982d7bc856dfe16d8402a.jpg', 'https://habr.com/share/publication/723416/6c06d6c9c46a72e32467b512c4502665/', 'https://habrastorage.org/getpro/habr/avatars/34f/333/f8d/34f333f8d2e982d7bc856dfe16d8402a.jpg', 'https://mc.yandex.ru/watch/24049213']"
7'723426'Эволюция LTE и NR'В этой статье не будет дежурных фраз про увеличение спектральной эффективности и уменьшение задержки (latency). Вместо этого я расскажу про развитие технологии OFDM-MIMO и о том, какие идеи двигали...'https://habr.com/ru/post/723426/'"В этой статье не будет дежурных фраз про увеличение спектральной эффективности и уменьшение задержки (latency). Вместо этого я расскажу про развитие технологии OFDM-MIMO и о том, какие идеи двигали это развитие. При этом постараюсь обойтись без формул. Тем не менее, статья написана не совсем в духе “LTE для чайников”, но предполагает наличие у читателя базовых знаний по цифровой обработке сигналов, OFDM и MIMO.

Примерно к 2005 году разработчикам сотовой связи стало понятно, что MIMO это практический, а не теоретический, путь повышения пропускной способности. Стоит пояснить, что на профессиональном жаргоне MIMO означает возможность передачи нескольких потоков, а не использование множества антенн для создания направленного излучения (beamforming) или использование пространственных свойств радиоканала для повышения надёжности (diversity). То, что MIMO повышает пропускную способность в теории, было известно задолго до 2005 года, но та же теория объясняет, что для этого необходимы, как минимум, два условия: высокое соотношение сигнал/шум и независимость (некоррелированность) каналов между различными парами передающая-приёмная антенна. Противники MIMO, а тогда таких было довольно много, утверждали, что в реальной жизни ни одно из этих условий выполнено не будет, сигнал/шум будет низкий поскольку передавать (или принимать) хотят все и сразу, а каналы будут сильно коррелированы, потому что антенны (на одном устройстве) находятся близко друг к другу. Однако апологеты MIMO, которые, к слову, ныне считаются отцами-основателями, всё больше и больше убеждались в обратном.

Следствием этого стал повышенный интерес к технологии OFDM. Как известно, OFDM позволяет избавиться от свёртки в уравнении, которое описывает связь между переданными символами и принятым сигналом, в результате MIMO становится гораздо проще и нагляднее. Конечно, чтобы это работало, параметры OFDM должны быть подобраны соответствующим образом, но здесь мы не будем углубляться в подробности.

Итак, примерно в 2007 году заинтересованные компании, договорившись между собой, начали разработку нового стандарта связи, который с самого начала (в отличие от предыдущих стандартов) предполагал использование MIMO и был основан на OFDM. Этот новый стандарт получил название LTE.

Первым делом появилась концепция антенного порта, которая освободила приёмник от необходимости знать как устроена антенная решётка на передатчике и сколько там физических антенн. Антенный порт совсем не обязательно является физической антенной, а определён опорным сигналом (Reference Signal, сокращённо RS). Например, если один RS передаётся с двух физических антенн, то эти две физические антенны являются одним портом. И наоборот, если два разных RS передаются с одной физической антенны, то эта одна антенна представляет собой два антенных порта.

Во времена рождения LTE два порта было уже много, а четыре – очень много. Поэтому первые версии стандарта поддерживали один, два или четыре порта. Эти порты определялись так называемыми CRS (Common, они же Cell-Specific RS). Общими они были названы потому, что любое приёмное устройство может их идентифицировать в результате выполнения начальной синхронизации. На CRS были основаны шесть (из семи в первой версии LTE) различных режимов передачи (Transmission Mode, TM). Каждая TM имеет как длинное название, так и, для краткости, номер, TM1, TM2 и т. д.

ТМ1 это режим передачи с одного порта. Базовых станций, использующих этот режим, в природе не существует, ну или почти не существует.

TM2 это небезызвестная схема Аламути. О ней стоит рассказать чуть подробнее. Оригинальная статья Аламути, 1998, если не ошибаюсь, года была написана очень простым языком: если передавать вот так, и применить довольно примитивный метод приёма, получим улучшение в 3 дБ, т.е. в два раза. Схема вызвала огромный интерес, и за неё взялись корифеи (сам Аламути в те времена таковым не являлся). Одной из проблем схемы было то, что она определена для двух передающих антенн, а очень хотелось обобщить её на большее их количество. Все эти попытки закончились тем, что один из авторитетов строго доказал, что подобной схемы с размерностью больше чем два не существует. Поэтому в LTE для случая четырёх портов схема была применена в комбинации с FSTD (Frequency Shift Transmit Diversity), что представляет собой попеременное выключение поднесущих, передаваемых с определённых портов. Отметим также, что схема Аламути не является MIMO в том смысле, о котором я говорил выше, поскольку предполагает передачу только одного потока.

Прежде чем описывать следующие TM, необходимо рассказать ещё об одном принципе. Дело в том, что для эффективной работы MIMO, кроме двух уже упомянутых условий, необходимо ещё знание пространственных свойств канала на передатчике (базовой станции). Строго говоря, эти знания есть только на приёмнике. Нужно передать их на другой конец в как можно более компактном виде. Для этого в LTE был разработан механизм CSI (Channel State Information). Хорошо работающий CSI очень важен, например одной из причин, по которым в своё время не взлетел WiMAX, была плохая, если не сказать никакая, продуманность этого механизма. Принцип CSI можно пояснить следующим рисунком:

UE (User Equipment или, попросту телефон) сначала оценивает канал используя RS, а затем передаёт его пространственные характеристики в формате, определённом стандартом. Эта посылка называется CSI Report. В начальных версиях стандарта CSI Report состоял из максимум трёх чисел. Это CQI (Channel Quality Indicator), RI (Rank Indicator) и PMI (Precoding Matrix Indicator). CQI можно рассматривать как соотношение сигнал/шум, которое приёмник телефона может обеспечить. Это соотношение зависит не только от качества канала между передающими и приёмными антеннами, но и от многих других факторов, таких как число приёмных антенн, качество аналоговых цепей, и алгоритм приёма, реализованный в телефоне. Понятно, что телефоны разных производителей, и даже из разных продуктовых линеек одного производителя, будут выдавать существенно разный CQI. Таким образом, CQI в CSI Report присутствует всегда, в отличие от двух других полей, которые нужны только в режимах MIMO. RI это число пространственных потоков которые приёмник может разделить. Так же, как и CQI, RI сильно зависит от алгоритма приёмника. PMI определяет прекодер, который, по мнению UE, должна применить базовая станция. Прекодер это матрица преобразования передаваемых символов в антенные порты, размер этой матрицы – число портов на RI. Набор прекодеров фиксирован стандартом и называется кодовой книгой, а PMI это один или несколько индексов, определяющих выбор прекодера из кодовой книги.

Немного разобравшись с CSI, можно продолжить разговор о режимах передачи.

TM3 это так называемый Open Loop MIMO. Open Loop он потому, что для него не нужен PMI. Прекодер определяется рангом (RI) и устроен так, что искусственно создаёт частотную селективность, различную для разных пространственных потоков. Несколько лет с момента развёртывания LTE сетей, этот режим, благодаря своей простоте, был самым часто используемым MIMO режимом.

TM4 – Closed Loop MIMO. Как нетрудно догадаться из предыдущего описания, Closed Loop означает наличие PMI, т.е. эффективный MIMO канал, с которым предстоит работать приёмнику (телефону), определяет (точнее рекомендует) сам приёмник. В процессе эволюции коммерческих сетей LTE, этот режим обошёл TM3 по востребованности, поскольку способен обеспечивать большие скорости передачи данных.

TM5 – то же самое что TM4, но разные потоки предназначаются разным UE. Это так называемое MU-MIMO, MU означает Multi User. Предыдущие MIMO режимы, таким образом, можно назвать SU (Single User) MIMO. TM5 может работать только в идеализированных условиях, поэтому на практике не используется. Скорее, он был нужен разработчикам LTE просто чтобы задекларировать поддержку MU-MIMO.

TM6 – снова то же самое что TM4, но с ограничением в один пространственный поток. Честно говоря, никто не понял зачем разработчики сделали этот режим как отдельный, такая же как в TM6 функциональность может быть обеспечена TM4.

Следующий, и последний в первой версии LTE, режим TM7 основан на другом типе RS, так называемых UERS. UE здесь означает UE-specific. Разработан этот режим был в основном для того, чтобы поддержать уже появившиеся к тому времени базовые станции с восемью портами. Как видно, уже тогда разработчикам стало понятно, что путь использования CRS – тупиковый, поскольку не масштабируется на большее количество портов. Уже при четырёх CRS портах, расходы на CRS, т.е. занятые ими ресурсы, превышают 20% от общего числа ресурсов, и дальнейшее увеличение этих расходов было бы расточительством. UERS, в отличие от CRS, появляются только там, где есть данные. Например, если полоса системы составляет 10 МГц, а передача данных для определённого телефона осуществляется только в кусочке этой полосы, например 3 МГц, то UERS будут находится только в этом кусочке 3 МГц. Другим преимуществом UERS является то, что они прекодируются так же, как данные. В предыдущих режимах канал для демодуляции данных состоял из двух компонент: канала, соответствующего CRS, и прекодера. Теперь, при использовании UERS, телефон сразу оценивает комбинацию этих двух компонент. Причём портов на базовой станции может быть сколь угодно много, на вычислительную сложность демодулятора это никак не повлияет. Но есть и проблема: откуда же базовая станция узнает какой применить прекодер? Узнать это она может только если восходящий (UpLink, UL) и нисходящий (DownLink, DL) каналы одинаковые, по крайней мере по пространственным свойствам. Это возможно только в TDD (Time Division Duplexing), т.е. когда UL и DL находятся на одной частоте. Таким образом TM7 была разработана только для TDD, хотя в стандарте, конечно же, никаких явных указаний на это нет. Ещё одна проблема TM7 это: как (делая какие предположения) телефон должен вычислять CQI? В предыдущих режимах UE делал это зная обе компоненты (CRS канал и прекодер), теперь прекодер неизвестен. Было решено, что CQI должен вычисляться как для TM2, хотя реальное качество канала при применении TM7 должно оказываться гораздо лучше. Это означает, что на базовой станции должен быть механизм, способный оценить эту разницу. Вследствие всех этих проблем, в ТМ7 с самого начала закладывалась возможность поддержки только одного потока.

Во второй версии LTE, это был 3GPP Release-9, появилась TM8 – обобщение TM7 для MIMO. TM8 унаследовала оба недостатка TM7: возможность работы только в TDD и несоответствие CSI условиям которые возникнут при передаче данных. Тем не менее, TM8 стал первым режимом поддерживающим и SU- и MU- MIMO (с возможностью переключения межу ними “на лету”), широко применённым на практике. Это стало возможным благодаря, в первую очередь, улучшенной конструкции UERS, которая позволяла быстро, т.е. без переключения TM, менять число портов, а в случае MU позволяла UE детектировать MU интерференцию и более-менее эффективно с ней бороться.

Тем временем число портов на базовой станции продолжало расти, и этот факт необходимо было использовать не только в TDD, но и в FDD (Frequency Division Duplexing). Для этого пришлось определить ещё один новый тип RS, который был назван CSI-RS. Как следует из названия, эти RS предназначены для вычисления CSI. Как и UERS в TM7/8, CSI-RS были определены как UE-Specific. В связи с этим термин UERS был заменён на DMRS (DeModulation RS). Появился новый режим TM9, основанный на CSI-RS и DMRS. Этот режим избавился от проблем TM7/8, в то же время унаследовав их преимущества. Это произошло в Release-10, который получил метку LTE-Advanced (сокращённо LTE-A).

Наконец последний режим передачи, TM10, также известный как CoMP (Coordinative Multi-Point), был предназначен для облегчения борьбы с межсотовой интерференцией. Все предыдущие режимы были сфокусированы на внутри-сотовой интерференции, а интерференция из соседних сот рассматривалась как неизбежное зло. Конечно, вопросам “усреднения” этой последней уделялось внимание, но и только то. Теперь же появился ещё один новый тип RS, - CSI-IM. Выглядели они точно так же, как CSI-RS, но предназначались для измерения не полезного сигнала, а интерференции (IM в названии означает Interference Measurement). Вместе с этим появилась и концепция CSI процесса. Концепция эта заключалась в том, что телефону может быть назначено несколько пар CSI-RS и CSI-IM, по каждой из которых он должен слать отдельный CSI Report. Каждая такая пара, вместе с конфигурацией CSI Report, и есть CSI процесс. Это позволяло сети определить с какой из базовых станций в данный момент лучше передавать данные, и какая из них при этом будет создавать наиболее сильную интерференцию. Изначально также планировалась возможность передавать данные одному UE сразу с нескольких базовых станций. Эта функциональность является наиболее заманчивой, поскольку позволяет превратить интерференцию в полезный сигнал и таким образом сильно облегчить жизнь телефону. Однако такая совместная передача не была реализована по нескольким причинам. Главной из них было то, что задачу приёма с нескольких базовых станций сильно усложняло наличие CRS у каждой из них. Требовались продвинутые алгоритмы и, соответственно, высокая вычислительная сложность. Такие алгоритмы были реализованы некоторыми производителями, но это, конечно же, существенно сказалось на цене. В результате, TM10 не получила широкого распространения на практике, хотя статей и диссертаций на тему CoMP было написано великое множество.

Подводя итог, можно сказать что самым популярным MIMO режимом в системах LTE стал TM4, а в системах с поддержкой LTE-A – TM9.

Дальнейшее развитие LTE/LTE-A было нацелено, в первую очередь, на улучшение функциональности MU-MIMO. Вопрос с SU-MIMO был более-менее закрыт, поскольку в телефон, просто в силу его размеров, нельзя засунуть больше четырёх антенн (цифровых портов). Напротив, число портов на базовой станции всё ещё можно продолжать увеличивать. Так в LTE Release-13 CSI появилась поддержка двумерных антенных решёток (все предыдущие версии подразумевали линейные решётки). Также появились абстракции управления «лучами», формируемыми большими антенными решётками. Эта версия LTE получила метку LTE-Advanced Pro. В LTE Release-14 появились гораздо более сложная кодовая книга, позволяющая базовой станции лучше предсказывать MU интерференцию. Все эти изменения отразились, в основном, на формате и механизмах CSI. Конечно, изменялись и другие разделы стандарта, и некоторые из них – довольно сильно, но CSI, наверное, претерпел наиболее бурное развитие. Тем не менее, эволюция CSI продолжается и по сей день, уже в стандарте NR.

Как раз к появлению Release-14 всем стало понятно, что ограничения, налагаемые первыми версиями, блокируют дальнейшее развитие. Как мы видели, MIMO превратилось в M-MIMO (Massive-MIMO, т.е. MIMO c большим количеством портов), при этом стандарт обязан был сохранять обратную совместимость, т.е. поддерживать устройства Release-8, которые знать ничего не знают ни про какие UERS, CSI-RS и DMRS. Тогда было принято решение пожертвовать этой обратной совместимостью, т.е. создать новый стандарт. Этот новый стандарт получил название NR (New Radio) и метку 5G.

Как LTE c самого начала предполагал поддержку MIMO, так NR c самого начала предполагал поддержку M-MIMO. Так же как LTE, NR использовал OFDM, поскольку ничего лучше не придумали (да и не предвидится). Это означало, что многие концепции LTE можно переиспользовать, что и было сделано. Наиболее удачными из них, в контексте M-MIMO, были, как мы видели, CSI-RS и DMRS. Эти сигналы и стали основой физического уровня NR. Отпала необходимость поддержки аж десяти режимов передачи, вместо них в NR определён один единственный, по сути он является тем, что в LTE называлось TM9. Ну или TM10, как уже сказано он отличается от TM9 в основном механизмом CSI. Отпала также необходимость использования CRS, вместе с этим ушли и все проблемы, с ними связанные, т.е. большое количество занимаемых CRS ресурсов и порождаемая ими межсотовая интерференция.

Поддержка M-MIMO также позволила включить в стандарт так называемый миллиметровый диапазон, соответствующий несущим частотам 28 ГГц и выше. «Традиционный» диапазон (всё что ниже 7 ГГц) в стандарте назвали FR1 (FR означает Frequency Range), а миллиметровый – FR2. На таких высоких частотах направленное излучение не просто желательно, а необходимо из-за сильного затухания сигнала при распространении, поскольку длина волны мала. Но это же является и преимуществом. Малая длина волны означает что физические антенны тоже будут небольшими, что позволяет поставить их в телефон много, и, таким образом, делать излучение хорошо направленным. В то же время, появляется проблема надёжности управления «лучом». Поскольку «луч» теперь очень узкий, его стало относительно легко «потерять», а вместе с этим потерять и связь. Для облегчения задачи отслеживания «луча», потребовалось определить в стандарте соответствующие процедуры.

Был существенно переработан механизм CSI. Уже в LTE Release-13, CSI стал очень громоздким и неоправданно сложным, в Release-14 ситуация только усугубилась. В NR механизм CSI сделали куда более понятным и гибким, что сильно улучшило его функциональность. Появились разные типы CSI-RS, не будем их здесь перечислять, думаю, что эта статья и так уже перегружена информацией. Поясним только, что эти разные типы CSI-RS можно рассматривать как сигналы для измерения различных свойств канала, например медленно и быстро меняющихся.

В дополнение к старым, тем что использовались в LTE, появились новые параметры OFDM, в первую очередь для поддержки миллиметрового диапазона. Как нетрудно догадаться, свойства канала там существенно отличаются от тех, что имеются в FR1 (7 ГГц и ниже), следовательно нужны и другие параметры. Набор этих параметров тоже сделали гибким, что позволило в обоих диапазонах лучше адаптировать радиосети к таким условиям как размер соты и мобильность пользователей.

Очень коротко перечислим и некоторые другие нововведения. В восходящем канале, снова в дополнение к использовавшемуся в LTE SC-OFDM (SC означает Single Carrier, по-другому этот формат ещё называют DFT-s-OFDM, DFT-s это DFT-spread), появился и обычный OFDM, такой же как в нисходящем канале. Для лучшего различия с DFT-s-OFDM, обычный OFDM так же называют CP-OFDM (CP - Cyclic Prefix). Помехоустойчивый код был поменян с использовавшегося в LTE турбо-кода на LDPC (Low Density Parity Check). Это изменение тоже можно рассматривать как шаг в сторону большей гибкости и универсальности системы. Некоторые авторы книг по помехоустойчивому кодированию утверждают, что турбо-коды являются всего лишь частным случаем LDPC.

Как видим, при переходе от LTE к NR революции не произошло. В отличие от изменений, произошедших при переходе от 2G (GSM) к 3G (WCDMA), и от 3G к 4G (LTE). Те изменения были действительно революционными, менялись сами принципы, на которых строились радиосети. Сейчас же можно сказать, что NR это хорошо оптимизированная LTE. По-простому, всю плохо работающую функциональность LTE выкинули, а всю хорошо работающую – сделали более гибкой. Да, обратная совместимость потеряна, произошёл ряд существенных изменений, но все они вместе взятые на революцию не тянут. Тем не менее, случилось качественное улучшение, и, наверное, хорошо, что этого улучшения удалось добиться эволюционным путём.

Эволюция не останавливается, на момент написания этой статьи (март 2023) в 3GPP идёт обсуждение Release-18. Среди предлагаемых изменений большая часть по-прежнему направлена на улучшения поддержки MIMO. Так, например, речь идёт о том, чтобы сделать, наконец, возможной одновременную передачу одному UE с нескольких базовых станций, для чего необходим соответствующий CSI. Кроме того, в Release-18 должно увеличиться максимально возможное число пространственных потоков в MU, т.е. число «непересекающихся» DMRS портов.

На этом, пожалуй, можно закончить. Если будет интерес со стороны читателей, то в следующих статьях я могу подробнее рассказать и про OFDM, и про MIMO, и про RS, и про CSI, да много про что, из того что здесь упомянуто, можно написать отдельную статью. При желании, – даже с формулами и картинками, т.е., соответственно, с более наглядными пояснениями и глубоким анализом."'https://habr.com/share/publication/723426/098130b36b6ad910e9bbd6f000c9ae8a/'"['https://habr.com/share/publication/723426/098130b36b6ad910e9bbd6f000c9ae8a/', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/4d0/3ed/617/4d03ed617c9567b4850fcf26a1608263.png', 'https://mc.yandex.ru/watch/24049213']"
8'723410'О модифицирующих командах'На волне нынешнего хайпа про инфраструктурные платформы, наверное каждый слышал о книге Team Topologies . Я ее сейчас пересказывать не буду, поэтому если какие-то термины или рассуждения ниже вам...'https://habr.com/ru/post/723410/'"На волне нынешнего хайпа про инфраструктурные платформы, наверное каждый слышал о книге Team Topologies.

Я ее сейчас пересказывать не буду, поэтому если какие-то термины или рассуждения ниже вам окажутся непонятными я рекомендую прочитать сперва ее, а затем вернуться к моему посту.

Из всех тем, рассматриваемых в Team Topologies наиболее непонятная тема — это Enabling team, “модифицирующая” или “преобразующая” команда. Я буду использовать слово Модифицирующая Команда, потому что такой же перевод используется в Platen.

В самой книге про нее говорится многих общих слов типа:

Enabling teams have a strongly collaborative nature; they thrive to understand the problems and shortcomings of stream-aligned teams in order to provide effective guidance

или

The mission of enabling teams is to help stream-aligned teams acquire missing capabilities, usually around a specific technical or product management area

Все это хорошо, но не дает понимания о том, как эти команды строить, да и что они будут делать. (Это же в целом можно сказать и о самой книге Team Topologies — это отличная и замечательная визионерская книга, но в ней очень мало практической пользы)

Давайте попробуем разобраться.

Во первых, в данной парадигме главная задача Модифицирующей Команды — подтягивать другие команды на следующий уровень развития в некоторой области.

Во вторых, и это следует из первого — это формировать пути развития других команд.

Я здесь вижу большую проблему в том, как эти задачи вписать в саму организацию, потому что в зависимости от реализации эта самая Модифицирующая Команда может оказаться не тем, что задумывалось в Team Topologies, а например, тушильщиками пожаров, или мамкиными вытиральщиками соплей.

Чтобы разобраться с этой проблемой давайте попробуем рассмотреть путь развития некоторой продуктовой команды, когда она переходит из одного набора компетенций и поставленных практик Alpha, к некоторому более широкому или глубокому набору практик Beta, и далее к еще более прокачанному варианту Charlie.

Здесь команда может переходить на следующий уровень как сама, так и с помощью Модифицирующей Команды.

Кому как, а мне это больше всего напоминает путь артефакта по CI/CD пайплайну.

Соответственно, можно представить способ взаимодействия Модифицирующих Команд с Потокоориентированными не в виде каких-то невнятных пятен как говорится в книге, а в виде вполне конкретной схемы, которую можно обсуждать.

А самое главное — это уже выглядит похоже на схему любой организации, т.е. на процесс преобразования неких объектов поступающих к ней на вход в некие выходы.

В данном случае на вход поступают “необученные” команды, а на выходе получаем “обученные”.

По факту, у нас получилась схема очень похожая на схему Платформы, только по пайплайну движутся не фичи, а сами продуктовые команды. И пайплайн этот не технический, а организационный.

Если взглянуть на дело таким образом, вопросы которые мы задаем будут уже не абстрактными вопросами вида “что нам с этим всем вообще делать”, а уже более конкретными и понятными, ответы на которые можно превратить в набор вполне конкретных решений и шагов:

Какой будет путь развития команд? Почему именно такой?

Одинаковым ли он будет для всех команд, или же будет разным? Почему?

Из каких промежуточных состояний он будет состоять?

Нужна ли для перехода на следующую стадию отдельная команда, или же будет достаточно видеоролика на wiki и примера шаблона новой практики (что-то типа “Thin Enabling Platform”)?

Обязательно ли командам проходить все эти состояния, или же можно пройти их выборочно?

Для каждой команды будет только один путь развития, или же будет несколько параллельных путей в различных компетенциях (например, пути развития в devops, в тестировании, в agile-процессах)?

Что будет меняться для команды при движении по этому пути?

Зачем командам вообще двигаться по этому пути?

Кто и каким образом будет их по этому пути двигать?

Останется ли при таком видении роль для самой Модифицирующей Команды или же эта команда превратится в несколько команд поменьше? Мне кажется, это не столь важно если будут выполняться цели, которые ставит перед собой организация.

А как считаете вы?"'https://habrastorage.org/getpro/habr/upload_files/3bb/74a/6cf/3bb74a6cf28e0fd54042c39daae9e4fe.png'"['https://habrastorage.org/r/w1560/getpro/habr/upload_files/3bb/74a/6cf/3bb74a6cf28e0fd54042c39daae9e4fe.png', 'https://habrastorage.org/getpro/habr/avatars/69a/d84/c1c/69ad84c1c7e14162ff9575e4e8494817.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/b27/223/66e/b2722366ee8853c8065c263d795001cb.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w48/getpro/habr/avatars/69a/d84/c1c/69ad84c1c7e14162ff9575e4e8494817.jpg', 'https://habrastorage.org/getpro/habr/upload_files/3bb/74a/6cf/3bb74a6cf28e0fd54042c39daae9e4fe.png']"
9'723358'Концепт-кары. Пыль в глаза или производственная необходимость?'Предлагаю вашему вниманию не претендующую на истину в последней инстанции статью, посвященную концепт-карам . Уверен, многие из вас знакомы с этим понятием. Я же ставлю себе целью в пределах статьи...'https://habr.com/ru/post/723358/'"Предлагаю вашему вниманию не претендующую на истину в последней инстанции статью, посвященную концепт-карам. Уверен, многие из вас знакомы с этим понятием. Я же ставлю себе целью в пределах статьи расширить ваши познания, напомнить забытое, и может быть открыть неизведанное.

Терминология

С ней не все так просто. Помимо concept car существует ещё show car и dream car, которые появились раньше (в 1920-е годы) и означают в примерно одно и тоже. Такое нередко бывает в активно развивающейся области, когда в разных странах или даже в разных компаниях одной страны придумывают разные названия для объекта или явления. Это может случиться и сейчас, в мире продвинутых информационных технологий.

В отличие от любого другого автомобиля, show car (далее просто шоу-кар) никогда не ставится в серийное производство. Это своего рода произведение искусства. Уникальное авто, предназначенное для показа на выставках, которое создается либо полностью с нуля, либо на базе уже существующих моделей. Во втором случае отличий может быть немного: одно-два свежих технических решения, которые можно пощупать, улучшенная эргономика или необычный стиль окраски. Звучит не сложно, но это будет продумано и реализовано командой дизайнеров и инженеров, что качественно отделяет их от кастомных модификаций серийных авто, выполненных в автосервисе или гараже. Представленный на выставке и ставший популярным шоу-кар может стать основой для новой модели, которая попадет на рынок.

Существует еще один термин, который по смыслу находится где-то рядом с концепт-каром - прототип. Он определяет другое направление проработки перспективного авто, а именно его функциональные характеристики. Если для шоу-кара не важно, какая у него начинка, то прототип - это набор новых технических решений. Для него в свою очередь не имеет значения покрытие руля или цвет кузова. Двигатель, подвеска, трансмиссия, система охлаждения, электрика, рулевая система и прочее, что мы не видим, не подняв хотя бы крышки капота, - все это отрабатывается сначала на прототипе.

Во время ходовых испытаний на прототипы наносят специальный камуфляж, размывающий их очертания, скрывающий детали дизайна

Концепт-кар, на мой взгляд, находится на стыке двух терминов. Он так же, как и все шоу-кары, предназначен в первую очередь для демонстрации новых технических, визуальных, эргономических решений, но в зависимости от ситуации и целей, может быть и полнофункциональным прототипом со всеми вытекающими возможностями. Демонстрацией их широкой публике фирма-изготовитель старается достичь следующих целей:

Привлечь внимание к своей продукции . Что может быть лучшей рекламой, чем сделать какую-нибудь вундервафлю, которую хотел бы иметь каждый? Получить обратную связь от покупателей. Это важно для оценки потенциальной прибыли от применения тех или иных новшеств. Привлечь инвестиции. Это вытекает из первого пункта. Если концепт-кар будет одновременно и прорывным, и технически реализуемым, это привлечет инвесторов, желающих получить прибыли от будущих продаж.

И сейчас сложно представить на дорогах такой “утюжок”, как Honda Fuyajo, показанный на Токийском автошоу 1999 года

Классификация концепт-каров

В зависимости от степени технической проработки, все концепт-кары можно разделить на следующие группы:

Нефункциональные. В них важна только визуальная часть, полёт дизайнерской мысли, целью которого является “вау-эффект”. Никто всерьез не задумывается, как эта штука будет ездить по дорогам города или за его пределами. Полуфункциональные. Этот вариант является упрощенным прототипом и отличным решением для автомобильных стартапов. Перед ним никто не ставит задач пройти полноценные испытания. Сделать несколько кругов по автодрому на небольшой скорости, показать потенциальным заказчикам и инвесторам, как он будет смотреться в естественной среде обитания, пустить немного пыли в глаза каким-то оригинальными, но не слишком вычурными визуальными решениями - вот его основные задачи. В дальнейшем такой концепт-кар ждет серьезная переработка: что-то выкинут, что-то добавят. Лоска поубавится, но он станет рабочим. Полностью функциональные концепт-кары. Создать такое могут только крупные фирмы, имеющие свободные деньги для таких шедевров технической и дизайнерской мысли. Эти уникальные машины могут принять участие в какой-то гонке со специфическими условиями (например, по дну высохшего соляного озера) или стать частью коллекции какого-нибудь миллионера. В очень редких случаях они становятся головными образцами серийных моделей, но и там не обходится без изменений в угоду оптимизации производства.

Звезда фильма “Миссия невыполнима: Протокол Фантом” концепт-кар BMW i8 ...

... и его серийный брат победнее

Добавлю, что один проект может как пройти пройти все стадии с первой по третьей, так и начать с любой из них. Отмечу еще, что первый и второй вариант развязывают руки разработчикам, и в ход идут различные “грязные трюки”. Следите за руками. Закинуть в багажник сервер с пачкой GeForce для демонстрации продвинутого ADAS - почему бы и нет. Реализовать критически важные функции на Arduino, напечатать детали на 3D-принтере, использовать NUC в качестве мозга автомобиля, соединять модули обычным патчкордом, подключать периферию по USB - тут всё дозволено. Не удалось довести функцию распознавания голоса до приемлемого качества - не беда, посадите человека. Боитесь, что при автономном вождении авто укатит в толпу зрителей - замените электронные мозги на удалённого водителя. Главная цель - продемонстрировать идею.

Заключение

Подведу итог, ответив на вопрос из заголовка: очевидно, что концепт-кар - это неотъемлемая часть современной разработки. Даже самые безумные модели преследуют весьма практичные цели: привлечь внимание и инвестиции, которые в свою очередь помогут разработать и поставить на поток производство более реалистичных авто.

В дальнейшем хочу сделать разбор конкретных примеров концептов."'https://habrastorage.org/getpro/habr/upload_files/791/50c/e2b/79150ce2b081a0b732eb1eff57129ff2.png'"['https://habrastorage.org/r/w780q1/getpro/habr/upload_files/773/a2a/d42/773a2ad420699a9820bcf16a3cdc9d0a.jpeg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/791/50c/e2b/79150ce2b081a0b732eb1eff57129ff2.png', 'https://habrastorage.org/getpro/habr/company/7f9/654/8d3/7f96548d381ccd53f24ac19d4cd9698f.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/ab9/4c4/528/ab94c4528aa53b10564e5c86a969eda9.jpeg', 'https://habrastorage.org/getpro/habr/upload_files/791/50c/e2b/79150ce2b081a0b732eb1eff57129ff2.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/252/81f/934/25281f934535f5838af78624d50e49c0.jpeg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/566/b80/741/566b807414ced17fb19fb3b59a49d5c7.jpeg', 'https://mc.yandex.ru/watch/24049213']"
10'723412'Стартап в Соло. Часть 4: техническая реализация'Содержание всех статей Стартап в соло. Часть 1: текущие показатели Стартап в соло. Часть 2: идея и первая версия Стартап в соло. Часть 3: упрощаем продукт Стартап в соло. Часть 4: техническая...'https://habr.com/ru/post/723412/'"Содержание всех статей

Содержание

О чей пойдет речь

В этой статье хочу рассказать, как технически устроен мой Telegram чат для сайта , из каких компонентов состоит и с какими подводными камнями я сталкивался.

Может сложиться впечатление, что чат для сайта - это простое приложение. На самом деле, зависит от стадии развития проекта. Когда пет-проект превращается именно в IT продукт с платящими пользователями, резко возрастают требования к качеству.

Даже при 100 активных виджетах появляются нетривиальные задачи: и контроль нагрузки, и оптимизация отправки сообщений в Telegram (с его ограничениями), и администрирование пользователей, и контроль оплат. Дополнительно появляются проблемы в виде всяких говнюков DDOS атак, XSS и разных попыток поломать приложение.

В результате чат превращается во вполне себе ощутимую систему c кучей компонентов и всевозможных защит. Причем проект разрастается даже всего за год работы в очень медленном режиме.

Архитектура

Концептуально архитектура чата выглядит как на диаграмме ниже.



Уточнения:

Указаны только основные библиотеки и фреймворки, маленькие не указаны.

И клиентская часть (SSR), и серверная (API) работает в многопроцесcном режиме.

Пока что всё находится на одном сервере, так как запас по лимиту вертикального масштабирования еще довольно большой. Но заранее есть основа под разнесение каждого компонента на разные серверы.

Архитектура проекта

Для сравнения, архитектура MVP Архитектура первой версии

В первой статье я говорил кратко про все компоненты выше, но расскажу еще раз (слева направо):

DDOS-защита и CDN



Использую DDOS-Guard (насколько я знаю, они самые крупные в СНГ после Cloudflare). Недорого, удобно. В дополнение на уровне Nginx и на уровне API есть “локальная” защита. Срабатывает чуть быстрее в некритичных случаях.

Down detector

Самодельная программа, которая находится на другом сервере. Проверяет, доступен ли сайт, виджет и API. В случае, если что-то не так, мне в Telegram прилетает уведомление.



Вот так выглядит чат с оповещениями:

Сюда приходят оповещения о поломках

Я добавил в чат еще трех человек, которые практически не пересекаются по свои биоритмам. Следовательно, в любое время суток хоть кто-то увидит сообщение, если я сплю или занят, и позвонят мне.

Контейнеры и сборка

Docker + Docker Compose. Потенциально каждый из компонентов может быть спокойно разнесет каждый на свой сервер в случае необходимости (но в ближайшие годы я ее не вижу).

Reverse proxy и SSL

Nginx. Лично для меня самое удобное и производительное. Легко настраивается для сокетов, легко настраивается под провайдера DDOS защиты, быстро раздает статику.

Сайт и личный кабинет пользователя

Основная задача сайта, после хорошего пользовательского опыта - это удовлетворят требованиям поисков для продвижения в SEO выдаче. Следовательно, необходим SSR и быстрая отрисовка. Здесь также находится личный кабинет пользователя и прием платежей.



Для защиты от ботов при регистрации используется каптча от Яндекса. Бесплатно, интеграция стандартная за 30 минут.



Технологии: TypeScript, NextJS (серверный рендеринг) + React, cluster mode для NextJS с одни процессом на одно ядро. CSS библиотеки не используются, чтобы быстрее грузился сайт, ограничиваюсь React CSS Module.

Админка с аналитикой и менеджментом пользователей

Исторически сложилось, что это отдельный фронт. Здесь у меня просмотр логов, пользователей, статистики и т.д.



Технологии: TypeScript, React, Bootstrap 4.



Выглядит примерно так:

Просмотр пользователей

Для входа администратора в аккаунт пользователя есть возможность копировать прямую ссылку с токеном для входа. Копирую через кнопку, вставляю в инкогнито и оказываюсь в личном кабинете пользователя. Итого, вход за 5 секунд.

Это оказалась необходимая функция на начальном этапе, чтобы с точки зрения пользователя смотреть, какие виджеты созданы и как настроены. Иначе было очень долго оказывать техническую поддержку, так как на каждый чих приходилось писать SQL запрос.

Отдельно уточню про логи и ошибки:

Логи для важных функций пишутся прямо в БД с ограниченным временем и объемом хранения.

Критичные ошибки (с платежной системой, с API Telegram’a) прилетают мне сразу в Telegram.

На отдельном сервере у меня стоит downdetector, чтобы сразу среагировать, если сайт, виджет или API недоступны.

Виджет для сайта

Собственно то, что и является конечным продуктом для клиента. Весь код компилируется в один .js файл, который клиенты вставляют на свой сайт.



Технологии: TypeScript, PreactJS, SocketIO. Особо добавить нечего.

Серверная часть с API

Здесь сосредоточена вся логика. Ее довольно много, но в детали углубляться смысла нет. Обычное приложение со своими нюансами.



Тестами покрыто ~5%-10% серверной части. Пет-проект все-таки 🙂. Покрыл только ключевые компоненты: взаимодействие с Telegram, взаимодействие с платежными системами и стресс-тест.



Технологии: TypeScript, NodeJS + NestJS, SocketIO, PM2 (менеджмент процессов), Jest (unit тесты) + Supertest (E2E тесты).

База данных

PostgreSQL 14. Не MySQL, потому что нынче проблемы с Oracle, мне более спокойно со 100% open source’ом. Не MariaDB, потому что PostgreSQL популярнее, в среднем быстрее, да и никогда не работал с ней.

Откровенно говоря, я еще не сталкивался с такими нагрузками на реляционную БД, где действительно был бы критичным выбор между MySQL или PostgreSQL, и при этом не нужно было смотреть в сторону альтернативных NoSQL баз.

Пересказать теоретические статьи на тему ""PostgreSQL MySQL performance comparison"" я могу, но вот в жизни еще не сталкивался с такими вопросами, где это имело бы значение. Поэтому выбор был по принципу ""что популярнее, удобнее и с чем давно работаю"".

Резервные копии

Делаются несколько раз в день стандартными средствами от FirstVDS + стандартным pg_dump + zip. Проверку восстановления из бекапов провожу примерно раз в месяц.



Кто не знает, довольно частая ситуация, когда бекапы настроили, вроде всё делается, а во время проблем оказывается, что или бекапы не такие, или восстановить нельзя.

Брокер сообщений и in-memory key-value хранилище

Redis. Не RabbitMQ для сообщений, потому что конкретно под этот проект базового механизма pub/sub в Redis хватает с головой. Учитывая, что и key-value, и брокинг в одном месте - выбрал Redis.



Тут нужно уточнение про виджет и Redis. Они взаимосвязаны.



Виджет подключается к серверу по сокетам. Так сообщения из Telegram отображаются быстрее, сервер не грузится лишний раз из-за long pooling’a.



Так как API запущено в несколько процессов (с разными зонами памяти), сокеты имеют свойство подключаться к разным процессам. Telegram доставляет данные так же в разные процессы. В результате процесс сокета и процесс с ответом от Telegram’a имеют свойство не сходится.



Чтобы их сопоставить, используется механизм publisher и subscriber в Redis. И сокет, и слушатель Telegram ответов подписываются на прослушивание ответов по своим ID. Как только приходит ответ от Telegram, Redis прокидывает сообщение в нужный сокет.



Дополнительно Redis используется для debounc’a, приоритизирования сообщений в Telegram и немного помогает с превентивной DDOS защитой.

Глобально с “концептуальной стороны” архитектура выглядит так. Далее расскажу про детали специфические для этого проекта.

Зачем оптимизировать виджет?

В мире веба существуют показатели Web Vitals. Они измеряются с помощью Google Page Speed Insights (на самом деле не совсем так, но неважно). Пример как раз моего сайта:

Показатели Google Page Speed для Telegram Feedback

Любой скрипт, компонент, лишняя картинка или виджет тормозят сайт. Показатели падают, пробиться в SEO выдачу становится сложнее. А это одна из основных задач всех сайтов. При том, что практически каждый сайт обвешан Google Analytics, Яндекс Метрикой, медленными скрипами и разными CSS библиотеками.

У меня стояла задача сделать виджет насколько быстрым и маленьким (в плане скорости загрузки на сайт), чтобы он не влиял или почти не влиял на скорость. Если на этапе MVP виджет был более 500кб, включал несколько жирных библиотек и тонну CSS’a - после MVP это стало недопустимо.

Как я оптимизировал виджет

Делал я это в 4 шага.

(1) Вставляем SVG иконки в bundle.



Если раньше иконка грузилась с помощью тега:



<img src=” https://telegram-feedback.com/images/arrow.svg ” />



Теперь все иконки в виджете имеют формат:

Использование изображений в виджете

Это позволяет обратиться к серверу один раз, получив скрипт и картинки за раз, и уменьшить задержку прогрузки страницы, а не отправить еще несколько запросов для запроса картинок.

(2) Заменяем ReactJS на PreactJS

React в сборке весит ~40 Кб. Меняем его на похожую (а во многих случаях аналогичную библиотеку) PreactJS, которая весит 3 Кб. Функционал остается, вес меньше.



Уточнение: в теории, можно написать виджет и на чистом JS. Но это будет намного более дорого с точки зрения времени (напомню, для меня это все-таки пет-проект в свободное время, которого мало) и, скорее всего, я напишу больше кода для выборки элементов, чем 3 Кб.

(3) Удаляем лишние библиотеки

Точно не вспомню, какие именно библиотеки я использовал, но точно помню, что удобно было использовать styled-components для динамического CSS’a. Пришлось удалять вообще все библиотеки, кроме одной - SocketIO.



Вообще, сокеты есть в стандартном API браузера, но SocketIO слишком удобно использовать и эта библиотека сильно экономит время. Единственное, что мне было слишком больно удалять.

(4) Удаляем лишний CSS и JS

~70% кода виджета - это мой CSS и JS. В самом начале я сделал предустановленные цветовые темы и на каждую тему был свой CSS файл по ~10 Кб. К тому же, был генератор фильтров для SVG иконок (чтобы закрасить иконку, нужно применить к ней фильтр, а до этого его сгенерировать).



CSS удалил, фильтры теперь генерируются на сервере при создании или сохранении виджета.



Вот так настраивается цвет виджета со стороны пользователя:

Ручная настройка дизайна виджета

Вот так генерируются CSS фильтры для заданных HEX цветов (раньше это было в виджете):

Генерация цветового фильтра для SVG изображения

Класс, отвечающий за генерацию фильтра

Уточню, код скопипастил со StackOverflow и не до конца понимаю, как эти цвета генерируются с точки зрения пересечения цветов. Зато честно и работает.

Теперь виджет весит ~150Кб и это самый маленький результат среди всех виджетов, которые я встречал (а я искал). В мобильной версии скорость сайта падает от 1% до 3%. Это в несколько раз лучше, чем скрипт Яндекс Метрик (скрипт у них меньше весит, что круто, но имеет намного больше бизнес-логики).

В перспективе уменьшу размер виджета еще сильнее и за рамки 1% потери скорости загрузки страницы выходить не буду.

Когда-то.

С какими атаками и проблемами сталкивался проект

Перечислю, как пытались ломать сайт и виджет.

XSS атаки, вставки гадости в формы



Результат: получилось через сообщения пробросить скрипт в панель администратора (причем это был пользователь с Хабра).



Однако сейчас абсолютно весь текст обязательно экранируется, все запросы экранируются, никаких запросов в БД с необработанным вводом от пользователя (хотя их и не было).

DOS с одного компьютера



Результат: не получилось. Изначально была DDOS защита на уровне API, потом появилась на уровне Nginx’a, а потом подключил DDOS Guard.

Слабый DDOS



Результат: не получилось. К тому моменту всё работало в кластерном режиме (и фронт, и сервер), были ограничения по скорости запросов от Nginx и со стороны API.

Загрузить память сервера картинками



Результат: почти получилось, случайно заметил. Какой-то говнюк нехороший человек начал грузить на сервер картинки весом 50 Мб с медленной периодичностью. Возможно даже вручную. Я заметил, что за пару часов память выросла на ~10Гб. Начал разбираться, нашел проблему.



Сейчас на размер картинок стоит ограничение. Если даже маленькими картинками пытаются забить память - предупреждаю клиента, что его пытаются сломать и отключаю загрузку картинок + чищу картинки на какое-то время.



Идея загрузки картинок мне изначально не нравилась. Или память севера забивается, или платный CDN нужен. Однако клиенты очень просили, пришлось сделать. Сейчас функция есть, но за попытками забить память очень пристально следит целый ряд защит.



На самом деле, память так конечно фиг забьешь. И диск большой, и защит понаставил. Да и в планах перейти на CDN от Selectel’a. Но всё равно лично мне функция с картинками не нравится 🙂.

Попытки регистрироваться много раз



Результат: немного получилось подпортить мне жизнь. Больше на статистику регистраций я не опираюсь, уведомления о регистрациях выключил. На всякий случай поставил каптчу (чего-то забыл о ней с самого начала).

Подобрать пароль к PostgreSQL



За эту ошибку мне очень стыдно. Опытный разработчик, про закрытие портов и сложные пароли знаю. А так облажался. Очень стыдно… Просто детский сад.



В первые несколько месяцев проекта мне нужно было подключиться к БД с локального компьютера, чтобы поделать выборки данных. Я открыл порт PostgreSQL во внешний мир, поковырялся вечерок и забыл, что порт открыт.



Спустя день я увидел, что загрузка сервера всё время 100% из-за процесса pg. Закрыл порт - не помогло. Перезагрузка тоже. Начал копать дальше и оказалось, что я оставил стандартный пароль на базе 🤦‍♂️. Естественно, бот нашел базу, пароль подошел и у него вышло разгруляться. На тот момент база была не в Docker’e, кстати.



В общем пришлось пересоздавать базу и перенастраивать роли, закрывать нормальным паролем. На всякий случай восстановился из бекапа, который был до открытия портов. Пароли пользователей, разумеется, были захешированы.



Вроде ничего страшного не случилось, но ЧСВ понизилось. Мораль: серьезные пароли, никаких портов во внешний мир (даже если так удобнее), аккуратно с настройками. Ну а для удобства поставил себе графическую оболочку XFCE (всегда ее любил) и PgAdmin, ковыряюсь в базе только по VNC .

Боты с подбором форм



Ну это классика с которой сталкиваются все сайты поголовно. Боты бегают по интернету и пытаются подобрать пароли к WordPress’ам, CMS’кам и т.д. У меня API свое, такое не угрожает.

Школьники, тролли и арабы



Не техническая проблема, но раздражает. Разные говнюки заходят на сайт, пишут в чат, отвлекают внимание, зачем-то кидают фотографии арабских женщин.



В мыслях есть когда-то сделать автоматическую блокировку при появлении мата или порнографического материала от посетителя (например, с помощью нейронки от вк ).



Но тоже когда-нибудь.

Про ограничения Telegram

Клиенты меня часто спрашивают, как я обхожу ограничения Telegram. Кто не знает, у Telegram ботов есть лимиты .



Тут скажу две вещи:



1. Никак. Я с ними сосуществую и играю по правилам, а не обхожу.



2. Использую дебоунсер с приоритезацией сообщений и потом планирую использовать разных ботов для распределения нагрузки.



Как это работает:



Всем сообщениям и действиям проставляется приоритет. Например, сообщение от пользователя имеет максимальный приоритет и будет доставлено в чат в первую очередь. Показ разных действий (например, кнопка ""показать, что отвечаю) имеют средний приоритет.



Если в очереди (в рамках 5 секунд, например) стоит 3 сообщения пользователя и действие для кнопки “показать, что я отвечаю”:

Приоритет действий

Я в первую очередь отправлю сначала 3 сообщения, а уже только потом покажу кнопки с функциями. Эта приоритезация очень классно работает, когда в очереди стоят сотни сообщений в десятки чатов.

Уточню: такие ситуации случаются крайне-крайне редко (судя по логам). Бывают сайты, у которых проходимость 100 000 посетителей в день и им часто пишет параллельно 5-10 пользователей.

Для таких сайтов, к сожалению, в целом Telegram не подойдет и у них сообщения действительно будут тормозить. В таком случае я говорю прямо, что со мной в рамках их задач работать будет неудобно.

Есть еще ограничение на отправку 40 сообщений в секунду во все чаты на одного бота. До этого ограничения я еще не добрался даже приблизительно. Однако я понимаю, что через какое-то время его достигну.

На этот случай у меня уже готов код, чтобы менять ботов. Если сейчас в системе есть один бот и пользователю нужно писать или добавлять его, в будущем этих ботов будет 2-5-10 или сколько более. Просто система будет выбирать наименее загруженного бота и подключать его к новым сайтам.

Послесловие

За почти год проект разросся. Даже несмотря на то, что у меня редко выходило выделять на него больше 10-20 часов в неделю. А частенько и не выходило 🙂.

У любого IT-проекта, которым действительно пользуются пользователи, всегда много нюансов. Приходится всё систематизировать, защищать, оптимизировать и делать надежным. Вот и у меня так вышло.

Какая мораль у этого всего не знаю. Рассказал просто, чтобы поделиться (и лишний раз рассказать потенциальным пользователям про проект, разумеется). Наверное, мораль в том, что если хочешь сделать даже маленький IT продукт - будь готов к сложностям и имей необходимые навыки.

Вот."'https://habrastorage.org/getpro/habr/upload_files/79c/0f2/b5a/79c0f2b5a2fb074306eaad4a394d18ed.jpg'"['https://habrastorage.org/r/w1560/getpro/habr/upload_files/4a7/8c3/d6b/4a78c3d6bd93d86064fc81317e231646.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/dfb/b65/04e/dfbb6504e33dea4653df3751ef9d9b92.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/e4e/cd7/147/e4ecd7147b44e24b7276bbb7a2621e7a.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/681/452/15f/68145215f20f4f007556b8df4e0c17af.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/73d/268/5d6/73d2685d63016dc388f9963cbe21b35e.png', 'https://habrastorage.org/getpro/habr/upload_files/79c/0f2/b5a/79c0f2b5a2fb074306eaad4a394d18ed.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/57b/053/2dd/57b0532dd0034bb727d0b55582d0bded.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c10/f1d/067/c10f1d067fa4ed85a34a9a446e4794f7.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/1f1/764/df9/1f1764df952290dd766c0be4b7b6fbe3.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/5ce/8ae/78f/5ce8ae78ff2c1a901796030bb5ae4fb6.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/6be/ece/9f6/6beece9f61e7180c1f98965455abcfc6.png']"
11'723404'Сообразим на троих. Троичные компьютеры'В повседневной жизни мы используем десятичную систему счисления. Почему именно её — это вопрос отдельный. В конце концов, существуют системы с основанием 12 (по фалангам пальцев без большого), 5...'https://habr.com/ru/post/723404/'"— Какой ужасный сон! Повсюду были нули и единицы. И мне показалось, что я увидел двойку!

— Бендер, это просто сон. Двоек не существует.

Ну, или как-то так

Собственно, «Сетунь». Достаточно компактна по сравнению с конкурентами

В повседневной жизни мы используем десятичную систему счисления. Почему именно её — это вопрос отдельный. В конце концов, существуют системы с основанием 12 (по фалангам пальцев без большого), 5 (пальцы на одной руке), 20, 60 и так далее. В компьютерах всё несколько проще — там (можно даже сказать, «Традиционно») используется двоичная система, как самая лёгкая для воплощения. Есть ток — нету тока. Есть отверстие в перфокарте — нет отверстия. Ноль или единица. Короче говоря, «да» или «нет» — третьего не дано. А что будет, если дать? Об этом и поговорим. Собственно, существуют две возможности «дать» это самое третье: в виде «0, 1, 2» или в виде «-1, 0, 1». Первая система называется несимметричной, вторая — симметричной. Само по себе введение троичной системы счисления выгодно тем, что экономичность хранения данных для каждого разряда выше, чем для любой другой системы счисления. Связано это с тем, что, как говорится, «God counts by E», и наиболее экономичной является система с основанием, равным числу Эйлера (доказательство ищите на стр. 37 ), а тройка ближе к Е, чем двойка.Но это ещё не всё — если несимметричная система является просто «расширением» двоичной, позволяя хранить в одной ячейке больше информации, то у симметричной системы выгод гораздо больше.Одна из таких выгод — это появление значения «0», то есть «не определено». Как правило, 0 передаёт отсутствие значения, а 1 и -1 (иногда вместо цифр используются «+» и «-») — двоичное «да» и «нет». Чем это может быть выгодно? Вообще, зависит от того, как именно задана работа логики. Например, двоичный компьютер столкнувшись с парадоксальным запросом в духе «Второе утверждение истинно — первое утверждение ложно» впадёт в ступор. Троичный компьютер в ответ может просто выдать 0 — он не ответит, но избежит ответа. Или 1 — если работает на «логике парадокса». Ну, и помимо этого многие вопросы можно подвергнуть улучшению — например, не «наличие/отсутствие», а «недостаток/норма/избыток».Выгода вторая — отрицательные значения. В двоичной системе, чтобы показать, что число имеет отрицательное значение, нужен дополнительный знак. В троичной системе если ведущий разряд числа отрицателен, то и число отрицательно. Смена знака с положительного на отрицательный и обратно достигается инвертированием всех его разрядов (что самое интересное, советский троичный компьютер «Сетунь» воспринимал «инвертирование» буквально — отрицательные числа печатались вверх ногами).Из предыдущих двух пунктов выходит третий — увеличенная скорость вычислений при пониженном объёме занимаемой памяти. В двоичной системе нужно два разряда, чтобы показать знак числа, а вот в троичной системе нужен только один разряд (собственно, само число). Далее — сложение, самая часто выполняемая операция, которую сильно тормозят переносы из разряда в разряд — в случае двоичной системы они происходят в 50 % случаев, а в троичной (симметричной) системе — в 8 случаях из 27, т. е., примерно в 29,6% случаев. Большая скорость и меньшее количество элементов повышают быстродействие троичной машины примерно в 1,6 раза, и, соответственно, уменьшают энергопотребление.Казалось бы, почему такое инженерное «wunderwaffe» не применяется повсеместно? На то есть несколько причин. Самая основная — их особенно-то никто и не разрабатывал. Самым известным примером троичного компьютера является советская «Сетунь» 50-х годов разработки. Уникальна она даже не потому, что является первой троичной ЭВМ (но не первой троичной вычислительной машиной ), а потому, что сотрудники лаборатории ЭВМ МГУ собирали её буквально на коленке и из подручных материалов, потому что:…мы должны были для МГУ получить машину М-2 , которую сделали в лаборатории Брука. Но получилась неувязочка. На выборах академиков Сергей Львович Соболев — наш руководитель — проголосовал не за Брука, а за Лебедева. Брук обиделся и машину не дал.Троичная счётная машина Фаулера — первый троичный калькулятор:Помимо обычной «Сетуни» была также разработана «Сетунь-70» — принципиально новая машина со стеками команд и операндов (разработана, что характерно, к 100-летию со дня рождения Ленина). Ни оригинальная, ни 70-я «Сетуни» в большую серию не пошли — оригинал по не до конца понятным причинам весьма прозаично «задушили», а 70-я была единичным экземпляром. А помимо «Сетуни»… не было ничего. Американцы одно время экспериментировали с троичной логикой, и даже добились некоторого прогресса, но до строительства полноценных ЭВМ дело не дошло (максимум — эмулятор троичной логики «Ternac» для двоичной машины, который был написан на FORTRAN'е). В Канаде в 80-х был разработан чип ROM на основе несимметричной троичной логики (похожий чип можно и создать самостоятельно). В 90-х был разработан троичный язык программирования TriINTERCAL — опять же, на основе несимметричной троичной логики. Какие-то разработки ведутся до сих пор, хотя и не являются приоритетными. Другими словами, для их повсеместного применения просто нет ни опыта, ни материальной базы.Из этого идёт вторая проблема — мы просто-напросто привыкли к двоичным компьютерам. Изначально они были гораздо более простым решением (сделать детектор «есть ток — нет тока» было гораздо легче, чем «ток ниже — ток номинальный — ток выше» — а ведь силу тока надо было точно контролировать…). Со временем их стало так много, и они стали так хорошо изучены, что нужды в каких-то более продвинутых системах пока (!) не возникает. Тем более, что все существующие на данный момент компьютерные программы заточены именно на бинарную логику. Если вводить троичные компьютеры в использование, то под них либо нужно писать свои собственные программы (что дорого и долго), либо делать их совместимыми с двоичными — а это не всегда возможно, и, возможно, даже сложнее.Тем не менее, если кто-то всё-таки решится вложить время и деньги в разработку троичных машин и программ, то, потенциально, это приведёт к значительному росту мощностей компьютеров по всему миру, и, теоретически, может даже снизить необходимость в микропроцессорах с нанометровым техпроцессом. Плюс, не стоит забывать про такую весёлую вещь, как квантовые компьютеры. В квантовой физике мало что понимают даже те люди, которые полжизни ей занимаются. Например, квант может быть, как волной, так и частицей. Когда не ясно, в каком состоянии находится квант — это называется «Суперпозицией», отразить которую как раз может помочь дополнительное значение троичной логики. В общем, поле возможностей, открываемое троичными ЭВМ, бесконечно.Непонятно только, когда и в какую сторону это поле начинать переходить."'https://habrastorage.org/webt/xy/lr/ls/xylrlsqnzfvoqmerb_hcfqjutuc.jpeg'"['https://habrastorage.org/r/w780q1/webt/ht/4b/mf/ht4bmf-sc4-muxorgf6lup7p6gq.jpeg', 'https://habrastorage.org/r/w780q1/webt/q0/to/hp/q0tohpbsilmlvxrlv3zpuro5aco.jpeg', 'https://habrastorage.org/r/w48/getpro/habr/avatars/a28/c88/5df/a28c885df4b2460fbdb36d9f37d34837.png', 'https://habrastorage.org/webt/xy/lr/ls/xylrlsqnzfvoqmerb_hcfqjutuc.jpeg', 'https://habrastorage.org/r/w780q1/webt/am/zi/kb/amzikbuzzjii9ouac3srbfxxaus.jpeg', 'https://habrastorage.org/getpro/habr/avatars/a28/c88/5df/a28c885df4b2460fbdb36d9f37d34837.png', 'https://habrastorage.org/r/w780q1/webt/xy/lr/ls/xylrlsqnzfvoqmerb_hcfqjutuc.jpeg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w780q1/webt/zh/rn/o5/zhrno5e3l7gdrtx8b1g6fpvly4g.jpeg', 'https://habrastorage.org/r/w780q1/webt/mx/ua/nb/mxuanbovcusqgmqdgugvpnql8vq.jpeg', 'https://habrastorage.org/getpro/habr/company/fc0/4f0/3f7/fc04f03f7188eca615ef971283d62dc5.png']"
12'723402'Работа с научными данными в рамках data-driven подхода'В современном мире человечество нуждается в большом количестве данных, которые используются в совершенно различных целях: от повышения эффективности работы маркетинга отдельно взятой компании до...'https://habr.com/ru/post/723402/'"В современном мире человечество нуждается в большом количестве данных, которые используются в совершенно различных целях: от повышения эффективности работы маркетинга отдельно взятой компании до построения технологий будущего в научно-исследовательских центрах [1]. Однако зачастую результат напрямую зависит от того, как собираются и обрабатываются данные.

В данной статье я хочу показать, как происходит работа по сбору и обработке данных в рамках научного проекта. Работа с данными будет основываться на data-driven подходе.

Что такое data-driven подход?

Data-Driven подход — это способ принимать различные решения, основываясь на больших данных. Его используют для построения бизнес-модели или маркетинговой стратегии, при составлении плана продаж, в программировании и даже в дизайне.

Для каждой сферы выбирают конкретный тип информации, например данные о покупках, геолокации мобильных устройств, количестве поисковых запросов по теме. При поиске помещения под новую кофейню владелец может проанализировать трафик людей на улицах и выбрать место с наибольшей проходимостью. Полное название этого подхода — Data Driven Decision Making (DDDM), то есть информационно обоснованные решения (или data driven decisions) [2].

В чём суть моего научного проекта?

Мой научный проект посвящён вирусам. В его основе лежит фундаментальное свойство всех вирусов – атаковать строго определённые клетки (или группу клеток) организма-носителя [3]. Это свойство можно использовать для таргетной доставки лекарственных препаратов прямо в клетки, что может существенно увеличить эффективность лекарств.

Таргетная доставка лекарств не просто красивая идея – сегодня мы находимся очень близко к воплощению этой идеи в жизнь, так как уже разработаны методики синтеза искусственных полых (без вредоносной для клеток ДНК/РНК) капсидов вирусов [4].

Задача данного проекта – составить базу данных по вирусам, где полностью будут описываться все виды и типы капсидов вирусов, на основе этой базы данных обучить программу, которая в последствии по запросу будет предлагать один или несколько капсидов вирусов, которые нужно будет синтезировать для таргетной доставки лекарств в каждом отдельно взятом случае.

Как собрать данные для базы данных?

В данном проекте особо остро стоит вопрос о корректности собираемых данных, на основе которых будет работать целевая программа, так как если будут некорректно собраны или собраны некорректные данные, то всех проект в целом теряет смысл.

В данном проекте сбор данных осуществляется из первичных источников – научных статей по данной теме.

Для составления базы данных необходимо найти как можно больше характеристик для каждого вида вирусов, который способен заражать человека. Эти характеристики могут включать форму капсида, состав капсида (только протеины или протеины + липиды), поражаемые вирусом клетки или группа клеток и т.д. Все эти данные есть в открытом доступе, однако есть трудности с их сбором. Во-первых, их необходимо собирать вручную, так как они содержаться в сплошном тексте, а также могут зависеть от контекста, что делает затруднительным построение парсера для лёгкого и безболезненного сбора данных. Во-вторых, данные должны быть (по возможности) из проверенного источника (в идеале, из статей в журналах вроде Nature или Science). Для подтверждения корректности собранных данных их необходимо проверять на небольшой выборке: минимум три источника. Если во всех говорится, что определённый вирус имеет сферический капсид, то можно быть почти полностью уверенным, что собранные данные корректны. Если из трёх источников два говорят, что капсид по форме сферический, а один говорит, что форма – палочковидная, то стоит поискать ещё несколько источников и разобраться допущена ли ошибка в одном из источников или данный вирус существует в нескольких формах, которые следует по-разному занести в базу данных. Также критерием плохих данных может быть слишком большой разброс значений. Например, для размеров капсидов вирусов могут быть указаны значения от 30 до 300 нм. Этот диапазон необходимо уменьшить путём просмотра других источников по данному виду вирусов. Таким образом будет увеличено качество данных, т.к. они будут точнее описывать реально существующие системы.

Полнота данных будет увеличиваться путём собирания большего количества дескрипторов для каждого отдельно взятого вируса. Полными данные будут считаться тогда, когда для каждого вируса будут собраны значения всех дескрипторов.

Объём данных можно увеличить путём добавление новых дескрипторов, которые будут улучшать качество описания вирусов. Дескрипторы могут быть не только в виде новых столбцов в таблице, но также и в других форматах. Например, фотографии исследований вируса на SEM (Scanning Electron Microscope), которые будут давать визуальное представление об определённом вирусе.

Как хранить найденные данные?

Найденные данные нуждаются в хранилище, где они будут структурированно храниться. Два самых распространённый варианта: MySQL/PostgreSQL или Microsoft Excel/Google Sheets. Для своего проекта я выбрал Microsoft Excel, так как давно с ним работаю и для него нет необходимости в построении схемы хранения данных, которое необходимо при составлении базы данных в SQL.

По окончании сбора данных, таблицу Excel можно будет сохранить в виде CSV-файла для более удобного дальнейшего использования полученных данных.

Очистка собранных данных

После этапа сбора данных следует этап очистки данных. На этом этапе происходит удаление или исправление неправильных значений в таблице.

Чтобы убрать эти помехи, существует специальный процесс – очистка данных, который ещё называют data cleaning или scrubbing. Задача очистки данных – избавиться от большинства ошибок с помощью специальных инструментов и алгоритмов, сделать будущий анализ более точным.

Теоретически данные можно начать анализировать и без очистки. Однако на практике это может привести к проблемам — не соответствующим реальности графикам и отчётам или нереалистичным прогнозам. Поэтому грамотная работа с данными подразумевает их обязательную предварительную очистку.

Например, если название одного вируса повторяется дважды и имеет одинаковые параметры – это значит, что значение дублировалось и один из дубликатов необходимо удалить.

Также необходимо проверить записи на наличие опечаток и, при их наличии, их исправить. Помимо опечаток следует следить за одинаковыми формулировками буквенных значений. Например, если вирус содержит две одноцепочечных РНК, следует определиться с типом записи данного значения, предположим «Две одноцепочечные РНК», и далее по таблице присваивать именно это значение строке. Т.е. не допускать наличия других видов записи данного значения: «2 одноцепочечных РНК», «2 1-цепоч. РНК» и т.д. Наличие таких ошибок может сильно повлиять на работу с такими данными в будущем.

Следует обратить внимание на недопустимые значение, чтобы в столбце «Размер капсида, нм» вдруг не оказалось значение «Сферическая», относящееся к форме капсида.

Для упрощения процесса очистки данных (или если у вас очень большая база данных) можно использовать инструменты, вроде Drake, DataWrangler, DataCleaner и др.

Дальнейшая работа с данными

Разметка данных:

В случае использования фотографий вирусов на SEM, на сами фотографии необходимо поставить разметку.

Разметка (Data labeling) – это процесс добавления меток и тэгов в сырые данные, чтобы показать модели машинного обучения целевые атрибуты (ответы), которые она должна предсказывать.

В рамках данного проекта планируется использовать среду LabelImg для разметки данных.

Дальнейшая разработка и версионирование:

Собранные данные будут проанализированы в среде Jupiter Notebook. При анализе должны быть выявлены корреляции между размерами, формами и составом капсидов вирусов и конкретными группами клеток, которые эти вирусы атакуют. Данные корреляции будут служить демонстрацией осуществимости (proof of concept) данного проекта.

Весь анализ данных и вся дальнейшая разработка модели машинного обучения (МО) будут своевременно выкладываться в открытый доступ через Git на платформу GitHub.

Открытость данного проекта будет способствовать воспроизводимости данной модели МО для других учёных.

Список использованных источников

1. Alex Bekker, Big Data: Examples, Sources and Technologies explained [Электронный ресурс] // ScienceSoft. URL: https://www.scnsoft.com/blog/what-is-big-data?ysclid=lelbkhm22f746063344 (дата обращения 18.01.2023)<o:p></o:p>

2. Data Driven-подход // SkillFactory.блог. URL: https://blog.skillfactory.ru/glossary/data-driven-podhod/?ysclid=ld38kbjyab856230797 (дата обращения 20.01.2023)<o:p></o:p>

3. Механизмы вирусного заражения // KNEWS. URL: https://knews.kg/2020/06/29/mehanizmy-virusnogo-zarazheniya/?ysclid=ld93bnggf0889964981 <o:p></o:p>"'https://habr.com/share/publication/723402/e08746d3f21dcad8571a07496fcf3d00/'"['https://habrastorage.org/getpro/habr/upload_files/5e2/fdf/7f2/5e2fdf7f244e831d84560a6b57865eab.webp', 'https://habr.com/share/publication/723402/e08746d3f21dcad8571a07496fcf3d00/', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/029/593/328/029593328bc730ab131e2b4286aec2c5.jpeg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/3a6/fa6/222/3a6fa622285594161b556b5ba11c2853.jpeg', 'https://habrastorage.org/r/w48/getpro/habr/avatars/79b/519/7a6/79b5197a6188cda7498399bd82c14db7.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/79b/519/7a6/79b5197a6188cda7498399bd82c14db7.jpg']"
13'723398'Программирование — как выражение строгой математической теории'А что если представлять программу как не набор ключевых слов, а как какой-то формальный язык, с математической строгостью. Тогда программу можно выразить через линии (например). Т.е. чисто...'https://habr.com/ru/post/723398/'"А что если представлять программу как не набор ключевых слов, а как какой-то формальный язык, с математической строгостью. Тогда программу можно выразить через линии (например).

Т.е. чисто теоретически может существовать такой язык программирования, где вместо ключевых слов в котором будут линии и изгибы. Например вот такая линия выражает программу ""достать все товары без фильтров из базы данных"".

Любой рисунок будет представлять из себя программу.

Тогда мы можем писать программы, которые удовлетворяют определенным математическим законам. Например:

В математике есть определенные геометрические фигуры, которые обладают одним свойством - замкнутые. Например круг, или знак бесконечности.

Эти фигуры выражают определенную математическую концепцию - замкнутость. Т.е. в фигурах нет какого-то конца, который торчит в сторону.

Данную концепцию замкнутости можно расширить от 0-мерного пространства, до 1-мерного, 2-мерного, 3-мерного, 4-мерного и бесконечно-мерного пространства.

Тогда мы можем писать только программы, которые будут выражены линиями и в обязательным требованием - замкнутыми. Т.е. рисовать замкнутые линии - писать программы на языке линий и только замкнутыми.

Еще одна математическая концепция - бесконечная асимптота - бесконечное приближение.

Например есть какая-то линия, для которой НЕ существует формулы вида

Сама формула тоже уже выражает определенную строгую математическую концепцию.

Так вот в математике есть концепция разложения любой линии в бесконечный многочлен, который будет максимально близко приближен к оригинальной линии, но никогда не равен ей.

А что если программирование - это выражение какой-то математической концепции - например ""бесконечное приближение с помощью разложения в многочлен к линии, для которой не существует простой формулы"".

Тогда мы можем писать программы (опять же линиями), которые будут бесконечно приближенными к какой-то нужной нам иррациональной требуемой линии.

Допустим требуемая линия - достать все товары из базы данных. И мы раскладываем эту 1 иррациональную линию в бесконечный ряд линий - ключевых слов языка программирования ""линии"".

Что в доставании товаров - иррационального? А как назвать функцию доставания товаров - getProducts или просто Something::products() или свойством - Something.products. А должна ли быть функция вообще? Или несколько? А какие еще GOF паттерны применить?

Или есть другая математическая концепция - увеличение. Вначале это + сложение, затем * умножение, затем это ^ возведение в степень, затем еще и еще, мы можем увеличивать что-то бесконечно быстро.

И что если программирование выражает какую-то такую математическую концепцию? Как замкнутость, разложение в бесконечный ряд, бесконечно быстрое увеличение. А не просто решает проблемы бизнеса - показать товары в списке таблицей.

Т.е. показать товары - надо, но какую ""линию"", т.е. ""программу"" нарисовать для этого - вот уже где есть полет для выражения определенной строгой математической концепции. Т.е. идеальной программы."'https://habrastorage.org/getpro/habr/upload_files/36d/112/a25/36d112a25323ef46c3884d99ec292cb6.png'"['https://habrastorage.org/r/w1560/getpro/habr/upload_files/9ef/f08/d5a/9eff08d5a833b6d892565a65edf6b270.png', 'https://habrastorage.org/getpro/habr/upload_files/394/b33/9f8/394b339f8e74c166468de89166c7eddb.svg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/509/d16/a74/509d16a74c1098a79514e6f1624f624e.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/36d/112/a25/36d112a25323ef46c3884d99ec292cb6.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/625/946/2b0/6259462b08fe88e071318b648f6cc786.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/bfb/2ba/664/bfb2ba6640886d99b6d2962784330d1c.png', 'https://habrastorage.org/getpro/habr/upload_files/36d/112/a25/36d112a25323ef46c3884d99ec292cb6.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/fb8/c59/0be/fb8c590bec7995e002edfda5f5133246.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/e49/c24/cb0/e49c24cb062f7443ff5358e658fc5b79.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/183/ca0/cf7/183ca0cf7c6c328541815eac8ef575b4.png']"
14'723400'Свой язык, или как я устал от ассемблера и С'Вступление Это не гайд, не туториал и не исследование. Эта статья - просто история о том, как я решил создать свой язык для низкоуровневых штучек, отличного от ассемблера и С. Приятного прочтения!...'https://habr.com/ru/post/723400/'"Вступление

Это не гайд, не туториал и не исследование. Эта статья - просто история о том, как я решил создать свой язык для низкоуровневых штучек, отличного от ассемблера и С. Приятного прочтения!

Предыстория

Как вы знаете, я обожал (и до сих пор обожаю) язык ассемблера, а именно - fasm. Я уже давно его изучил и пользуюсь им, но постепенно стал давать слабину. Я устал писать код на ассемблере, так как это долго и довольно таки тяжело (рано, или поздно, это всё равно произошло бы). Понять мою любовь к этому языку можно прочитав мои предыдущие статьи: раз, два, три, четыре. Почему же я не стал использовать С? Он мне просто не нравится. Неудобно мне. Вот и всё.

Концепт

Концепт заключается в том, что человек указывает все данные для компиляции в главном файле с помощью директивы, например, format . Так же, есть два типа библиотек: встроенные (стандартные) и кастомные (пользовательские). Иначе говоря, либы и модули. Для использования shared object, dll и пр. будет отдельная директива. указателей в языке не будет, а для разыменывания будет использоваться макрос OFFSET . Для работы с железом на все случаи жизни будут стдлибы. Синтаксис будет чем-то средним между Java, TS, fasm (для некоторых выражений) и Python.

Синтаксис

Это, пожалуй, первое, с чего я начал. Для начала, я написал пример кода, который устроит меня своим синтаксисом. Вышло как-то так:

format mbr.x86.16.executable; use Bios; use Console; fn main() -> Void { Bios.set_mode(3); Console.log(""Hello, World!""); return 0; }

Я решил не сильно париться, поэтому использовал библиотеку parglare. Она очень легкая и удобная, всем рекомендую. Для описания синтаксиса парсер принимает строку в соответствующем формате, использует регулярные выражения (не надо осуждать регулярки, они всесильны!). Итак, вот такое описание синтаксиса у меня получилось:

sroot: sany*; sany: sformat | suse | sfn | sdefine; sformat: ""format"" tname "";""; suse: ""using"" tname "";""; sfn: ""fn"" tname ""("" sargs? "")"" ""->"" tname sbody; sargs: sarg ("","" sarg)*; sarg: tname "":"" tname; sbody: ""{"" sline* ""}""; sline: (scall | sequal | sdefine | sreturn) "";""; scall: tname ""("" scallargs? "")""; scallargs: sexpr ("","" sexpr)*; sequal: tname ""="" sexpr "";""; sdefine: sarg (""="" sexpr)* "";""; sreturn: ""return"" sexpr?; sexpr: ""("" sexpr "")"" |(ssequence | tname) ""["" tinteger ""]"" |sexpr ""*"" ""*"" sexpr |""-"" sexpr |sexpr ""*"" sexpr |sexpr ""/"" sexpr |sexpr ""+"" sexpr |sexpr ""-"" sexpr |""!"" sexpr |sexpr ""&"" sexpr |sexpr ""|"" sexpr |sexpr ""^"" sexpr |tinteger |tstring |tname |ssequence; ssequence: ""<"" scallargs "">""; terminals tstring: /""[^""]*""/; tname: /([A-Za-z_]\w*\.)*[A-Za-z_]\w*/; tinteger: /00?|[1-9]\d*/;

Вышло кратко. А краткость - сестра таланта. Да и к тому же, так будет проще.

Компиляция в язык ассемблера (fasm)

Я долго ломал голову, как это полаконичней сделать, и никак не мог придумать решение. Через пару дней я наткнулся на статью про pyast64 (на медиум, по-моему). Она раскрыла мне глаза. В коде этого скрипта было все что мне нужно: и работа со стеком, и соглашение о вызовах, и пр и тп. Я очень шустро накидал константы:

SIMPLE_BINOPS = ( ""add"", ""sub"", ""or"", ""and"", ""xor"", ""mul"", ""div"" ) SIMPLE_UNOPS = ( ""neg"", ""not"" ) SIMPLE_TYPES = ( ""integer"", ""string"", ""label"" ) COMPLEX_BINOPS = ( ""pow"", ""ind"" ) MUTABLE = ( ""integer"" ) ASM_BINOP = """""" pop qword rdx pop qword rax %s qword rax, rdx push qword rax"""""" ASM_DEF = """""" %s d_%s %s"""""" ASM_EQU = """""" pop qword rdx mov [%s], rdx"""""" ASM_LDR = """""" push qword [%s]"""""" ASM_LEA = """""" push qword %s"""""" ASM_PTR = """""" push qword %s"""""" ASM_RET = ""

ret"" ASM_SEQ = """""" push %s """"""

Дописать транслятор в ассемблер я ещё не успел, но до этого не долго осталось. Весь исходный код опубликован здесь: группа Telegram, здесь же можно обсудить и/или поддержать проект. Спасибо за внимание!"'https://habrastorage.org/getpro/habr/upload_files/2cf/cbc/5a6/2cfcbc5a67a4fda6bbf934876a1e06e4.png'"['https://habrastorage.org/getpro/habr/upload_files/2cf/cbc/5a6/2cfcbc5a67a4fda6bbf934876a1e06e4.png', 'https://habrastorage.org/r/w48/getpro/habr/avatars/9b6/2fc/a40/9b62fca40ad65f7a985ea43a21caa106.png', 'https://habrastorage.org/getpro/habr/avatars/9b6/2fc/a40/9b62fca40ad65f7a985ea43a21caa106.png', 'https://mc.yandex.ru/watch/24049213']"
15'723392'Как закалялась сталь современной симметричной криптографии. Глава 1. Классическая криптография'Введение Современные симметричные шифры, которыми мы пользуемся неявно, но повсеместно, появились в ходе своей многовековой эволюции, в ходе продолжительных и постоянных этапов собственного...'https://habr.com/ru/post/723392/'"Введение

Современные симметричные шифры, которыми мы пользуемся неявно, но повсеместно, появились в ходе своей многовековой эволюции, в ходе продолжительных и постоянных этапов собственного совершенствования. Каждый новый шаг улучшения приводил одновременно к разрушению старых уязвимых шифров и к порождению новых, более качественных и безопасных. Тем не менее, само разрушение старых алгоритмов всегда двояко свидетельствовало как об их недостатках, которые необходимо было искоренять, так и об их достоинствах, которые нужно было наследовать. В следствие этого, каждый новый, более качественный шифр, представлял собой количественный синтез старых, менее качественных алгоритмов шифрования.

Таким образом, для того, чтобы узнать как современные симметричные алгоритмы шифрования стали такими, какими мы их сейчас видим, нам необходимо углубиться в историю шифров, а именно — в классическую криптографию. Основной нашей целью будет являться выявление примитивов шифрования на базе классических шифров и реструктуризация современных шифров по их композиции. Это даст понимание того, что современные симметричные шифры появились не просто из пустого места, а из структур ранее созданных алгоритмов шифрования.

Данный материал также может быть полезен коллегам преподавателям по предмету КСЗИ (криптографические средства защиты информации) и непосредственно самим студентам при изучении классической и современной симметричной криптографии. По ходу статьи будут прикладываться программные коды на языке Си некоторых шифров классической криптографии. В конце данной статьи также будет указан список литературы по классической криптографии, с которым вы сможете ознакомиться.

Классическая криптография

Если начать с самого начала, с понимания того, как мы пришли к такой жизни, как люди научились создавать современные блочные/поточные шифры, нам необходимо углубиться в историю, а именно во времена, когда криптография ещё не являлась наукой, а была порождением искусства — в классическую криптографию.

Классическая криптография ныне является частью общей криптографии и представляет собой скорее исторический характер, нежели математический или информатический (современная криптография), относительно базисных наук. Таким образом, это говорит о том, что шифры которые будут описаны по ходу повествования, с большей долей вероятности не будут являться надёжными, и к ним нужно будет относиться исключительно как к экспонатам, играющим роль причины возникновения современных симметричных шифров.

Эпоху классической криптографии можно датировать периодом: 3000 л.д.н.э — первая половина XX в.н.э.. Вторая половина XX века связывает себя с рождением криптографии как науки, где не малую роль сыграли следующие факторы: 1) Работа ""Теория связи в секретных системах"" (К. Шеннон), где были предложены базовые принципы шифров - конфузия и диффузия, было проведено математическое описание ранее существовавших шифров, доказано существование абсолютной криптостойкости на примере шифра Вернама; 2) Стандартизация шифра DES; 3) Появление нового раздела — асимметричной криптографии; 4) Информация о дешифровании Энигмы; 5) Появление криптографических хеш-функций; 6) Появление концепции ЭЦП; 7) Массовое применение в коммуникациях. Таким образом, всё что было в криптографии до второй половины XX века базировалось исключительно на необходимых мерах конфиденциальности передаваемой/хранимой информации, без признаков применения хеширования, ЭЦП, асимметричного распределения ключей и массового применения в коммуникации.

В классической криптографии, в явном виде, существовало два класса шифров — подстановочные и перестановочные. Суть первых сводится к тому, что один символ или группа символов открытого текста заменяется на один символ или группу символов закрытого текста. Суть вторых сводится к тому, что открытый текст ""перемешивается"" или ""перетасовывается"" таким образом, что он становится в конечном счёте закрытым. Вследствие этого, основным отличием перестановочных шифров от подстановочных является использование в закрытом тексте тех же символов открытого текста, в ровно таком же количестве и такой же пропорции. Это можно представить в виде следующей схемы.

Классы шифров классической криптографии — подстановочные и перестановочные шифры

Подстановочные и перестановочные шифры также делятся на подклассы. Подстановочные шифры содержат пять подклассов, а именно: 1) коды, 2) моноалфавитные, 3) омофонические, 4) полиалфавитные, 5) полиграммные. Перестановочные содержат всего два подкласса: 1) простые и 2) сложные. Всю эту иерархию можно представить в виде следующей схемы.

Классы и подклассы шифров классической криптографии

1. Коды

Являются самыми первыми методами шифрования в истории. Известно, что применялись в Древнем Египте, хоть и не в целях скрытия информации. Их суть заключается в замене (шифровании) целых слов на другие слова, группу символов или числа. Данный вид шифров можно видеть и в настоящем времени, где шпионы не говорят свои настоящие имена, а заменяют их псевдонимами. Ключевой особенностью кодов является существование кодовой книги по принципу ""ключ-значение"", например Алиса=Змея, Боб=Черепаха, Ева=Ящерица, а само сообщение может звучать так: ""Змея-Змея, Ящерица вызывает Черепаху"".

Коды могут также хорошо синтезироваться со стеганографией, то-есть не только шифровать сообщение, но и скрывать сам факт существования оригинального сообщения посредством другого (нейтрального) сообщения. Так например, сообщение ""Я отнесу подарок часовщику в полдень"" может трактоваться так: ""Я положу бомбу у часовни в полночь"". Если кодовая книга достаточно большая, то она может очень сильно искажать первоначальный смысл сообщения, ""затмевая"" истинное ложным. Хоть коды и представляют собой самый древний способ шифрования, тем не менее, при хорошо продуманной кодовой книге, результирующий шифр может оказаться сложно взламываемым даже в текущих реалиях.

При всём этом, стоит сказать, что коды не являлись основополагающими методами шифрования для развития классической криптографии, т.к. их основной проблемой являлась и продолжает являться прямая зависимость криптостойкости от размера кодовой книги. Для того времени это становилось (простите за мой каламбур) ключевой проблемой, потому как необходимо было иметь как минимум две копии одной и той же кодовой книги у двух людей на большой дистанции.

2. Моноалфавитные шифры

Являются отправной и ключевой точкой отчёта развития классической криптографии. Самыми старыми представителями подобного подкласса являются шифр Атбаш (~ 500 л.д.н.э.), шифр Полибия (~ III в.д.н.э.) и шифр Цезаря (~ I в.д.н.э.). В отличие от кодов, шифрующих целые слова, как элементарную единицу, моноалфавитные шифры нацелены исключительно на посимвольное шифрование. Также как и коды, моноалфавитные шифры имеют прямую связь между открытой элементарной единицей (слово/символ) и закрытой (слово/число/символ). Данную связь мы будем называть 1к1, где например, если открытый символ A преобразуется в закрытый символом B, то он не может ещё и преобразовываться в закрытый символ C, D, E и т.д. И наоборот, если закрытый символ B был получен из открытого символа A, то он не может быть расшифрован как-либо иначе кроме этого же символа A.

В качестве примера, часто приводят шифр Цезаря. Думаю вряд-ли кто-то с ним не знаком, если человек хоть когда-нибудь начинал увлекаться криптографией. Основной особенностью шифра Цезаря является его ключ, представленный числом сдвигов оригинального алфавита. Так например, предположим, что у нас присутствует ключ K=1 и сообщение M=HELLO, тогда шифрованный результат будет выглядить как IFMMP. Если ключ K=3, то сообщение становится равным KHOOR. Итого, количество всех возможных ключей в шифре Цезаря выражается мощностью алфавита |A| (количеством символов). Если это английский алфавит, то существует всего |A|=26 ключей, если русский, то |A|=33 ключа и т.д. При этом всегда присутствует ключ равный нулю, в итоге количество ""нормальных"" ключей равно |A|-1.

Шифр Цезаря со сдвигом равным единице

Часто те кто начинает изучать классическую криптографию, испытывает путаницу в понимании различия между подстановочными и перестановочными шифрами. Иногда (хоть и редко) можно услышать, что шифр Цезаря — это перестановочный шифр. Путаница возникает на моменте вышепоказанной схемы, где действительно происходит обычная перестановка алфавита. Тем не менее, перестановочным шифром является алгоритм, при котором все символы исходного текста также находятся в шифрованном тексте, в ровно такой же пропорции — постоянно, как бы вы часто не меняли ключ шифрования. В контексте же шифра Цезаря, алфавит — это не открытый текст, а полученный алфавит после сдвига — не шифротекст. Можно сказать, более обще, что алфавит в шифре Цезаря — это есть часть ключа, посредством которой мы шифруем все последующие сообщения.

Тем не менее, если подойти к проблеме с другой точки зрения и представить алфавит как открытый текст, то тут уже действительно применяется перестановочный шифр, результатом которого становится ключ для шифра Цезаря. Но само применение перестановочного шифра при генерации ключа для другого шифра (будь то подстановочного или перестановочного) не свидетельствует о том, что другой шифр становится также перестановочным.

Программный код шифра Цезаря #include ""encoder.h"" #include <stdio.h> #include <stdint.h> #include <stdlib.h> #include <string.h> typedef struct caesar_t { encoder_t *encoder; int32_t key; } caesar_t; extern caesar_t *caesar_new(encoder_t *encoder, int32_t k); extern void caesar_free(caesar_t *caesar); extern uint8_t *caesar_encrypt(caesar_t *caesar, uint8_t *output, uint8_t *input); extern uint8_t *caesar_decrypt(caesar_t *caesar, uint8_t *output, uint8_t *input); static uint8_t *encrypt_string(caesar_t *caesar, encmode_t m, uint8_t *output, uint8_t *input); static int32_t encrypt_code(encoder_t *encoder, int32_t c, int32_t k); int main(int argc, char *argv[]) { uint8_t alphabet[] = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ""; uint8_t size_alph = (uint8_t)strlen((char*)alphabet); encoder_t *encoder = encoder_new(size_alph); encoder_set_alphabet(encoder, alphabet); uint8_t message[BUFSIZ]; uint32_t key = 3; strcpy((char*)message, ""HELLOWORLD""); caesar_t *caesar = caesar_new(encoder, key); printf(""%s

"", (char*)caesar_encrypt(caesar, message, message)); printf(""%s

"", (char*)caesar_decrypt(caesar, message, message)); caesar_free(caesar); encoder_free(encoder); return 0; } extern caesar_t *caesar_new(encoder_t *encoder, int32_t k) { caesar_t *caesar = (caesar_t*)malloc(sizeof(caesar_t)); caesar->encoder = encoder; caesar->key = k; return caesar; } extern void caesar_free(caesar_t *caesar) { free(caesar); } extern uint8_t *caesar_encrypt(caesar_t *caesar, uint8_t *output, uint8_t *input) { return encrypt_string(caesar, MODE_ENC, output, input); } extern uint8_t *caesar_decrypt(caesar_t *caesar, uint8_t *output, uint8_t *input) { return encrypt_string(caesar, MODE_DEC, output, input); } static uint8_t *encrypt_string(caesar_t *caesar, encmode_t m, uint8_t *output, uint8_t *input) { size_t input_len = strlen((char*)input); int encoded_ch, encrypted, flag; for (int i = 0; i < input_len; i++) { encoded_ch = encoder_encode(caesar->encoder, input[i], &flag); if (flag == 0) { fprintf(stderr, ""undefined char %c;

"", input[i]); return NULL; } encrypted = encrypt_code(caesar->encoder, encoded_ch, m*caesar->key); // m = {-1, 1} output[i] = encoder_decode(caesar->encoder, encrypted, &flag); if (flag == 0) { fprintf(stderr, ""undefined code %c;

"", encrypted); return NULL; } } output[input_len] = '\0'; return output; } static int32_t encrypt_code(encoder_t *encoder, int32_t c, int32_t k) { uint8_t size = encoder_get_size_alphabet(encoder); return (c+k+size)%size; } Библиотека encoder Файл encoder.h #ifndef _H_ENCODER #define _H_ENCODER #include <stdint.h> typedef enum encmode_t { MODE_ENC = 1, MODE_DEC = -1 } encmode_t; typedef struct encoder_t encoder_t; extern encoder_t *encoder_new(uint8_t size_alph); extern void encoder_free(encoder_t *encoder); extern uint8_t encoder_get_size_alphabet(encoder_t *encoder); extern void encoder_set_alphabet(encoder_t *encoder, uint8_t *alphabet); extern uint8_t encoder_encode(encoder_t *encoder, uint8_t ch, int *found); extern uint8_t encoder_decode(encoder_t *encoder, uint8_t code, int *valid); #endif Файл encoder.c #include ""encoder.h"" #include <stdint.h> #include <stdlib.h> typedef struct encoder_t { uint8_t size_alph; uint8_t *alphabet; } encoder_t; extern encoder_t *encoder_new(uint8_t size_alph) { encoder_t *encoder = (encoder_t*)malloc(sizeof(encoder_t)); if (encoder == NULL) { return NULL; } encoder->size_alph = size_alph; encoder->alphabet = (uint8_t*)malloc(sizeof(uint8_t)*size_alph); return encoder; } extern void encoder_free(encoder_t *encoder) { free(encoder->alphabet); free(encoder); } extern uint8_t encoder_get_size_alphabet(encoder_t *encoder) { return encoder->size_alph; } extern void encoder_set_alphabet(encoder_t *encoder, uint8_t *alphabet) { for (int i = 0; i < encoder->size_alph; ++i) { encoder->alphabet[i] = alphabet[i]; } } extern uint8_t encoder_encode(encoder_t *encoder, uint8_t ch, int *found) { for (int i = 0; i < encoder->size_alph; ++i) { if (encoder->alphabet[i] == ch) { *found = 1; return i; } } *found = 0; return 0; } extern uint8_t encoder_decode(encoder_t *encoder, uint8_t code, int *valid) { if (code >= encoder->size_alph) { *valid = 0; return 0; } *valid = 1; return encoder->alphabet[code]; } Компиляция gcc -Wall -std=c99 main.c encoder.c Запуск ./a.out Результат исполнения KHOORZRUOG HELLOWORLD

Теперь, хоть мы и рассмотрели шифр Цезаря в подробностях, он всё равно является лишь единичным случаем (реализацией) всех моноалфавитных шифров. Благо моноалфавитные шифры можно обобщить. Так например, наивысшая криптостойкость всех моноалфавитных шифров выражается в лице шифра простой подстановки. Можно также в равной степени сказать, что шифр простой подстановки — это и есть целый подкласс в лице моноалфавитных шифров, потому как посредством него могут быть выражены все другие моноалфавитные шифры, будь то шифр Атбаш, шифр Цезаря, шифр Полибия, шифр Бэкона, Аффинный шифр и т.д. Следовательно, если шифр простой подстановки будет обладать определённым рядом уязвимостей, то все они также будут наследоваться побочными шифрами.

Шифр простой подстановки

Ключом в шифре простой подстановки является сам алфавит, а точнее его подстановочная версия. Так например, предположим, что имеется подстановка, которая указана на схеме выше и открытое сообщение M=HELLO. Результатом шифрования станет зашифрованное сообщение C=ITSSG. В отличие от шифра Цезаря, здесь нет вообще никакой перестановки даже на уровне алфавита, потому как могут существовать символы в подстановочной алфавите, которых не существует в оригинальном, и наоборот. Так например, символа @ не существует в оригинальном алфавите, а символа B не существует в подстановочном алфавите.

Шифр простой подстановки поражает количеством всевозможных ключей, потому как таковое количество становится равным факториалу мощности алфавита |A|!. Для английского алфавита количество ключей равно |A|!=26!=403291461126605635584000000, для русского |A|!=33!=8683317618811886495518194401280000000. Если очень грубо выражать данное количество ключей через сложность вычисления в битовом представлении современных симметричных шифров, то получится, что для английского алфавита сложность составляет ~=288, а для русского ~=2122. Для сравнения с текущими реалиями, считается, что длина ключа в 120 бит является вычислительно надёжной к полному перебору подготовленным криптоаналитиком с огромными вычислительными ресурсами.

Но не нужно быть такими наивными. Вышеописанная сложность будет работать лишь при том условии, когда шифр является идеальным в том простом плане, что у него не существует более никаких других уязвимостей, кроме полного перебора. Тем не менее, шифр простой подстановки имеет ряд уязвимостей. Это можно даже доказать на априорных знаниях, где существуют другие методы шифрования, отличные от моноалфавитных. Если бы моноалфавитный шифр являлся бы надёжным, то другие шифры скорее всего бы даже не разрабатывались и не были бы так знамениты в своих применениях. Но всё же, для лучшего понимания уязвимостей, нужно исходить из апостериорных знаний.

У шифра простой подстановки существует два основных вектора нападения — частотный криптоанализ и атака по маске. Первый вектор базируется на том факте, что у каждого алфавита, т.к. он естественный, существует некая избыточность символов, приводящая к тому, что одни символы в тексте встречаются гораздо чаще чем другие. Под текстом нам лучше понимать совокупность всех открытых текстов на выбранном языке. На практике конечно достаточно знать лишь несколько текстов с большим объёмом символов, чтобы выстроить частоту встречаемости каждого отдельного символа приближенную к частотам суммы всех текстов на данном языке. Второй вектор также базируется на факте избыточности символов в открытом тексте, но уже не на уровне каждого отдельного символа, как это предполагает частотный криптоанализ, а на уровне целой группы символов. Под группой символов могут выступать часто повторяемые слова, часто употребляемые приставки, суффиксы, предлоги, окончания, и т.д.

В любом случае, лучше будет попрактиковаться на примере данных векторов нападения. Предположим, что у нас существует следующий шифротекст. Известно, что таковой закрытый текст был получен посредством моноалфавитного шифра. Значит это говорит о том, что сохраняется связь символов между открытым и закрытым текстами 1к1.

Закрытый текст (моноалфавитный шифр) AFD RPKOA PX AFKU AFPEJFA DSRDVKHDOA NZU AP UFPN AFD HZOT ZYDOEDU PX ZAAZQC ZJZKOUA Z UTUADH, ZOM FPN XDN PX AFDH KOYPIYD AFD QPHREADV- KLDM RPVAKPO PX AFD RVPQDUU. ND QZO ZAAZQC AFD AZWEIZAKPO UPXANZVD, ZOM ND QZO HPEOA Z MDOKZI-PX-UDVYKQD ZAAZQC WT HZCKOJ AFD ZEAPHZAKQ UTUADH XZKI ZOM XPVQKOJ AFD DIDQAKPO BEMJDU AP XZII WZQC PO ZO PIMDV, HPVD KOUDQEVD, RVPQDMEVD XPV ZQQPHRIKUFKOJ AFD UZHD AZUC. KO AFD DOM, DIDQAKPOU ZVD ZWPEA AVEUA. KX AFD DIDQAKPO BEMJDU ZVD AVEUANPVAFT ZOM QPHRDADOA, AFD DIDQAKPO NKII WD XZKV. KX AFD DIDQAKPO BEMJDU ZVD OPA AVEUANPVAFT, AFDVD ZVD UP HZOT NZTU AP VKJ AFD DIDQAKPO AFZA KA KUO’A DYDO NPVAF NPVVTKOJ ZWPEA NFKQF POD KU HPUA IKCDIT. AFD KOADVODA ZMMU ODN ANKUAU AP AFKU ZIVDZMT AZOJIDM UCDKO, ZOM AFD VKUCU KOQVDZUD UKJOKXKQZOAIT. ZII AFD PIM ZAAZQCU VDHZKO, ZOM AFDVD ZVD ZII AFD ODN ZAAZQCU ZJZKOUA AFD YPAKOJ QPHREADVU, AFD ODANPVC, ZOM AFD YPADVU’ QPHREADVU (NFKQF ZVD OPA AVEUADM KO ZOT NZT). ZOM MDOKZI-PX- UDVYKQD ZAAZQCU AFZA MPO’A DSKUA ZJZKOUA QDOAVZIKLDM UTUADHU. DYDO NPVUD, HPMDVO DIDQAKPOU FZYD OP JVZQDXEI NZT AP XZKI. AFD 2000 MDHPQVZAKQ RVK- HZVT KO ZVKLPOZ ZIIPNDM KOADVODA YPAKOJ. KX AFDVD NZU Z RVPWIDH, PV DYDO UEURKQKPO PX Z RVPWIDH, NFZA QPEIM ZVKLPOZ MP? VDWPPA AFD DIDQAKPO ZOM AVT ZJZKO AFD XPIIPNKOJ NDDC? AFKU VDZUPO ZIPOD KU DOPEJF AP QPOYKOQD ZOT RUDRFPIPJKUA AP DUQFDN KOADVODA YPAKOJ. В исторической действительности же люди понимали (хоть и не сразу), что всеразличные символы точки, двоиточия, запятые, пробелы, абзацы и т.д. могут сыграть плохую роль в скорейшем взломе (дешифровании) закрытого текста. Поэтому они исключались и сам шифртекст выглядил как сплошной набор закрытых символов. Тем не менее, для примера взлома вполне сгодится более легковесная и лёгкая версия.

1) Частотный криптоанализ

Первое, что нам необходимо сделать — это вычислить частоты каждого отдельного символа в шифртексте. Для этого мы можем написать небольшую программу на Си, которая самостоятельно будет вычислять все частоты символов в закрытом тексте.

Программный код вычисления частот встречаемости символов #include <stdio.h> // Читаем только английские символы большого регистра #define ALPHA_SIZE 26 int main(void) { FILE *file = fopen(""encrypted.txt"", ""r""); if (file == NULL) { return 1; } int ch, sum; int frequency[ALPHA_SIZE] = {0}; while ((ch = fgetc(file)) != EOF) { if ('A' <= ch && ch <= 'Z') { frequency[ch-'A']++; ++sum; } } for (int i = 0; i < ALPHA_SIZE; ++i) { printf(""%c = %5.2f%%;

"", 'A'+i, ((double)frequency[i])/((double)sum)*100); } fclose(file); return 0; } Данная программа работает исключительно с символами ASCII, то-есть с английским алфавитом. Поэтому, если шифртекст будет написан на русском языке, то данную программу нужно будет переписать под поддержку кириллицы.

Получаем на выходе такие частоты. Здесь стоит помнить, что т.к. наш текст не сказать что большой, то и частоты могут перекрывать друг друга. Поэтому, при таком типе криптоанализа, становится необходимо иметь достаточно обширный текст, чтобы исключить как можно больше неопределённостей.

A = 11.49%; B = 0.28%; C = 1.29%; D = 12.50%; E = 2.11%; F = 4.50%; G = 0.00%; H = 2.21%; I = 3.77%; J = 2.02%; K = 6.89%; L = 0.37%; M = 2.85%; N = 2.57%; O = 7.90%; P = 7.90%; Q = 3.95%; R = 1.47%; S = 0.18%; T = 1.75%; U = 5.79%; V = 5.51%; W = 0.83%; X = 1.93%; Y = 1.29%; Z = 8.64%;

Теперь, второе, что нам необходимо сделать — это сравнить полученные частоты с оригинальными частотами символов английского алфавита.

Из сравнения мы видим, что (с большей долей вероятности) символ открытого текста E либо равен символу A закрытого текста, либо символу D закрытого текста. Оставшийся символ закрытого текста (A или D) должен будет также принадлежать (с большей долей вероятности) одному из первых оставшихся символов оригинального алфавита, то-есть к T, A, O, N или I.

Делаем предположение, что символ E=D по большей частоте встречаемости. На самом деле мы также могли сделать предположение, что символ E=A), потому как расстояние частот между символами A и D невелико. Оставшийся символ A предполагаем следующему символу оригинального алфавита T, иными словами делаем предположение, что T=A. Теперь заменяем все символы A, D в шифротексте на E и T. Получаем следующий текст.

Первая итерация дешифрования моноалфавитного шифра tFe RPKOt PX tFKU tFPEJFt eSReVKHeOt NZU tP UFPN tFe HZOT ZYeOEeU PX ZttZQC ZJZKOUt Z UTUteH, ZOM FPN XeN PX tFeH KOYPIYe tFe QPHREteV- KLeM RPVtKPO PX tFe RVPQeUU. Ne QZO ZttZQC tFe tZWEIZtKPO UPXtNZVe, ZOM Ne QZO HPEOt Z MeOKZI-PX-UeVYKQe ZttZQC WT HZCKOJ tFe ZEtPHZtKQ UTUteH XZKI ZOM XPVQKOJ tFe eIeQtKPO BEMJeU tP XZII WZQC PO ZO PIMeV, HPVe KOUeQEVe, RVPQeMEVe XPV ZQQPHRIKUFKOJ tFe UZHe tZUC. KO tFe eOM, eIeQtKPOU ZVe ZWPEt tVEUt. KX tFe eIeQtKPO BEMJeU ZVe tVEUtNPVtFT ZOM QPHReteOt, tFe eIeQtKPO NKII We XZKV. KX tFe eIeQtKPO BEMJeU ZVe OPt tVEUtNPVtFT, tFeVe ZVe UP HZOT NZTU tP VKJ tFe eIeQtKPO tFZt Kt KUO’t eYeO NPVtF NPVVTKOJ ZWPEt NFKQF POe KU HPUt IKCeIT. tFe KOteVOet ZMMU OeN tNKUtU tP tFKU ZIVeZMT tZOJIeM UCeKO, ZOM tFe VKUCU KOQVeZUe UKJOKXKQZOtIT. ZII tFe PIM ZttZQCU VeHZKO, ZOM tFeVe ZVe ZII tFe OeN ZttZQCU ZJZKOUt tFe YPtKOJ QPHREteVU, tFe OetNPVC, ZOM tFe YPteVU’ QPHREteVU (NFKQF ZVe OPt tVEUteM KO ZOT NZT). ZOM MeOKZI-PX- UeVYKQe ZttZQCU tFZt MPO’t eSKUt ZJZKOUt QeOtVZIKLeM UTUteHU. eYeO NPVUe, HPMeVO eIeQtKPOU FZYe OP JVZQeXEI NZT tP XZKI. tFe 2000 MeHPQVZtKQ RVK- HZVT KO ZVKLPOZ ZIIPNeM KOteVOet YPtKOJ. KX tFeVe NZU Z RVPWIeH, PV eYeO UEURKQKPO PX Z RVPWIeH, NFZt QPEIM ZVKLPOZ MP? VeWPPt tFe eIeQtKPO ZOM tVT ZJZKO tFe XPIIPNKOJ NeeC? tFKU VeZUPO ZIPOe KU eOPEJF tP QPOYKOQe ZOT RUeRFPIPJKUt tP eUQFeN KOteVOet YPtKOJ.

Третье, что мы делаем — это пытаемся найти в полученном тексте какие-либо похожие слова. Так например, очень часто попадается комбинация символов равная tFe. В английском алфавите, присутствует схожая комбинация и тоже часто встречаемая равная символам THE. Если наши первоначальные предположения на счёт символов T и E оказались верными, то скорее всего сопоставление H=F тоже окажется верным. Это можно проверить на примере косвенных сопоставлений. Так например, в тексте есть ещё комбинация tFeH которая может быть равна THEN или THEM, также слово tFeVe, которое может быть равно THERE или THESE, и tFZt может быть равно THAT. Таким образом, H=F скорее всего точно является верным, т.к. мы нашли достаточно много косвенных совпадений. Заменяем F на H, параллельно заменяем Z на A, и пытаемся поразмыслить теперь над H = N или M, а также V = R или S. Плюс к этому, в полученном тексте начинает вырисовываться слово attaQCU из которого мы можем предположить ATTACKS. Если это верно, то мы расскрываем дополнительные сразу три символа C, K, S, а также ставим однозначную связь V=R (потому как символ S нам стал известен).

Вторая итерация дешифрования моноалфавитного шифра the RPKOt PX thKs thPEJht eSRerKHeOt Nas tP shPN the HaOT aYeOEes PX attack aJaKOst a sTsteH, aOM hPN XeN PX theH KOYPIYe the cPHREter- KLeM RPrtKPO PX the RrPcess. Ne caO attack the taWEIatKPO sPXtNare, aOM Ne caO HPEOt a MeOKaI-PX-serYKce attack WT HakKOJ the aEtPHatKc sTsteH XaKI aOM XPrcKOJ the eIectKPO BEMJes tP XaII Wack PO aO PIMer, HPre KOsecEre, RrPceMEre XPr accPHRIKshKOJ the saHe task. KO the eOM, eIectKPOs are aWPEt trEst. KX the eIectKPO BEMJes are trEstNPrthT aOM cPHReteOt, the eIectKPO NKII We XaKr. KX the eIectKPO BEMJes are OPt trEstNPrthT, there are sP HaOT NaTs tP rKJ the eIectKPO that Kt KsO’t eYeO NPrth NPrrTKOJ aWPEt NhKch POe Ks HPst IKkeIT. the KOterOet aMMs OeN tNKsts tP thKs aIreaMT taOJIeM skeKO, aOM the rKsks KOcrease sKJOKXKcaOtIT. aII the PIM attacks reHaKO, aOM there are aII the OeN attacks aJaKOst the YPtKOJ cPHREters, the OetNPrk, aOM the YPters’ cPHREters (NhKch are OPt trEsteM KO aOT NaT). aOM MeOKaI-PX- serYKce attacks that MPO’t eSKst aJaKOst ceOtraIKLeM sTsteHs. eYeO NPrse, HPMerO eIectKPOs haYe OP JraceXEI NaT tP XaKI. the 2000 MeHPcratKc RrK- HarT KO arKLPOa aIIPNeM KOterOet YPtKOJ. KX there Nas a RrPWIeH, Pr eYeO sEsRKcKPO PX a RrPWIeH, Nhat cPEIM arKLPOa MP? reWPPt the eIectKPO aOM trT aJaKO the XPIIPNKOJ Neek? thKs reasPO aIPOe Ks eOPEJh tP cPOYKOce aOT RseRhPIPJKst tP escheN KOterOet YPtKOJ.

Из полученного результата мы также начинаем видеть ещё новые слова, например rKsks может быть равно risks (это подкрепляется также thKs => this), Neek может быть равно week (это подкрепляется также Nhat => what и Nas => was), reasPO может быть равно reason (это подкрепляется также RrPcess => process и tP => to, и eYeO => even). Все полученные комбинации также пытаемся заменить. Если будет что-то неверно, может попытаться вернуться назад.

Получаем уже такой текст, где его большая часть читается даже без последующего анализа и сравнения. Мы открыли следующие символы: t, h, e, p, o, i, n, t, o, r, v, w, c, k, s. В сумме 15, что представляет уже большую часть символов английского алфавита, более 50%. Далее, можете продолжить дешифровывать текст самостоятельно.

the point oX this thoEJht eSperiHent was to show the HanT avenEes oX attack aJainst a sTsteH, anM how Xew oX theH invoIve the coHpEter- iLeM portion oX the process. we can attack the taWEIation soXtware, anM we can HoEnt a MeniaI-oX-service attack WT HakinJ the aEtoHatic sTsteH XaiI anM XorcinJ the eIection BEMJes to XaII Wack on an oIMer, Hore insecEre, proceMEre Xor accoHpIishinJ the saHe task. in the enM, eIections are aWoEt trEst. iX the eIection BEMJes are trEstworthT anM coHpetent, the eIection wiII We Xair. iX the eIection BEMJes are not trEstworthT, there are so HanT waTs to riJ the eIection that it isn’t even worth worrTinJ aWoEt which one is Host IikeIT. the internet aMMs new twists to this aIreaMT tanJIeM skein, anM the risks increase siJniXicantIT. aII the oIM attacks reHain, anM there are aII the new attacks aJainst the votinJ coHpEters, the network, anM the voters’ coHpEters (which are not trEsteM in anT waT). anM MeniaI-oX- service attacks that Mon’t eSist aJainst centraIiLeM sTsteHs. even worse, HoMern eIections have no JraceXEI waT to XaiI. the 2000 MeHocratic pri- HarT in ariLona aIIoweM internet votinJ. iX there was a proWIeH, or even sEspicion oX a proWIeH, what coEIM ariLona Mo? reWoot the eIection anM trT aJain the XoIIowinJ week? this reason aIone is enoEJh to convince anT psephoIoJist to eschew internet votinJ.

От куда взят текст? Книга — Секреты и ложь (Б. Шнайер)

P.S. На данном моменте (или даже раньше) могло возникнуть сомнение, что этот текст я уже знал и поэтому так легко его дешифровывал. На самом деле так и было, примерно пол года назад, пока я не удалил все открытые тексты. На моём ПК (а точнее на сервере) остались лишь самостоятельные работы для студентов, но без оригинальных текстов. Так что можно сказать, что это дешифрование было спонтанным.

2) Атака по маске

Данный вид криптоаналитической атаки схож по своему методу на частотный криптоанализ, но лишь с тем отличием, что таковой смотрит не на частоты встречаемости каждого отдельного символа, а на частоты встречаемости целых слов в тексте, или на частоты появления приставок, суффиксов, предлогов, окончаний и т.д. Следовательно, он заменяет два первых этапа частотного криптоанализа на этап сравнивания групп символов. В некой степени данный вид атаки является более простым и быстрым, если вы знакомы с языком, на котором написан текст.

Предположим, что у нас также существует тот самый текст. Забудем о том, что мы его смогли успешно дешифровать.

Закрытый текст (моноалфавитный шифр) AFD RPKOA PX AFKU AFPEJFA DSRDVKHDOA NZU AP UFPN AFD HZOT ZYDOEDU PX ZAAZQC ZJZKOUA Z UTUADH, ZOM FPN XDN PX AFDH KOYPIYD AFD QPHREADV- KLDM RPVAKPO PX AFD RVPQDUU. ND QZO ZAAZQC AFD AZWEIZAKPO UPXANZVD, ZOM ND QZO HPEOA Z MDOKZI-PX-UDVYKQD ZAAZQC WT HZCKOJ AFD ZEAPHZAKQ UTUADH XZKI ZOM XPVQKOJ AFD DIDQAKPO BEMJDU AP XZII WZQC PO ZO PIMDV, HPVD KOUDQEVD, RVPQDMEVD XPV ZQQPHRIKUFKOJ AFD UZHD AZUC. KO AFD DOM, DIDQAKPOU ZVD ZWPEA AVEUA. KX AFD DIDQAKPO BEMJDU ZVD AVEUANPVAFT ZOM QPHRDADOA, AFD DIDQAKPO NKII WD XZKV. KX AFD DIDQAKPO BEMJDU ZVD OPA AVEUANPVAFT, AFDVD ZVD UP HZOT NZTU AP VKJ AFD DIDQAKPO AFZA KA KUO’A DYDO NPVAF NPVVTKOJ ZWPEA NFKQF POD KU HPUA IKCDIT. AFD KOADVODA ZMMU ODN ANKUAU AP AFKU ZIVDZMT AZOJIDM UCDKO, ZOM AFD VKUCU KOQVDZUD UKJOKXKQZOAIT. ZII AFD PIM ZAAZQCU VDHZKO, ZOM AFDVD ZVD ZII AFD ODN ZAAZQCU ZJZKOUA AFD YPAKOJ QPHREADVU, AFD ODANPVC, ZOM AFD YPADVU’ QPHREADVU (NFKQF ZVD OPA AVEUADM KO ZOT NZT). ZOM MDOKZI-PX- UDVYKQD ZAAZQCU AFZA MPO’A DSKUA ZJZKOUA QDOAVZIKLDM UTUADHU. DYDO NPVUD, HPMDVO DIDQAKPOU FZYD OP JVZQDXEI NZT AP XZKI. AFD 2000 MDHPQVZAKQ RVK- HZVT KO ZVKLPOZ ZIIPNDM KOADVODA YPAKOJ. KX AFDVD NZU Z RVPWIDH, PV DYDO UEURKQKPO PX Z RVPWIDH, NFZA QPEIM ZVKLPOZ MP? VDWPPA AFD DIDQAKPO ZOM AVT ZJZKO AFD XPIIPNKOJ NDDC? AFKU VDZUPO ZIPOD KU DOPEJF AP QPOYKOQD ZOT RUDRFPIPJKUA AP DUQFDN KOADVODA YPAKOJ.

Первое, на что наше внимание теперь должно быть приковано, так это к структуре самого текста. Нам нужно найти наибольшее количество закономерностей. Так например, группа символов AFD очень часто встречается в начале предложений, что может быть равно группе символов THE английского алфавита. Если это так, то мы сразу сможем узнать три правильных символа. Далее, моё внимание приковывают предложения с вопросами, потому как в английском языке вопросительные предложения строятся немного по другому в сравнении с обычными, а также имеют вспомогательные слова. Предположим, что в этих предложениях могут существовать слова WHAT, WHY, WHERE, HOW и т.д. Под WHAT может подходить шифртекст NFZA, т.к. никакие четыре символа не совпадают и находятся в вопросительном предложении. Далее очень часто в тексте встречается одиночный символ Z, который может быть равен символу A в английском тексте, который также подкрепляет гипотезу о WHAT=NFZA.

После того, как мы открыли несколько слов, нам будет легче продолжиать взламывать шифртекст, но уже посимвольно, как ранее мы это делали в частотном криптоанализе. На данном этапе, нам известны уже следующие символы: t, h, e, a, w. Если взглянуть вновь на частотный криптоанализ, то нам для этого текста было достаточно всего двух открытых символов для взлома всего текста, а именно T и E. Так что с полученным результатом также вполне реально доломать весь оставшийся шифртекст.

Программный код шифра простой подстановки #include ""encoder.h"" #include <stdio.h> #include <stdint.h> #include <stdlib.h> #include <string.h> typedef struct simple_substitution_t { encoder_t *orig_encoder; encoder_t *encr_encoder; } simple_substitution_t; extern simple_substitution_t *simple_substitution_new(encoder_t *orig_encoder, encoder_t *encr_encoder); extern void simple_substitution_free(simple_substitution_t *simple_substitution); extern uint8_t *simple_substitution_encrypt(simple_substitution_t *simple_substitution, uint8_t *output, uint8_t *input); extern uint8_t *simple_substitution_decrypt(simple_substitution_t *simple_substitution, uint8_t *output, uint8_t *input); static uint8_t *encrypt_string(simple_substitution_t *simple_substitution, encmode_t m, uint8_t *output, uint8_t *input); int main(int argc, char *argv[]) { uint8_t alphabet_orig[] = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ""; uint8_t size_alph_orig = (uint8_t)strlen((char*)alphabet_orig); encoder_t *encoder_orig = encoder_new(size_alph_orig); encoder_set_alphabet(encoder_orig, alphabet_orig); uint8_t alphabet_encr[] = ""QWERTYUIOPASDFGHJKLZXCVBNM""; uint8_t size_alph_encr = (uint8_t)strlen((char*)alphabet_encr); encoder_t *encoder_encr = encoder_new(size_alph_encr); encoder_set_alphabet(encoder_encr, alphabet_encr); uint8_t message[BUFSIZ]; strcpy((char*)message, ""HELLOWORLD""); simple_substitution_t *simple_substitution = simple_substitution_new(encoder_orig, encoder_encr); printf(""%s

"", (char*)simple_substitution_encrypt(simple_substitution, message, message)); printf(""%s

"", (char*)simple_substitution_decrypt(simple_substitution, message, message)); simple_substitution_free(simple_substitution); encoder_free(encoder_orig); encoder_free(encoder_encr); return 0; } extern simple_substitution_t *simple_substitution_new(encoder_t *orig_encoder, encoder_t *encr_encoder) { simple_substitution_t *simple_substitution = (simple_substitution_t*)malloc(sizeof(simple_substitution_t)); simple_substitution->orig_encoder = orig_encoder; simple_substitution->encr_encoder = encr_encoder; return simple_substitution; } extern void simple_substitution_free(simple_substitution_t *simple_substitution) { free(simple_substitution); } extern uint8_t *simple_substitution_encrypt(simple_substitution_t *simple_substitution, uint8_t *output, uint8_t *input) { return encrypt_string(simple_substitution, MODE_ENC, output, input); } extern uint8_t *simple_substitution_decrypt(simple_substitution_t *simple_substitution, uint8_t *output, uint8_t *input) { return encrypt_string(simple_substitution, MODE_DEC, output, input); } static uint8_t *encrypt_string(simple_substitution_t *simple_substitution, encmode_t m, uint8_t *output, uint8_t *input) { encoder_t *encoder_read, *encoder_write; size_t input_len = strlen((char*)input); int encoded_ch, flag; switch (m) { case MODE_ENC: encoder_read = simple_substitution->orig_encoder; encoder_write = simple_substitution->encr_encoder; break; case MODE_DEC: encoder_read = simple_substitution->encr_encoder; encoder_write = simple_substitution->orig_encoder; break; } for (int i = 0; i < input_len; i++) { encoded_ch = encoder_encode(encoder_read, input[i], &flag); if (flag == 0) { fprintf(stderr, ""undefined char %c;

"", input[i]); return NULL; } output[i] = encoder_decode(encoder_write, encoded_ch, &flag); if (flag == 0) { fprintf(stderr, ""undefined code %c;

"", encoded_ch); return NULL; } } output[input_len] = '\0'; return output; } Библиотека encoder, а также способ компиляции находятся во вложении с кодом шифра Цезаря. Результат исполнения ITSSGVGKSR HELLOWORLD

В итоге, на заре окончания использования моноалфавитных шифров уже было всем известно, что таковой подкласс шифров ни в коем случае нельзя считать надёжным. Хоть у него и вправду может существовать огромное количество ключей, тем не менее, у него существует и ряд значительных уязвимостей, позволяющих взламывать закрытый текст за считанные минуты. Люди того времени уже понимали на чём зиждется данная уязвимость, а именно на связи 1к1. Если такую связь скрыть, размыть или исключить, то частотный криптоанализ и атака по маске будут уже не такими эффективными орудиями в руках криптоаналитиков.

3. Омофонические шифры

Представляют собой развитие моноалфавитного подкласса, позволяющего шифровать один и тот же символ несколькими способами, тем самым образуя новый тип связи 1кN. Иными словами, теперь становится возможным отождествлять символ A одновременно с несколькими символами, как например B, C и D. При шифровании символа A случайным образом выбирается символ из данного множества, что как следствие, может порождать закрытый текст вида BCDBD из открытого текста AAAAA. Тем не менее, остаётся и в омофоническом шифре ""наследие"" моноалфавитного, а именно расшифрование становится всегда однозначным относительно множества закрытых символов. Так например, если A способен преобразовываться в B, C или D, то B, C и D не могут расшифровываться никак иначе как символ A. Поэтому связь и является однонаправленной. Представителем подобных шифров является книжный шифр (не путать с книжным шифром из стеганографии).

Главной целью омофонических шифров является сокрытие частот встречаемости каждого отдельного символа посредством их выравнивания. Так предположим, что существует алфавит всего из трёх символов {A, B, C}. Предположим, что в текстах на этом языке, A=X (где X - шифросимвол) встречается в 50% случаев, а символы B=Y и C=Z в 25% случаев каждый. В моноалфавитном шифре частота символа X всегда бы сохранялась и была равна частоте символа A открытого текста, из-за чего могла бы применяться атака частотным криптоанализом. Омофонический же шифр размывает частотную закономерность посредством ""деления"" символа на несколько символов шифртекста. Так например, если A разделить на два символа Q и W, и при шифровании с равной и случайной вероятностью выбирать один из них, то символы Q и W, вместе с символами Y и Z будут иметь вероятность встречаемости по 25% каждый. Из этого следует, что применять на шифртекст с правильной омофонической заменой атаку частотного криптоанализа более становится невозможно.

Омофонический шифр, искореняя атаку частотным криптоанализом, вдобавок и повышает количество возможных ключей при полном переборе. На первый взгляд кажется, что вот он, идеальный шифр, у которого более не существует уязвимостей, а полный перебор просто неосуществим на практике. Но вы ведь ещё не забыли об атаке по маске? Хоть атака по маске и представляет собой некий частный случай атаки частотного криптоанализа, но за счёт того, что атака по маске анализирует закономерность на уровне групп символов, то и векторы нападения начинают немного отличаться. Эта атака становится губительной для омофонических шифров.

Основная суть атаки сводится к тому, что омофонический шифр (пока не берём в расчёт книжный шифр) имеет тенденцию повторять шифросимволы, хоть и с равной вероятностью. Если открытый текст будет достаточно объёмным, то таким же объёмным будет и шифртекст. Из-за объёмности в тексте будут часто повторяться одни и те же группы символов. Так например, предположим, что существует английский алфавит, где нашей маленькой задачей будет являться сокрытие огромного количества групп символов THE омофоническим шифром. И в чём же заключается проблема? Проблема заключается в том, что количество всех возможных комбинаций омофонических подстановок ограничено, что может приводить рано или поздно к повторам одних и тех же групп. Если T = (# или B), H = (2 или O), E = (& или 5), то в лучшем (именно в лучшем) случае группа символов THE повторит себя спустя 23=8 раз, т.к. для такой группы символов существует именно 8 разных способов написания: #2&, #25, #O&, #O5, B2&, B25, BO&, BO5. Таким образом, криптоаналитик всё равно будет видеть частоты встречаемости, хоть и не каждого отдельного символа, но именно повторяющихся групп символов.

Но теперь представьте, что если количество омофонических подстановок для каждого отдельного символа растёт очень быстро? Так например, если для каждого символа существует 8 подстановок, то комбинация THE (опять таки в лучшем случае) повторится спустя 83=512 использований. Если выбрано 32 подстановки, то 323=32 768 и т.д. Можно сказать, что не словами едины и криптоаналитик начнёт искать также закономерности повторений не только в словах, но и в приставках, суффиках, предлогах, окончаниях и т.п. А теперь предположим, что если каждый отдельный зашифрованный символ будет обладать своей уникальной омофонической заменой? Иными словами, если вы будете шифровать много одинаковых символов AAA...AAA, то всегда будете получать разные символы #$8...0JD. Можно конечно сказать, что количество символов в какой-либо кодировке ограничено, но ничто не мешает шифровать символы числами, подобия (31)(222)(1)...(3123)(4454)(910). В таком случае шифрования, какие бы то ни было атаки окажутся бессмысленными, будь то частотный криптоанализ, т.к. частоты всегда будут априори выравнены из-за неповторяемости каждого отдельного символа, будь то атака по маске, т.к. не будет связей групп между собой.

Но существует ли такой омофонический шифр? Существует — это книжный шифр. Его суть крайне проста и может быть описана следующим алгоритмом действий.

Взять случайную книгу, статью или какой-либо массивный текст. Взять открытый символ оригинального текста. Открыть книгу и найти там этот символ. Записать в качестве шифрсимвола (страницу/строку/позицию) этого символа. Зачеркнуть этот символ в книге и никогда больше его не применять. Перейти на пункт 2, если нужно продолжить шифрование.

Таким образом, единственная атака на подобный вид омофонических шифров сводится к нахождению оригинальной книги (ключа) для возможности расшифрования. Иными словами, единственной атакой на книжный шифр становится атака полным перебором всех возможных ключей. С одной стороны действительно можно сказать, что это и есть идеальный шифр, но стоит учесть несколько факторов: 1) книги, статьи, текста нужно как-то уметь передавать, т.к. они могут быть достаточно большими в размерах; 2) если брать теоретически все возможные книги в мире и на основе них высчитывать количество ключей, то получится всего ~=130 000 000 возможных ключей (https://www.vesti.ru/article/2053203), что составляет примерно всего ~=227 сложности перебора. Что с первым, что со вторым пунктом действительно можно поспорить. Так например, по первому пункту, можно выбирать малую книгу, статью или какой-либо другой текст, но итоговый шифртекст также будет малым. Также со вторым пунктом, можно учитывать не только книги, но и статьи, а также всеразличные другие тексты, но 1) это может непозволить шифровать большие сообщения и 2) оставшиеся большие тексты также будут ограничены в количестве, что не на сильно повысит итоговое количество ключей.

Программная реализация книжного шифра #include <stdio.h> #include <stdint.h> #include <stdlib.h> #include <string.h> typedef struct book_cipher_t { FILE *book_key; uint32_t msg_size; } book_cipher_t; extern book_cipher_t *book_cipher_new(FILE *book_key, uint32_t msg_size); extern void book_cipher_free(book_cipher_t *book_cipher); extern uint32_t *book_cipher_encrypt(book_cipher_t *book_cipher, uint32_t *output, uint8_t *input); extern uint8_t *book_cipher_decrypt(book_cipher_t *book_cipher, uint8_t *output, uint32_t *input); static int find_position(uint32_t *positions, uint32_t n, uint32_t pos); int main(int argc, char *argv[]) { uint32_t encrypted[BUFSIZ]; uint8_t message[BUFSIZ]; strcpy((char*)message, ""hello, world""); FILE *book_key = fopen(""book_key.txt"", ""r""); if (book_key == NULL) { return 1; } book_cipher_t *book_cipher = book_cipher_new(book_key, strlen((char*)message)); book_cipher_encrypt(book_cipher, encrypted, message); for (int i = 0; i < book_cipher->msg_size; ++i) { printf(""%d "", encrypted[i]); } printf(""

""); printf(""%s

"", (char*)book_cipher_decrypt(book_cipher, message, encrypted)); book_cipher_free(book_cipher); fclose(book_key); return 0; } extern book_cipher_t *book_cipher_new(FILE *book_key, uint32_t msg_size) { book_cipher_t *book_cipher = (book_cipher_t*)malloc(sizeof(book_cipher_t)); book_cipher->book_key = book_key; book_cipher->msg_size = msg_size; return book_cipher; } extern void book_cipher_free(book_cipher_t *book_cipher) { free(book_cipher); } extern uint32_t *book_cipher_encrypt(book_cipher_t *book_cipher, uint32_t *output, uint8_t *input) { uint32_t file_pos, positions[book_cipher->msg_size]; uint32_t output_i = 0, size_positions = 0; int ch; for (int i = 0; i < book_cipher->msg_size; ++i) { int ch_found = 0; while((ch = fgetc(book_cipher->book_key)) != EOF) { file_pos = ftell(book_cipher->book_key); if (ch == input[i] && !find_position(positions, book_cipher->msg_size, file_pos)) { output[output_i++] = file_pos; positions[size_positions++] = file_pos; fseek(book_cipher->book_key, 0, SEEK_SET); ch_found = 1; break; } } if (!ch_found) { output[output_i++] = 0; fprintf(stderr, ""char '%c' undefined

"", input[i]); fseek(book_cipher->book_key, 0, SEEK_SET); } } return output; } extern uint8_t *book_cipher_decrypt(book_cipher_t *book_cipher, uint8_t *output, uint32_t *input) { for (int i = 0; i < book_cipher->msg_size; ++i) { if (input[i] == 0) { fprintf(stderr, ""found null char

""); continue; } fseek(book_cipher->book_key, input[i]-1, SEEK_SET); output[i] = fgetc(book_cipher->book_key); } return output; } static int find_position(uint32_t *positions, uint32_t n, uint32_t pos) { for (int i = 0; i < n; ++i) { if (positions[i] == pos) { return 1; } } return 0; } Файл book_key.txt Love is too young to know what conscience is, Yet who knows not conscience is born of love? Then, gentle cheater, urge not my amiss, Lest guilty of my faults thy sweet self prove. For, thou betraying me, I do betray My nobler part to my gross body’s treason: My soul doth tell my body that he may Triumph in love; flesh stays no farther reason; But rising at thy name doth point out thee As his triumphant prize. Proud of this pride, He is contented thy poor drudge to be, To stand in thy affairs, fall by thy side. No want of conscience hold it that I call Her ‘love’ for whose dear love I rise and fall. Программная реализация более простая, чем оригинальный шифр, потому как не учитывает строки и страницы, а просто печатает позиции символов. Результат исполнения 28 4 87 103 2 45 5 25 10 81 142 207 hello, world

В результате, наивысшая криптостойкость омофонических шифров становится противоречивой сущностью, потому как количественная характеристика ключа начинает идти в открытое противоречие с качеством криптостойкости самого алгоритма шифрования. Таким образом, с одной стороны, появляется уязвимость атаки по маске, но при этом исключается атака перебором, с другой стороны исключается уязвимость атаки по маске, но появляется возможность полного перебора ключей. В конечном счёте приходится выбирать определённые компромиссы.

4. Полиалфавитные шифры

Являются дальнейшим развитием моноалфавитных, а также омофонических шифров, представляя новый тип связи NкN. В отличие от омофонических шифров, способных представлять множественную вариативность исключительно операции шифрования, полиалфавитные шифры способны представлять двунаправленную связь между открытым и закрытым текстом. Так например, становится возможным замена символа A на B или C и одновременно с этим, символ B может расшифровываться как символ A или C (такое же утверждение справедливо для символа C). Примерами подобных шифров являются диск Альберти, шифр Гронсвельда, шифр Виженера, шифр Вернама, шифр Тритемиуса.

Разберём для начала классический полиалфавитный шифр — шифр Виженера. Данный алгоритм шифрования представляет собой более общий случай шифра Цезаря, переводя ключ-число в ключ-строку. Каждый отдельный символ ключ-строки исполняет ту же самую функцию, что и ключ-число в шифре Цезаря для конкретно выбранного символа. Так например, предположим, что у нас существует ключ K=QWE и сообщение M=HELLO. Само шифрование осуществляется таким образом, что ключ начинает кодироваться в числовое представление, где символ ключа становится позицией оригинального алфавита. Так например, если бы ключ был равен ABC...XYZ, то он бы закодировался в 0,1,2,...,23,24,25 соответственно (нумерация начинается с нуля). Таким образом, ключ QWE становится равен 16,22,4. Далее, начинается этап дублирования ключа до тех пор, пока он не станет больше или равен количеству символов в открытом тексте. Следовательно, продублированный ключ станет равен 16,22,4,16,22. В конечном итоге, при шифровании происходит наложение ключа с открытым текстом, а операцией наложения становится сдвиг накладываемого символа на количество позиций накладываемого ключа, иными словами шифр Цезаря. Всё это можно описать следующим образом.

Алфавит = ABCDEFGHIJKLMNOPQRSTUVWXYZ Открытый текст = HELLO Шифрование: H >> 16 = X (применяется шифр Цезаря с K=16) E >> 22 = A (применяется шифр Цезаря с K=22) L >> 4 = P (применяется шифр Цезаря с K=4) L >> 16 = B (применяется шифр Цезаря с K=16) O >> 22 = K (применяется шифр Цезаря с K=22) Закрытый текст = XAPBK

Шифр Виженера также может быть представлен таблицей NxN, где N - количество символов алфавита. Так, на примере английского алфавита, это выглядит следующим образом.

Квадрат шифра Виженера

Чтобы зашифровать определённый символ с определённым ключом, необходимо будет найти его на пересечении данной матрицы. Если взять наш ключ K=QWE и сообщение M=HELLO, а также предположить, что слева по вертикали будут находиться символы ключа, а сверху по горизонтали символы сообщения, то на пересечении символов мы будем находить те же шифросимволы: Q+H=X, W+E=A, E+L=P, Q+L=B, W+O=K. Итого, XAPBK, что и требовалось ожидать.

Шифр Виженера при этом также является частным случаем более общего описания полиалфавитных шифров. Так например, в более абстрактном виде для полиалфавитного шифра не важен как таковой конкретный моноалфавитный шифр. Наиболее абстрактная, и как следствие, общая версия описания полиалфавитных шифров может быть представлена множественным применением шифров простой подстановки с разными ключами.

Может ложно показаться, что шифр Виженера является надёжным шифром, т.к. относится к типу связи NкN. Тем не менее, полиалфавитные шифры в массе своей наследуют уязвимости моноалфавитных шифров, но не таким явным образом. Так например, если взять вышеописанный случай шифрования с ключом K=QWE и сгруппировать полученный шифртекст C по группам символов типа (C[0], C[3], C[6], ..., C[3k]), (C[1], C[4], C[7], ..., C[3k+1]) и (C[2], C[5], C[8], ..., C[3k+2]), где значение в скобках - это нумерация символа в шифртексте C, то каждая группа будет обладать собственным смещением. Так группа шифросимволов (C[0], C[3], C[6], ..., C[3k]) обладает смещением равным 16, группа (C[1], C[4], C[7], ..., C[3k+1]) обладает смещением равным 22, а группа (C[2], C[5], C[8], ..., C[3k+2]) обладает смещением равным 4. Иными словами, каждая группа символов по отдельности была зашифрована просто шифром Цезаря с определённым ключом. И так, если нам известны все эти группы, то мы становимся способными применить частотный криптоанализ на каждую группу по отдельности, восстанавливая открытые символы. После того, как был применён частотный криптоанализ на каждую группу происходит этап слияния всех групп вновь в собранный текст. Если все или большая часть частот успешно подошла, то можно легко будет прочитать открытый текст.

Также в шифре Виженера остаётся уязвимость к атаке по маске. Так например, если текущая позиция ключа при шифровании открытого текста начинает совпадать с уже продублированным блоком открытого текста, который был зашифрован с точно такой же позицией ключа, то шифрованным результат данного блока будет аналогичным. По такому признаку как раз и становится возможным определять количество групп по шифртексту, или вернее сказать количество непродублированных символов ключа.

Программная реализация шифра Виженера #include ""encoder.h"" #include <stdio.h> #include <stdint.h> #include <stdlib.h> #include <string.h> typedef struct vigenere_t { encoder_t *encoder; uint8_t *key; uint32_t key_size; } vigenere_t; extern vigenere_t *vigenere_new(encoder_t *encoder, uint8_t *key); extern void vigenere_free(vigenere_t *vigenere); extern uint8_t *vigenere_encrypt(vigenere_t *vigenere, uint8_t *output, uint8_t *input); extern uint8_t *vigenere_decrypt(vigenere_t *vigenere, uint8_t *output, uint8_t *input); static uint8_t *encrypt_string(vigenere_t *vigenere, encmode_t m, uint8_t *output, uint8_t *input); static int32_t encrypt_code(encoder_t *encoder, int32_t c, int32_t k); int main(int argc, char *argv[]) { uint8_t alphabet[] = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ""; uint8_t size_alph = (uint8_t)strlen((char*)alphabet); encoder_t *encoder = encoder_new(size_alph); encoder_set_alphabet(encoder, alphabet); uint8_t message[BUFSIZ]; uint8_t key[] = ""QWE""; strcpy((char*)message, ""HELLOWORLD""); vigenere_t *vigenere = vigenere_new(encoder, key); printf(""%s

"", (char*)vigenere_encrypt(vigenere, message, message)); printf(""%s

"", (char*)vigenere_decrypt(vigenere, message, message)); vigenere_free(vigenere); encoder_free(encoder); return 0; } extern vigenere_t *vigenere_new(encoder_t *encoder, uint8_t *key) { vigenere_t *vigenere = (vigenere_t*)malloc(sizeof(vigenere_t)); vigenere->encoder = encoder; vigenere->key_size = strlen((char*)key); vigenere->key = (uint8_t*)malloc(sizeof(uint8_t)*vigenere->key_size+1); strcpy((char*)vigenere->key, (char*)key); return vigenere; } extern void vigenere_free(vigenere_t *vigenere) { free(vigenere->key); free(vigenere); } extern uint8_t *vigenere_encrypt(vigenere_t *vigenere, uint8_t *output, uint8_t *input) { return encrypt_string(vigenere, MODE_ENC, output, input); } extern uint8_t *vigenere_decrypt(vigenere_t *vigenere, uint8_t *output, uint8_t *input) { return encrypt_string(vigenere, MODE_DEC, output, input); } static uint8_t *encrypt_string(vigenere_t *vigenere, encmode_t m, uint8_t *output, uint8_t *input) { size_t input_len = strlen((char*)input); int encoded_ch, encrypted, key, flag; for (int i = 0; i < input_len; i++) { encoded_ch = encoder_encode(vigenere->encoder, input[i], &flag); if (flag == 0) { fprintf(stderr, ""undefined char %c;

"", input[i]); return NULL; } key = encoder_encode(vigenere->encoder, vigenere->key[i%vigenere->key_size], &flag); if (flag == 0) { fprintf(stderr, ""encode key char %c;

"", vigenere->key[i%vigenere->key_size]); return NULL; } encrypted = encrypt_code(vigenere->encoder, encoded_ch, m*key); // m = {-1, 1} output[i] = encoder_decode(vigenere->encoder, encrypted, &flag); if (flag == 0) { fprintf(stderr, ""undefined code %c;

"", encrypted); return NULL; } } output[input_len] = '\0'; return output; } static int32_t encrypt_code(encoder_t *encoder, int32_t c, int32_t k) { uint8_t size = encoder_get_size_alphabet(encoder); return (c+k+size)%size; } Библиотека encoder, а также способ компиляции находятся во вложении с кодом шифра Цезаря. Результат исполнения XAPBKAENPT HELLOWORLD

Хоть такие уязвимости в шифре Виженера и присутствуют, но они прямолинейно зависят от 1) количества символов ключа; 2) качества ключа. Начнём с количества. Основной проблемой дешифрования (взлома) шифра Виженера является определение количества групп или, иными словами, количество непродублированных символов ключа. Для малой длины ключа и большого открытого текста найти группы не составит труда. Тем не менее, если ключ будет достаточно длинным, то найти повторяющиеся группы может быть проблематичным занятием. Если же длина ключа будет равна длине сообщения, то таковых групп и не будет существовать вовсе, и как следствие будет невозможным применение атаки по маске, для нахождения повторяемых групп символов, и атаки частотного криптоанализа, для дешифрования групп символов. В таком случае криптоаналитик полагается на существование некачественного, предсказуемого ключа, зависимого от контекста определённых событий. Например, началом ключа может быть какая-то дата, стих, прогноз погоды и т.д.

P.S. Некоторые полиалфавитные шифры, подобия шифра Тритемиуса, могли быть также взломаны посредством линейного криптоанализа, анализирующего статистическкую закономерность между открытым и закрытым текстом, на основе каких-либо алгебраический закономерностей. Такая уязвимость возникает из особенности шифра Тритемиуса, где ключом является функция, аргументом которой становится позиция шифруемого символа. Но такой метод криптоанализа появился лишь в современной криптографии, а потому о таковом следует говорить лишь в пределах его зарождения и последующего использования.

На основе всех вышеописанных критериев создаётся шифр Вернама, как определение наивысшей криптостойкости всех полиалфавитных алгоритмов шифрования. Шифр Вернама можно рассматривать как частный случай шифра Виженера с тремя правилами:

Необходимо использовать ключ, длина которого будет больше или равна длине сообщения. В данном контексте не позволяется как-либо дублировать или дополнять ключ. Он должен быть цельным. В качестве ключа нужно использовать случайную и равновероятную последовательность символов. Иными словами, если нам необходимо зашифровать какой-либо символ, то под него мы должны сгенерировать случайный символ. Вероятность угадать какой символ будет получен при генерации должна составлять 1/N, где N - количество символов в алфавите. Недопускать использование одного и того же ключа для двух разных сообщений. Иначе, это приведёт к уничтожению фактора случайности, то-есть к ликвидации второго пункта.

Шифр Вернама является не только представителем полиалфавитных шифров, не только их выражением наивысшей криптостойкости, но и шифром с теоретической (абсолютной) криптостойкостью. Иными словами, если в шифре Вернама были соблюдены все три критерия, то порождённый им шифртекст невозможно взломать ни за какое время и никакими вычислительными ресурсами.

Доказательство Я постараюсь привести простым языком доказательство абсолютной криптостойкости шифра Вернама. Так например, Клод Шеннон в своей работе ""Теория связи в секретных системах"" говорит о теоретической криптостойкости с позиции того, что апостериорные знания полученные вследствие дешифрования (взлома) шифртекста должны оставаться равны априорным, до непосредственного криптоанализа. На этой основе давайте посмотрим шифр Вернама. Предположим, что у нас имеется следующий шифртекст GHX. Из априорных знаний нам известно, что здесь либо было зашифровано слово DOG с вероятностью 50%, либо слово CAT с вероятностью 30%, либо слово RAT с вероятностью 20%. Также нам известно, что был выбран случайный и равновероятный ключ, длина которого равна длине самого сообщения. Это говорит о том, что вероятность угадывания правильного ключа составит 1/(263)=1/17576. Количество ключей невелико, мы можем перебрать каждый ключ и попытаться дешифровать сообщение, но беда заключается в том, что при переборе найдётся ключ K=DTR, который приведёт к сообщению DOG, ключ K=EHF, который приведёт к сообщению CAT и ключ K=PHF, который приведёт к сообщению RAT. Иными словами, во всём множестве ключей будут априори существовать ключи под все предполагаемые варианты. Таким образом, нам ничего не даст полный перебор всех возможных ключей, а это лишь свидетельствует о том, что апостериорные знания (после попытки криптоанализа) остались равными априорным знаниям (до его попытки).

5. Полиграммные шифры

Являются представителями развития кодов и моноалфавитных шифров, преобразующих не единичные символы и не целые слова в шифрованный результат, а целые блоки символов открытого текста в блоки закрытого текста. Можно сказать данный подкласс шифров является неким промежуточным или синтезирующим звеном между подклассами моноалфавитных шифров и кодов, усложняющих преобразования посредством стремления к кодам и увеличивающих количество вариантов шифрования в сравнении с моноалфавитными шифрами. В качестве примера, группа символов AB может шифроваться только как группа CD, в ровно такой же степени как и CD может расшифровываться исключительно и только как AB. Тем не менее, если один ранее использованный символ группы будет шифроваться, но уже с другим, то результатом преобразования может стать совершенно другая пара, например AC может быть преобразовано в EZ. В данном контексте сохраняется связь 1к1, но данный подкласс шифров становится более трудным по той лишь простой причине, что для взлома необходимым становится анализ частот не каждого отдельного символа, а целой группы символов. В качестве примера полиграммных шифров можно привести шифр Порты, шифр Плейфера, шифр Хилла.

Разберём полиграммные шифры на примере шифра Плейфера, как наиболее классического представителя полиграммных шифров. Шифр Плейфера является биграммным шифром, то-есть шифрует по два символа за раз, парно. В отличие от шифра Хилла, который может шифровать биграммами, триграммами, ..., N-граммами, шифр Плейфера шифрует исключительно биграммами.

Преобразование открытого текста в закрытый посредством шифра Плейфера происходит посредством выстраивания ключ-матрицы из ключа-строки. Предположим, что у нас существует английский алфавит, количество символов которого равно 26. Чтобы поместить эти 26 символов в матрицу, потребуется либо матрица 5x6, либо матрица 6x6 с дополнительными символами. В исторической же действительности брали матрицу 5x5, заменяя символ J символом I. Иными словами данные символы становились аналогичны друг другу при шифровании. При расшифровании они восстанавливались исходя из контекста самого сообщения. Ключ-строка играла роль первичного заполнения ключ-матрицы, посредством которого перемешивался оригинальный английский алфавит. Так например, предположим что у нас существует ключ-строка K=PARROT. В таком случае нам необходимо сконкатенировать к PARROT весь английский алфавит. Получим на выходе следующую строку: PARROTABCDEFGHIJKLMNOPQRSTUVWXYZ. Теперь нам нужно удалить все повторяющиеся символы начиная с конца данной строки, а также не забыть удалить символ J. В итоге, мы получаем такую строку PAROTBCDEFGHIKLMNQSUVWXYZ. Теперь создаём матрицу 5x5 и вносим туда получившуюся строку слева-направо, сверху-вниз.

P A R O T B C D E F G H I K L M N Q S U V W X Y Z

Как только была сгенерирована матрица-ключ мы можем приступать к шифрованию сообщений. Предположим, что мы шифруем сообщение M=HELL. У шифр Плейфера существует ряд условностей, которые необходимо выполнить с открытым сообщением ещё до момента шифрования. Первое — разбить текст на биграммы, таким образом HELL преобразуется в (HE, LL). Второе — начиная с первой биграммы идти по порядку и как только появляется биграмма с одинаковыми символами, необходимо вставить между двумя символами нейтральный символ. В истории классической криптографии таким символом являлся X. После вставки нужно вновь выстроить биграммы и продолжить проверку повторяющихся символов в биграммах. Третье — если последняя биграмма неполная, то-есть не имеет парного символа, тогда нужно дополнить её нейтральным символом. В следствие этого, у нас получатся уже такие биграммы (HE, LX, LX).

P.S. В данном алгоритме существует одна погрешность, которая может допустим при программной реализации привести к бесконечному циклу, а именно если биграмма будет состоять из символов XX или если последняя биграмма будет неполной и состоять только из символа X. В таком случае, алгоритм будет всегда пытаться либо вставить между двумя XX ещё X, либо будет добавлять к X ещё X и приведёт вновь к зацикленности вставления X между двумя XX. На практике же (в истории) такой проблемы не встречалось по той лишь простой причине, что два символа XX просто не могут существовать рядом в английских словах. Таким образом, для программных реализаций может сойти использование второго нейтрального символа, допустим Y при таком случае.

Далее, как только мы получили биграммы открытого текста (HE, LX, LX), мы можем приступать к шифрованию. Шифр Плейфера предлагает нам три основных правила для шифрования сообщений.

Если два символа одной биграммы находятся на одной строке и на разных столбцах матрицы, то необходимо сдвинуть позицию текущих символов на одну позицию вправо и взять символы стоящие под новыми позициями в качестве шифрованной биграммы. Предположим, если бы мы шифровали биграмму HK, то её результатом по нашей ключ-матрице стала бы биграмма IL (H=>I, K=>L). Если два символа одной биграммы находятся на одном столбце и на разных строках матрицы, то необходимо сдвинуть позицию текущих символов на одну позицию вниз и взять символы стоящие под новыми позициями в качестве шифрованной биграммы. Предположим, если бы мы шифровали биграмму DQ, то её результатом по нашей ключ-матрице стала бы биграмма IX (D=>I, Q=>X). Если два символа одной биграммы находятся на разных строках и столбцах матрицы, то необходимо прочертить прямоугольник, где символы биграммы будут являться его углами, и взять противоположные углы. Символы на противоположных углах прямоугольника будут являться шифром биграммы. Предположим, если бы мы шифровали биграмму AS, то её результатом по нашей ключ-матрице стала бы биграмма NO (A=>N, S=>O) или ON (A=>O, S=>N).

Неоднозначность третьего пункта связана с нестандартизацией шифра Плейфера как такового. Такая же ситуация может происходить со множеством других алгоритмов шифрования классической криптографии (например — шифр вертикальной перестановки). Таким образом, абоненты в лице отправителя и получателя должны были заранее договориться о том, как следует шифровать биграммы находящиеся на разных строках и столбцах — либо по вертикали, либо по горизонтали.

Предположим, что мы будем придерживаться вертикальной шифрования при существовании третьего пункта. Таким образом, наши биграммы (HE, LX, LX) открытого текста будут преобразованы в биграммы (CK, ZI, ZI) закрытого текста.

У шифра Плейфера существует ряд недостатков. Так например, при заполнении ключ-матрицы, последние символы часто находятся в алфавитном порядке и чисто теоретически можно предположить, исходя из частоты использования символов, что X, Y, Z скорее всего в конце как были, так и остались в неизменной позиции. Таким образом, нам становится возможным определение нескольких символов ключ-матрицы сразу на раннем этапе. Также, если будут шифроваться биграммы по первому или второму правилу с использованием одинаковых символов, например биграммы (CE, CF), то в качестве результата мы получим схожее соответствие (DF, DB). Иными словами, на данном примере символ C не зависит от изменения парного ему символа.

Помимо вышеописанных недостатков, на нашем примере также видны ещё классические уязвимости, унаследованные моноалфавитными шифрами. Так например, биграммы LX всегда одинакого будут шифроваться как биграммы ZI. Также на основе атаки по маске мы можем продолжать находить часто повторяемые последовательности групп биграмм в зашифрованном тексте. Эти классические уязвимости всегда присутствуют в полиграммных шифрах и не исчезают при каких-либо частных и более конкретных реализациях.

Ещё одним и наверное самым простым представителем биграммных шифров является шифр Порты. Его можно представить в виде следующей таблицы. Здесь стоит понимать, что сам алфавит может быть перемешан, а потому количество ключей увеличится и будет равно N!, где N - количество символов в алфавите.

Таблица шифра Порты с русским алфавитом

Программная реализация шифра Порты #include ""encoder.h"" #include <stdio.h> #include <stdint.h> #include <stdlib.h> #include <string.h> typedef struct porto_t { encoder_t *encoder; uint8_t neutral_ch; } porto_t; extern porto_t *porto_new(encoder_t *encoder, uint8_t neutral_ch); extern void porto_free(porto_t *porto); extern uint32_t *porto_encrypt(porto_t *porto, uint32_t *output, uint8_t *input, uint32_t *size); extern uint8_t *porto_decrypt(porto_t *porto, uint8_t *output, uint32_t *input, uint32_t size); int main(int argc, char *argv[]) { uint8_t alphabet[] = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ""; uint8_t size_alph = (uint8_t)strlen((char*)alphabet); encoder_t *encoder = encoder_new(size_alph); encoder_set_alphabet(encoder, alphabet); uint8_t message[BUFSIZ]; strcpy((char*)message, ""HELLOWORLD""); uint32_t message_len = strlen((char*)message); uint32_t encrypted[message_len]; porto_t *porto = porto_new(encoder, 'X'); uint32_t size; porto_encrypt(porto, encrypted, message, &size); for (int i = 0; i < size; ++i) { printf(""%d "", encrypted[i]); } printf(""

""); printf(""%s

"", (char*)porto_decrypt(porto, message, encrypted, size)); porto_free(porto); encoder_free(encoder); return 0; } extern porto_t *porto_new(encoder_t *encoder, uint8_t neutral_ch) { porto_t *porto = (porto_t*)malloc(sizeof(porto_t)); porto->encoder = encoder; porto->neutral_ch = neutral_ch; return porto; } extern void porto_free(porto_t *porto) { free(porto); } extern uint32_t *porto_encrypt(porto_t *porto, uint32_t *output, uint8_t *input, uint32_t *size) { size_t input_len = strlen((char*)input); uint8_t first, second; int flag; int j = 0; uint32_t alpha_size = ((uint32_t)encoder_get_size_alphabet(porto->encoder)); for (int i = 0; i < input_len-1; i += 2) { first = encoder_encode(porto->encoder, input[i], &flag); if (flag == 0) { fprintf(stderr, ""failed encode first char '%c'

"", input[i]); return NULL; } second = encoder_encode(porto->encoder, input[i+1], &flag); if (flag == 0) { fprintf(stderr, ""failed encode second char '%c'

"", input[i+1]); return NULL; } output[j++] = ((uint32_t)first)*alpha_size+((uint32_t)second); } if (input_len%2 == 1) { first = encoder_encode(porto->encoder, input[input_len-1], &flag); if (flag == 0) { fprintf(stderr, ""failed encode first char '%c'

"", input[input_len-1]); return NULL; } second = encoder_encode(porto->encoder, porto->neutral_ch, &flag); if (flag == 0) { fprintf(stderr, ""failed encode second char '%c'

"", porto->neutral_ch); return NULL; } output[j++] = ((uint32_t)first)*alpha_size+((uint32_t)second); } *size = j; return output; } extern uint8_t *porto_decrypt(porto_t *porto, uint8_t *output, uint32_t *input, uint32_t size) { uint32_t alpha_size = ((uint32_t)encoder_get_size_alphabet(porto->encoder)); int flag, j = 0; for (int i = 0; i < size; ++i) { output[j++] = encoder_decode(porto->encoder, input[i] / alpha_size, &flag); if (flag == 0) { fprintf(stderr, ""failed first second code '%c'

"", input[i] / alpha_size); return NULL; } output[j++] = encoder_decode(porto->encoder, input[i] % alpha_size, &flag); if (flag == 0) { fprintf(stderr, ""failed second first code '%c'

"", input[i] % alpha_size); return NULL; } } return output; } Библиотека encoder, а также способ компиляции находятся во вложении с кодом шифра Цезаря. Результат исполнения 186 297 386 381 289 HELLOWORLD

Криптостойкость полиграммных шифрова прямо пропорционально зависит от количества шифруемых символов за раз в качестве N-граммы. Чем больше символов будет шифроваться одновременно, тем сложнее осуществлять атаки частотного криптоанализа и атаки по маске. Следовательно, наивысшей криптостойкостью полиграммных шифров становится размер равный L-грамме, где L - количество символов в открытом тексте, при условии, что изменение одного символа L-граммы будет приводить к изменению большинства других символов (лавинный эффект).

6. Простая перестановка

Предполагает собой полноценный и монолитный механизм, алгоритм перемешивания символов открытого текста с целью получения закрытого. По большей части это всё определение, а потому к такому подклассу шифров можно относить большинство известных перестановок, подобия маршрутной, вертикальной, решета Кардано, шифра Скитала (шифр Древней Спарты).

Так представим простую перестановку на примере вертикальной перестановки. У таковой перестановки ключом может быть строка или просто набор чисел. Количество символов (или чисел) ключа порождает размер блока, в который будут записываться блоки сообщения такого же размера. Если длина ключа равна длине сообщения, то происходит обычная математическая перестановка.

Предположим, что у нас существует ключ K=KEY и сообщение M=HELLOWORLD. В таком случае, мы создаём матрицу 3x4, где первое число - это размер ключа (количество символов), а второе число - это количество используемых блоков по 3 для вместимости всего сообщения M. Вписывает в матрицу слева-направо, сверху-вниз сообщение. Если остаются пустые ячейки, то заполняем их либо нейтральным символов (подобия того же X), либо случайными символами.

K E Y H E L L O W O R L D X X

После заполнения всех ячеек, мы сортируем ключ KEY по алфавитному порядку, тем самым получая новый ключ EKY. Вместе с сортировкой символов ключа сортируем и столбцы под ними находящиеся. В итоге получае следующее.

E K Y E H L O L W R O L X D X

Результат шифрования выписываем снизу-вверх, справа-налево. Получаем на выходе следующий шифртекст C=XLWLDOLHXROE. Вышеописанный алгоритм является лишь одним из возможных вариантов. Так например, можно вписывать/выписывать символы снизу-вверх, слева-направо, а можно также слева-направо, сверху-вниз, также можно сортировать ключ в порядке убывания и т.д. Это шифр классической криптографии, стандартизации как таковой на данном этапе ещё не существует.

При этом стоит заметить, что шифры простой перестановки никак не скрывают частоты символов открытого текста, в отличие от подстановочных шифров. Такое свойство играет двоякую роль, потому как с одной стороны применять частотный криптоанализ, в том привычном виде, становится бессмысленным. Частотный криптоанализ хорошо работает на классе подстановочные шифров, но не перестановочных. С другой стороны, сама перестановка всё же сохраняет в открытой форме символы открытого текста и если хорошо знать язык, на котором текст был написан, то нам становится возможно исключать определённые конструкции, которых просто не может существовать в оригинальном тексте. Так например, в русском тексте Ь не может существовать в начале слова, символ Н часто находится в сумме с другим Н, Й часто находится в конце слова, Ы существовует в массе своей с Й, Е или Н и т.д. Языковые конструкции избыточны, а потому могут приводить к дополнительным способам дешифрования, даже сложных перестановок.

Программная реализация шифра вертикальной перестановки #include <stdio.h> #include <stdint.h> #include <stdlib.h> #include <string.h> typedef struct vertical_permutation_t { uint8_t *key; uint8_t *sorted_key; uint32_t key_size; } vertical_permutation_t; extern vertical_permutation_t *vertical_permutation_new(uint8_t *key); extern void vertical_permutation_free(vertical_permutation_t *vertical_permutation); extern uint8_t *vertical_permutation_encrypt(vertical_permutation_t *vertical_permutation, uint8_t *output, uint8_t *input); extern uint8_t *vertical_permutation_decrypt(vertical_permutation_t *vertical_permutation, uint8_t *output, uint8_t *input); static int find_index(uint8_t *arr, uint8_t v, int size); static int comp(const void * elem1, const void * elem2); int main(int argc, char *argv[]) { uint8_t encrypted[BUFSIZ]; uint8_t message[BUFSIZ]; strcpy((char*)message, ""HELLOWORLDXX""); uint8_t key[BUFSIZ]; strcpy((char*)key, ""KEY""); vertical_permutation_t *vertical_permutation = vertical_permutation_new(key); printf(""%s

"", (char*)vertical_permutation_encrypt(vertical_permutation, encrypted, message)); printf(""%s

"", (char*)vertical_permutation_decrypt(vertical_permutation, message, encrypted)); vertical_permutation_free(vertical_permutation); return 0; } extern vertical_permutation_t *vertical_permutation_new(uint8_t *key) { vertical_permutation_t *vertical_permutation = (vertical_permutation_t*)malloc(sizeof(vertical_permutation_t)); vertical_permutation->key_size = strlen((char*)key); vertical_permutation->key = (uint8_t*)malloc(sizeof(uint8_t)*vertical_permutation->key_size+1); vertical_permutation->sorted_key = (uint8_t*)malloc(sizeof(uint8_t)*vertical_permutation->key_size+1); strcpy((char*)vertical_permutation->key, (char*)key); strcpy((char*)vertical_permutation->sorted_key, (char*)key); qsort(vertical_permutation->sorted_key, sizeof(uint8_t)*vertical_permutation->key_size, sizeof(uint8_t), comp); return vertical_permutation; } extern void vertical_permutation_free(vertical_permutation_t *vertical_permutation) { free(vertical_permutation->key); free(vertical_permutation); } extern uint8_t *vertical_permutation_encrypt(vertical_permutation_t *vertical_permutation, uint8_t *output, uint8_t *input) { size_t input_len = strlen((char*)input); int index_key, output_i = 0; if (input_len % vertical_permutation->key_size != 0) { fprintf(stderr, ""input_len %% vertical_permutation->key_size != 0""); return NULL; } for (int i = 0; i < vertical_permutation->key_size; ++i) { index_key = find_index(vertical_permutation->key, vertical_permutation->sorted_key[i], vertical_permutation->key_size); for (int j = index_key; j < input_len; j += vertical_permutation->key_size) { output[output_i++] = input[j]; } } return output; } extern uint8_t *vertical_permutation_decrypt(vertical_permutation_t *vertical_permutation, uint8_t *output, uint8_t *input) { size_t input_len = strlen((char*)input); int index_key, output_i = 0; if (input_len % vertical_permutation->key_size != 0) { fprintf(stderr, ""input_len %% vertical_permutation->key_size != 0""); return NULL; } for (int i = 0; i < input_len; i += vertical_permutation->key_size) { for (int j = index_key; j < input_len; j += vertical_permutation->key_size) { index_key = find_index(vertical_permutation->key, vertical_permutation->sorted_key[j], vertical_permutation->key_size); output[output_i++] = input[j]; } } return output; } static int find_index(uint8_t *arr, uint8_t v, int size) { for (int i = 0; i < size; ++i) { if (arr[i] == v) { return i; } } return -1; } static int comp(const void * elem1, const void * elem2) { uint8_t f = *((uint8_t*)elem1); uint8_t s = *((uint8_t*)elem2); if (f > s) return 1; if (f < s) return -1; return 0; } Результат исполнения EORXHLODLWLX HELLOWORLDXX В данном программном случае, чтение при шифровании происходило сверху-вниз, слева-направо.

Криптостойкость шифров простой перестановки увеличивается удлинением размера ключа, а соответственно и удлинением блоков перестановки. Таким образом, если шифр простой перестановки зависит от ключа, а длина ключа определяется длиной N входного текста, то количество всевозможных ключей будет равно N!. Так, на примере шифра вертикальной перестановки, количество всевозможных ключей при длине ключа равной 3 составляет 3!=6, а при длине ключа равной 4 составляет 4!=24 и т.д. Исходя из всего этого, наивысшая криптостойкость определяется схожим образом с полиграммными шифрами.

7. Сложная перестановка

Является обычным сочетанием, композицией простых перестановок. Это может быть как вертикальная+вертикальная перестановки с разной длиной ключа (желательно, чтобы НОД(a, b) = 1 (НОД = наибольший общий делитель), где a, b - длины блоков первой и второй перестановок), так и для примера маршрутная+решето Кардано. Всевозможных комбинаций в таком подклассе существует бесконечное множество.

При наилучшей композиции сложная перестановка приводит к произведению количества ключей простых перестановок. Так например, если одна простая перестановка имеет длину ключа равную 7, а другая равную 13, то итоговое количество ключей будет равно 7!*13!=31384184832000 всевозможным перестановкам, что в свою очередь представляет сложность ~=241.

P.S. Стоит заметить, что такое свойство композиций существует не у всех шифров. Так например, бессмысленно композировать несколько моноалфавитных шифров, потому как выходом объединения станет обычный моноалфавитный шифр. Также нет смысла комбинировать несколько полиалфавитных шифров с одинаковой длиной ключа, потому как это приведёт ровно также к созданию одного полиалфавитного шифра с такой же длиной ключа. Из этого следует, что сама композиция, комбинирование нескольких шифров должно происходить лишь на основе объединения разных длин ключей.

Тем не менее, полученная длина ключа может быть урезана многократно, если криптоаналитик сможет найти один из делителей сложной перестановки. Иными словами, если он поймёт, что длина одной перестановки равна 7, то длина ключа сложной перестановки упадёт до 13!=6227020800. Таким образом, сложная перестановка продолжает наследовать внутри себя критерий наивысшей криптостойкости простой перестановки, что логично, ведь таковая сложность является лишь комбинацией простоты.

Помимо сложной перестановки, в истории криптографии существовал ещё ряд композиционных шифров, как вид объединения нескольких алгоритмов. Так в качестве примера, таковыми являлись шифр ADFGVX (шифр Полибия+вертикальная перестановка) и шифровальная машина Энигма (парный шифр+полиалфавитный шифр). Тем не менее, их вид композиции в некой степени разный, неоднородный, потому как ADFGVX соединяет одновременно два класса, в то время как Энигма объединяет два подкласса только из одного класса, ровно также как это делает сложная перестановка. В дальнейшем, чтобы понимать о каком конкретно типе объединения идёт речь, введём различие на уровне терминологии, где для сочетания двух классов подстановка+перестановка мы будем использовать термин Композиционный (ADFGVX), а для сочетания двух подклассов одного класса — Комбинированный («Энигма», Сложная перестановка).

Композиционные шифры (в дальнейшем повествовании современных симметричных алгоритмов) играют большую роль чем комбинированные, поэтому на последних мы не будем сильно заострять внимание. Более подробно, в качестве примера комбинированных шифров, вы можете рассмотреть устройство шифровальной машины «Энигма», а также её реализацию на языке программирования Си — тут.

Заключение

Пока что мы рассмотрели лишь классы и подклассы алгоритмов классической криптографии, не затрагивая при этом современную симметричную криптографию. Тем не менее, кто уже знаком с современной криптографией может увидеть достаточно много ""деталей"", которые были унаследованы современными шифрами.

Список литературы"'https://habrastorage.org/getpro/habr/upload_files/e24/267/5fa/e242675fa7d9e33adaa3fc303ab688e9.png'"['https://habrastorage.org/r/w1560/getpro/habr/upload_files/101/a4e/3e8/101a4e3e84031b4cded195aa52728dd4.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/1f2/bf2/79e/1f2bf279ebc701e3952a3045d52fb125.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/3b0/b68/629/3b0b68629634de6fb03c4b0f642fb614.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/e80/025/8ec/e800258ecf56fd1b56a8a5a8a50cadfe.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/860/c69/005/860c69005a6f519f3cd690e6436ae462.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/e3b/913/ffe/e3b913ffe9d04bd91b0be9da4f144d74.png', 'https://habrastorage.org/getpro/habr/avatars/3a7/b29/0f7/3a7b290f7401111b35722db2d1380907.png', 'https://habrastorage.org/getpro/habr/upload_files/e24/267/5fa/e242675fa7d9e33adaa3fc303ab688e9.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/962/61d/205/96261d20569c4151493fc949ba6bcbc6.png', 'https://habrastorage.org/r/w48/getpro/habr/avatars/3a7/b29/0f7/3a7b290f7401111b35722db2d1380907.png']"
16'723390'Код на python, сервер и Cron. Запускаем код на сервере по времени'Введение У меня была задача «Собирать статистику постов в vk каждый час». Я не являюсь разработчиком или DevOps специалистом. Поэтому мой способ решения задачи сложился из поисковых запросов, личного...'https://habr.com/ru/post/723390/'"Введение

У меня была задача «Собирать статистику постов в vk каждый час». Я не являюсь разработчиком или DevOps специалистом. Поэтому мой способ решения задачи сложился из поисковых запросов, личного опыта, советов друзей и коллег.

Решение я разбил на 2 части:

Написать код для сбора. (см. статью https://habr.com/ru/post/720862/) Запустить процедуру на сервере с интервалом 1 час

В этой статье мы рассмотрим реализацию 2-го пункта. Если у вас нет 2 пункта подойдет любой другой код, которые требуется запускать по расписанию.

На схеме это будет выглядеть следующим образом.

Код на python публикуем на сервер через github, устанавливаем docker. В crontab задаем интервал для запуска docker контейнера

Подготавливаем данные для Docker

Про Docker написано очень много статей, поэтому я не буду писать еще раз, что это и для чего используется. В контексте данной статьи Docker будет частью нашего решения. В следующем разделе будет ссылка на материал по теме Docker, который помог мне.

План действий:

Создаем файл requrements.txt Настраиваем Dockerfile Настраиваем переменное окружение в коде python Оставляем словарь, который использует google sheet api*

* noted-point файл с расширением json, который используется в коде на python

requrements.txt

В папке с вашим кодом создаем файл с точно таким же именем requrements.txt Этим файлом мы говорим Docker, какие библиотеки нужно дополнительно установить и какой версии .

Как понять, что туда написать?

Обязательно вносим в файл библиотеки, которые вы устанавливали дополнительно. В моем случае все библиотеки, которые использованы в коде в самом начале.

import os import requests from pandas import json_normalize import pandas as pd from datetime import datetime from datetime import * import httplib2 from oauth2client.service_account import ServiceAccountCredentials import apiclient.discovery

В IDE в консоле пишем pip freeze.

Видим список всех установленных пакетов в вашем виртуальном окружение и их версии

Пример вывода списка библиотек с и их версии

Выбираем библиотеки, которые мы с вами используем в коде и переносим в requrements.txt

На выходе это будет выглядеть так:

Наполнение файла requrements.txt

Dockerfile

заполненная структура докер файла

Создаем файл Dockerfile, без расширения. Открываем его и заносим данные

FROM python: «ваша версия python». Узнать ее можно набрав в терминале: python –V

Подробно останавливаться на всем не буду. Выше собранный requrements.txt будет использован в RUN.

ENV это переменное окружение, которые будут храниться внутри Docker. ENV TZ Europe/Moscow – установление московского времени.

Все остальные переменные необходимы для корректной работы кода. (см. статью https://habr.com/ru/post/720862/)

Конечно можно их и не прописывать и все оставить в коде. В моем случае, я решил, что оставлю все переменные в одном месте просто для своего удобства.

CMD указываем язык программирования и названия вашего файла с кодом в моем случае это vk_stat.py

Настраиваем переменное окружение в коде python

Мы удаляем значение переменных из кода, так как они у нас уже в Dockerfile.

Прописываем команду, которая будет забирать переменные окружения.

TOKEN_USER = os.getenv('TOKEN_USER') VERSION = os.getenv('VERSION') DOMAIN = os.getenv('DOMAIN')

Создаем сервер, публикуем код на GitHub

Я бы посоветовал прежде, чем перейти к этому шагу скачать отдельно docker desktop и провести тестирование на вашей локальной машине.

В этом видео вы найдете все что нужно по установки docker и кратко для чего он применяется. Мне данное видео очень помогло. https://www.youtube.com/watch?v=QF4ZF857m44

Для тех кто c Docker знаком предлагаю просмотреть фрагмент видео (ссылка выше) с 1:05:23 по 1:10:17

Добавлю лишь, если вы не хотите прописывать переменные внутри сервера, то сделайте закрытый репозиторий на GitHub!

Здесь не вижу смысла перечислять все шаги, если вы повторите за автором видео.

90% работы вами уже сделано. По итогам у вас:

- Создан сервер с опубликованном кодом через github + установленный docker

Отладка Cron

Далее через командную строку заходим на наш сервер.

Мне понравилась статья про cron здесь https://losst.pro/nastrojka-cron, но далее кратко напишу по сути. Набираем «crontab –e» в командной строке.

В самом конце набираем интервал для запуска контейнер. В моем случае каждый час. В помощь хороший сайт, который позволит сразу настроить интервал https://crontab.guru

Далее пишем команду Docker run –rm «имя вашего образа». Флажок –rm удаляет контейнер после его отработки. Не забываем сохранить наши изменения.

Cron перед сохранением. test - имя моего образа

Проверить, не падает ли контейнер при запуске можно в логах. Введите команду grep CRON /var/log/syslog

Заключение

Данное решение позволяет выполнить поставленную задачу. Конечно его можно улучшить. Например, добавить логирование, написать класс и завернуть все в функции что позволит в будущем расширять функционал. Возможно радикально пересмотреть в целом предлагаемое мной решение.

Сервер обходиться в 200 рублей за месяц аренды. Работать код будет 4-6 месяцев. Если у кого-то есть решение, как можно сделать тоже самое без использования сервера, будет интересно почитать.

Код на GitHub"'https://habrastorage.org/getpro/habr/upload_files/684/bb2/e91/684bb2e91d7e30be7713fe3268c8b488.jpg'"['https://habrastorage.org/r/w780q1/getpro/habr/upload_files/394/3ac/900/3943ac900df16ee0c87e4ae35918aebe.jpg', 'https://habrastorage.org/getpro/habr/upload_files/684/bb2/e91/684bb2e91d7e30be7713fe3268c8b488.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/983/ff2/bc5/983ff2bc513a2c9bcadef8d7fb2ceb2f.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/836/b81/8ed/836b818edfb3d2747a2dac83fa1e497f.jpg', 'https://habrastorage.org/getpro/habr/upload_files/a96/42f/7a3/a9642f7a3e9c64ace8b266d36d589c40.JPG', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/8e1/8f4/d80/8e18f4d80c705db4ef75aef83bcda821.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/2be/897/5fd/2be8975fdc8e1c9ee2b936025ca6cadb.png']"
17'723386'Примеры анимаций, зависящих от прокрутки содержимого UIScrollView'Это вторая часть статьи про анимации, зависящие от скролла. В предыдущей статье я подробно описал, как создаются такие анимации, и в качестве примера продемонстрировал слайдер с процентом завершения...'https://habr.com/ru/post/723386/'"Это вторая часть статьи про анимации, зависящие от скролла. В предыдущей статье я подробно описал, как создаются такие анимации, и в качестве примера продемонстрировал слайдер с процентом завершения анимации. С полученным процентом можно сделать что угодно - наша фантазия безгранична, но в этой статье я ограничусь тремя примерами, которые могут вдохновить вас при написании кода:

Фейд

Изменение координат

Изменение размера

TLDR: Проект с примерами

Flashback

Возможно, вы не читали предыдущую статью и не хотели бы тратить время на её прочтение. Однако, обязательно прочтите данный абзац, так как здесь будет краткое изложение ключевых моментов предыдущей статьи.

Для начала, чтобы продемонстрировать примеры, нужно вспомнить, как выглядел код для получения процента завершения анимации. Это самая важная часть, и мне хотелось бы её напомнить. Весь код для анимации находится в делегатном методе UIScrollView - scrollViewDidScroll:

func scrollViewDidScroll(_ scrollView: UIScrollView) { let currentContentOffsetY = scrollView.contentOffset.y let scrollDiff = currentContentOffsetY - previousContentOffsetY // Верхняя граница начала bounce эффекта let bounceBorderContentOffsetY = -scrollView.contentInset.top let contentMovesUp = scrollDiff > 0 && currentContentOffsetY > bounceBorderContentOffsetY let contentMovesDown = scrollDiff < 0 && currentContentOffsetY < bounceBorderContentOffsetY let currentConstraintConstant = animatedConstraint!.constant var newConstraintConstant = currentConstraintConstant if contentMovesUp { // Уменьшаем константу констрэйнта newConstraintConstant = max(currentConstraintConstant - scrollDiff, minConstraintConstant) } else if contentMovesDown { // Увеличиваем константу констрэйнта newConstraintConstant = min(currentConstraintConstant - scrollDiff, maxConstraintConstant) } // Меняем высоту и запрещаем скролл, только в случае изменения константы if newConstraintConstant != currentConstraintConstant { animatedConstraint?.constant = newConstraintConstant scrollView.contentOffset.y = previousContentOffsetY } // Процент завершения анимации let animationCompletionPercent = (maxConstraintConstant - currentConstraintConstant) / (maxConstraintConstant - minConstraintConstant) progressView.progress = Float(animationCompletionPercent) previousContentOffsetY = scrollView.contentOffset.y }

Расчёт процента находится в самом конце, он то нам и нужен:

// Процент завершения анимации let animationCompletionPercent = (maxConstraintConstant - currentConstraintConstant) / (maxConstraintConstant - minConstraintConstant)

Фейд UIView

Здесь всё просто: альфа UIView - это процент завершения анимации:

// Процент завершения анимации let animationCompletionPercent = (maxConstraintConstant - currentConstraintConstant) / (maxConstraintConstant - minConstraintConstant) fadeView.alpha = animationCompletionPercent

Изменение координат UIView

Данный пример демонстрирует использование аффинных преобразований, которые позволяют реализовывать самые сложные анимации. Двухмерные аффинные преобразования осуществляются путем умножения вектора на матрицу 3x3, что можно представить в виде системы уравнений, решением которой станут новые координаты для каждой точки. Если вкратце, то с помощью аффинных преобразований UIView можно двигать, вращать и масштабировать как угодно. В этом примере я также воспользуюсь UIViewPropertyAnimator для анимирования UIView.

class CoordinatesChangeView: UIView { var animationCompletionPercentage: Double = 0 { didSet { animator.fractionComplete = animationCompletionPercentage } } private let side: CGFloat = 60 private lazy var animator = UIViewPropertyAnimator(duration: 0.1, curve: .easeIn) { [weak self] in guard let self else { return } self.imageView.transform = CGAffineTransform(translationX: self.side - self.bounds.width, y: 0) } }

Так настраивается анимация внутри CoordinatesChangeView. В самом UIViewController всё так же, как и в прошлом примере:

// Процент завершения анимации let animationCompletionPercent = (maxConstraintConstant - currentConstraintConstant) / (maxConstraintConstant - minConstraintConstant) coordinateChangeView.animationCompletionPercentage = animationCompletionPercent

Изменение размера UIView

В этом примере так же можно было использовать аффинные преобразования и анимировать изменения через UIViewPropertyAnimator, но я решил немного разнообразить пример и пользоваться не процентом, а самим констрейнтом:

private let minConstraintConstant: CGFloat = 50 private let maxConstraintConstant: CGFloat = 200 private var animatedConstraint: NSLayoutConstraint? private var avatarHeightConstraint: NSLayoutConstraint? private func setupAvatarView() { view.addSubview(avatarImageView) avatarHeightConstraint = avatarImageView.heightAnchor.constraint(equalToConstant: maxConstraintConstant) NSLayoutConstraint.activate([ avatarHeightConstraint!, avatarImageView.topAnchor.constraint(equalTo: view.safeAreaLayoutGuide.topAnchor), avatarImageView.heightAnchor.constraint(equalTo: avatarImageView.widthAnchor, multiplier: 1.0), avatarImageView.centerXAnchor.constraint(equalTo: view.centerXAnchor), ]) }

В коде выше я сохраняю ещё одну константу и буду изменять её в методе scrollViewDidScroll:

// Меняем высоту и запрещаем скролл, только в случае изменения константы if newConstraintConstant != currentConstraintConstant { animatedConstraint?.constant = newConstraintConstant scrollView.contentOffset.y = previousContentOffsetY } // Меняем высоту аватара, только в случае изменения константы if newConstraintConstant != avatarHeightConstraint!.constant { avatarHeightConstraint?.constant = currentConstraintConstant }

Изменяю высоту так же, как и с коснтрейнтом таблицы - только в случае изменения значения. Мне не нужно вычислять процент, так как я меняю константу напрямую.

Заключение

Данная статья получилась небольшой, но, надеюсь, от этого не менее полезной. Я постарался реализовать все примеры разными способами, чтобы у вас было больше пищи для размышлений. Я надеюсь, что вы найдете здесь множество идей, которые помогут вам при написании кода. Кроме того, я бы хотел подчеркнуть, что важно не только владеть разными способами, но и уметь выбрать тот, который подходит именно для вашей задачи."'https://habrastorage.org/getpro/habr/upload_files/ed3/b73/526/ed3b73526f8b7f99607219266eae9318.jpg'"['https://habrastorage.org/r/w48/getpro/habr/avatars/7d8/902/984/7d89029848fe6c38c3b903a71c7d1219.jpg', 'https://habrastorage.org/getpro/habr/upload_files/a1c/cc2/2cf/a1ccc22cfc1fdf82057a3ddbac2b2d1d.gif', 'https://habrastorage.org/getpro/habr/avatars/7d8/902/984/7d89029848fe6c38c3b903a71c7d1219.jpg', 'https://habrastorage.org/getpro/habr/upload_files/0f3/534/6b7/0f35346b7ee689ba18de6209c5c0d3d9.gif', 'https://habrastorage.org/getpro/habr/upload_files/ed3/b73/526/ed3b73526f8b7f99607219266eae9318.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/upload_files/aae/b3f/c92/aaeb3fc92e98b32d72fce9f02880ea68.gif', 'https://habrastorage.org/getpro/habr/upload_files/d04/d61/41c/d04d6141cb5f502848c6102fb9568a4d.gif']"
18'723384'Дайджест  ̶л̶е̶н̶т̶я̶я̶ уставшего человека: как отдыхать без угрызений совести'Как проходят выходные? Встречаете весну на улице, чистите тающий снег у дома или гаража, гуляете с детьми, тягаете железо в зале, засели в любимой игре или работаете работу вне работы, потому что...'https://habr.com/ru/post/723384/'"Как проходят выходные? Встречаете весну на улице, чистите тающий снег у дома или гаража, гуляете с детьми, тягаете железо в зале, засели в любимой игре или работаете работу вне работы, потому что привыкли работать? Каждый из нас волен проводить свободное время так, как считает нужным. Но не факт, что нужное окажется правильным и полезным, позволяющим перезагрузить организм, дать ему отдых — физический, интеллектуальный, эмоциональный. Впрочем, нельзя сказать, что какой-то паттерн отдыха однозначно универсальный и правильный для всех: виды отдыха и их эффективность зависят от возраста, телосложения, рода занятий, привычек, склада личности, региона проживания и массы других факторов. Что не отменяет общих рекомендаций, на которые стоит обратить внимание, чтобы находиться в ладах со своим организмом.

Принципы, которые помогут отдыхать

Отдых — это не привилегия выходного дня или праздников, он должен быть и полноценным (длительным), и периодическим непродолжительным (в том числе в рабочие часы). Ни один человек не способен без вреда для соматического здоровья и психики работать 8 часов в сутки, адекватный непрерывный максимум — 3-4 часа. Поэтому важно планировать отдых так же, как вы планируете работу: интервалы, способы, занятия во время отдыха, партнёры по отдыху или одиночество и т.д.

Работа, даже самая любимая, — не отдых. С распространением удалёнки в 2020 году всё больше сотрудников компаний работают фактически постоянно: кто-то по инерции, кто-то от трудоголизма, кто-то «от нечего делать», а большинство — из-за нерационального перемешивания домашних дел и работы (в итоге страдают оба аспекта). Иногда кажется, что любимая работа — вроде бы неплохой отдых: ты просто продолжаешь заниматься тем, что нравится. Это неприятная ловушка, которая приведёт к выгоранию: отсутствие переключения деятельности и однообразное занятие рано или поздно утомят каждого. От работы нужно обязательно отдыхать — так вы сможете вернуться к ней со свежими идеями, силами и даже с новым взглядом на задачи и процессы.

Отдых должен быть антагонистом работы. Это не строгое правило, кому-то наоборот нравится отдыхать и работать в одном ритме и с одной нагрузкой, но с точки зрения физиологии рациональнее сочетать разную нагрузку и темп. Если у вас сидячая работа, лучше пройтись по парку, заняться спортивными играми или танцами, поработать на даче; наоборот, если волка ноги кормят (например, вы сотрудник выездной инженерной службы) и эти самые ноги гудят, лучше вытянуться и послушать, посмотреть или почитать что-то приятное и интересное. Таким образом вы сделаете самое главное — дадите полноценный отдых или полноценную нагрузку вашему телу, состояние которого определяет и настроение, и эмоции, и трудоспособность.

Не забывайте о природе. Часто мы идём по городу, не замечая мира вокруг нас: прилетели птицы, ручьи в парке образовали озёра, в которых красиво отражаются берёзы, приятно скрипит снег или перекатывается под ногами галька, шумит море или несёт ледоход река. наблюдение за природой помогает сосредоточиться на своих мыслях, отдохнуть и получить приятные эмоции (особенно здорово «работает» зелёный цвет). Если вы не можете выключиться из мира для созерцания, выбирайте активный контакт с природой: походы, сплавы, прогулки с фотоаппаратом или даже особенные увлечения вроде бёрдвотчинга (наблюдения за птицами).

Отдых должен проходить в нескольких направлениях :

физическом — прежде всего должно отдыхать тело, успешно сочетая для себя нагрузку и состояние покоя; важно, чтобы было время не только на обычный отдых, но и на отдых в случае ран, болезней, падений и т.д. — не стоит сидеть за работой с высокой температурой или лёгким сотрясением мозга, это сократит продуктивность и нанесёт в прямом смысле непоправимый вред; эмоциональном — отпустите на время отдыха страхи и переживания, не думайте о людях, которые вас напрягают или раздражают, позвольте себе роскошь одиночества (кстати, для эмоционального отдыха отлично подходит погружение в хорошую художественную литературу); интеллектуальном — нужно найти в себе силы «затормозить» и перестать думать о работе, задачах, пет-проекте, перестать заниматься думскроллингом; если удастся, вы получите приятнейшую побочку — могут начаться инсайты по тем задачам, вопросам и ситуациям, которые, казалось, уже безнадёжны или безмерно сложны.

Определите, что вас заряжает, вдохновляет и расслабляет. На пересечении лежит идеальный отдых. Только не забудьте о важном условии: ваш отдых не должен ущемлять время и отдых других людей (увы, или даже к счастью, даже родные и близкие должны отдыхать в том числе друг от друга).

Соберите набор рутин для отдыха — они будут посылать мозгу однозначный сигнал «пора отдыхать». Например, начинайте отдых с любимой музыки, танца, уборки, прогулки по определённому маршруту, посещения привычного кафе и т.д. Так у вас сформируются небольшие ритуалы, позволяющие быстро перестроить из режима работы в режим покоя, отдыха или смены деятельности (опять же, кому что подходит).

Не вините себя за отдых: это не зря потраченное время, а правильная инвестиция в себя. Если вы будете испытывать чувство вины, полноценного отдыха не получится, более того, вы устанете ещё больше, потому что станете нагонять всё то, что, как вам кажется, вы упустили «в празднестве и неделании».

Не бойтесь отдыхать. Особая история для трудных ситуаций: когда человек попадает в сложный жизненный период и оказывается перегруженным до предела, он боится отдохнуть, потому что знает, что за отдыхом последует возвращение в ад (например, сочетание работы с болезнью близких или неприятностями в личной жизни). Кажется, что стоит пробежать весь марафон неприятностей, и уж потом-то точно оторваться на полную. Да, правда, после периода отдыха (а иногда и просто сна) в трудный период жизни возвращаться к неприятной рутине буквально невыносимо. Но в критических ситуациях, особенно если они затягиваются надолго, отдыхать нужно обязательно, иначе вы начнёте разрушаться как личность и деградировать, отдавая себя труду, борьбе с неприятностями и переживаниям. Несмотря на то что выход из отдыха в такие моменты более чем отвратителен, сам отдых даёт заряд сил и главное, щадит перегруженный организм. Если позволять себе выбирать время отдыха, можно действительно дотянуть до конца «чёрной полосы», если нет — за ней придёт другая, связанная с надорванным здоровьем.

Что почитать об отдыхе на Хабре

О сне — важнейшем элементе отдыха

Немного расслабляющих материалов для домоседов

Arzamas — большой проект, где можно найти материалы на исторические, культурные и научные темы. Журнал, курсы лекций, радио, материалы для детей - есть информация почти для любого возраста и интереса. Ничего не стоит прийти на сайт Arzamas и остаться с ним навсегда. Для нашего времени — потрясающе качественное, продуманное, грамотное и отлично выстроенное интернет-издание.

Постнаука — огромный портал с контентом любого типа и на самые широкие научно-популярные темы. Материалы удобно сгруппированы по 15 тематикам, вы можете читать всё или выбрать то, что интересно именно вам. Статей и медиаматериалов на сайте очень много, видео зачастую приведены с расшифровками — знак особого уважения к читателям.

Наука и Жизнь — сайт ещё одного очень известного журнала. С точки зрения контента и механизмов сайт журнала значительно беднее предыдущих, нет каких-то интересных механик. Но это классический научно-популярный журнал с выверенными статьями, информации в которых можно доверять.

Медиатека | Лекториум — огромное количество лекций по многим темам. Можно просто слушать, а можно конспектировать — для кого-то это может оказаться средством, неожиданно не худшим, чем медитация или просмотр классного сериала.

Будущее сейчас — немного наивный, немного забавный, но довольно мудрый и умный сайт с прогнозами на будущее, теориями, экспертными оценками и т. д. Смесь библиотеки мечтателя, научной фантастики и объективной прогнозной аналитики. Местами захватывает!

Универсариум — масса вузовских лекций в отличном качестве, которые можно прослушать хотя бы для общей эрудиции. Как и на остальных площадках, достаточно много бесплатного контента., кое-где можно получить сертификат.

Виртуальный Эрмитаж и Моя Третьяковка — два невероятных проекта, позволяющих не спеша прогуляться по экспозициям, подробно почитать об экспонатах, приблизить и рассмотреть самые мелочи. Конечно, несравнимо с реальной прогулкой, но может быть хорошим способом спланировать будущее посещение того же Эрмитажа (который невозможно обойти за день, за неделю и уж тем более за двухчасовой тур с гидом).

Отдыхать — это нормально. Увы, нас, детей 70-80-90-х, не научили отдыхать. Сколько раз мы за жизнь слышали: «смена занятий — лучший отдых», «это ты где так устаёшь, за компом что ли?» и неизменно бодрящее «на том свете отдохнём»! Отдых у многих людей по-прежнему ассоциируется с ленью, разгильдяйством, потерей времени. Между тем организм всё равно возьмёт своё: не хочешь добровольно, я тебя загоню на стоянку болезнью, переутомлением, депрессией, выгоранием — будешь отдыхать не с удовольствием, а с температурой, апатией и врачами. Здоровый, хороший, эффективный отдых — это выбор адекватного взрослого человека, который смог полюбить и понять себя. Это признак уважения к себе и своему здоровью, гарантия нормального трудоспособного состояния и психического равновесия. При этом отдых доступен абсолютно всем. Главное, захотеть его получить, и здесь единственная помеха — мы сами."'https://habrastorage.org/getpro/habr/upload_files/0ee/8e0/318/0ee8e0318fa94841e02b18751c97e8c4.png'"['https://habrastorage.org/getpro/habr/avatars/387/c30/35e/387c3035e3a22a0b918b4cb0616b34e3.jpg', 'https://habrastorage.org/r/w48/getpro/habr/avatars/387/c30/35e/387c3035e3a22a0b918b4cb0616b34e3.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ee/8e0/318/0ee8e0318fa94841e02b18751c97e8c4.png', 'https://habrastorage.org/getpro/habr/upload_files/0ee/8e0/318/0ee8e0318fa94841e02b18751c97e8c4.png', 'https://mc.yandex.ru/watch/24049213']"
19'723318'Худшие курсы по программированию 2023 | Голосование'Обучение онлайн стало одним из главных источников знаний для многих будущих специалистов, и существует множество курсов по программированию, которые предлагают обучение с нуля. Однако, к сожалению,...'https://habr.com/ru/post/723318/'"Обучение онлайн стало одним из главных источников знаний для многих будущих специалистов, и существует множество курсов по программированию, которые предлагают обучение с нуля. Однако, к сожалению, не все из них могут похвастаться высоким качеством обучения. В этой статье мы хотим провести голосование среди читателей, чтобы определить самые худшие курсы по программированию 2023 года.

Правила голосования за худшие курсы по программированию:

Вы можете проголосовать только за одни курсы программирования, которые по вашему мнению являются худшим из всех, с которыми вы сталкивались. Укажите причины в комментариях, почему вы считаете этот курс худшим, чтобы другие читатели могли принять во внимание ваши аргументы. Через неделю мы подведем итоги и обновим статью с обзором самых худших курсов по программированию 2023 года по версии пользователей Habr.com. (Для большей объективности будут взяты данные сервиса Similarweb для определения трафика по каждому курсу и в конце голосования будет посчитан топ 10 худших, пропорционально в зависимости от доли трафика каждого отдельного курса и % голосов, который он получил.)

Примеры возможных причин для выбора худшего курса по программированию:

Низкое качество материалов: Возможно, материалы курса устарели, неинформативны или слишком сложны для понимания. Плохая организация курса: Может быть, курс неструктурирован, информация представлена хаотично, и студентам трудно понять, с чего начать. Некомпетентные преподаватели: Возможно, преподаватели курса не имеют достаточных знаний или опыта для преподавания данной темы. Отсутствие практической составляющей: Если курс не предлагает возможности практического применения полученных знаний, студенты могут столкнуться с трудностями в реальной работе. Недостаток поддержки: Возможно, курс не предоставляет достаточной поддержки студентам, что затрудняет процесс обучения и решение возникающих вопросов. Отсутствие обратной связи: Если преподаватели не дают обратной связи или не уделяют внимания прогрессу студентов, это может повлиять на успешность обучения и мотивацию студентов. Высокая стоимость: Возможно, курс имеет необоснованно высокую стоимость, что не соответствует качеству предоставляемых материалов и услуг.Фальшивые отзывы и завышенные ожидания: Некоторые курсы программирования могут быть надумано хорошими из-за фальшивых отзывов и обещаний, которые они не могут выполнить.

Некачественные курсы по программированию. Как их избежать?

Проверка репутации курса:

Чтение отзывов: Ищите независимые и объективные отзывы о курсе по программированию на различных площадках, таких как форумы, блоги и социальные сети. Помимо количества положительных и отрицательных отзывов, обратите внимание на обоснованные аргументы в пользу или против курса. Рекомендации от знакомых: Спросите у друзей, коллег или знакомых, которые уже прошли курс программирования, о их мнении. Личный опыт может быть более надежным источником информации. Проверка аккредитации и партнерств: Наличие аккредитации от профессиональных организаций или партнерств с известными компаниями может свидетельствовать о качестве курса по программированию.

Оценка качества материалов и преподавания:

Доступ к пробным материалам: Проверьте, предоставляет ли курс по программированию бесплатный доступ к части материалов или в ведению. Это позволит вам оценить стиль преподавания, качество материалов и определить, подходит ли курс вашим потребностям и ожиданиям. Обновление материалов: Убедитесь, что курс обновляется регулярно, чтобы отражать последние изменения и тренды в области программирования. Это гарантирует актуальность получаемых знаний. Четкая структура и план обучения: Хороший курс должен иметь четкую структуру и план обучения, который облегчает процесс изучения материала и способствует усвоению знаний. Поддержка и обратная связь: Выбирайте курсы программирования, которые предлагают поддержку и обратную связь от преподавателей или наставников. Это поможет вам лучше усвоить материал и успешно преодолеть возникающие трудности.

Учет стоимости и гибкости обучения:

Соотношение цены и качества: Оцените, насколько цена курса соответствует его качеству, актуальности материалов и предоставляемой поддержки. Иногда дешевые курсы программирования могут оказаться некачественными, а дорогие – не соответствовать своей стоимости. Гибкость и доступность: Выбирайте курсы, которые предлагают гибкий график обучения и возможность проходить материал в удобное для вас время. Это особенно важно для занятых людей или тех, кто совмещает обучение программированию с работой. Возврат средств: Рассмотрите курсы программирования с гарантией возврата средств в течение определенного периода времени, если вы не удовлетворены качеством обучения. Это снижает риск потери средств на некачественный курс.

Теперь, когда вы знакомы с правилами голосования и примерами причин для номинации курсов, мы приглашаем вас поделиться своими мнениями и голосовать за самые худшие онлайн курсы по программированию 2023 года. Ваше мнение важно для нас, и оно поможет другим читателям избежать потери времени и средств на некачественное обучение.

В заключение:

Важно помнить, что этот список создается с целью предоставить читателям информацию о курсах, которые имеют наименьшую ценность для студентов и могут вызвать разочарование. Целью данного голосования является помощь другим читателям сделать осознанный выбор и не тратить свое время и средства на некачественное обучение. Надеемся, что результаты голосования помогут улучшить стандарты онлайн-курсов и подтолкнуть провайдеров к улучшению своих образовательных продуктов.

После завершения голосования мы подведем итоги и опубликуем список худших онлайн курсов по программированию 2023 года, основанный на вашем мнении и голосах. Мы также постараемся связаться с организаторами некачественных курсов и предложить им обратную связь для улучшения своих образовательных продуктов.

Не забывайте делиться своими мнениями и опытом с другими читателями в комментариях. Если вы не нашли курсов, за которые хотите проголосовать, дайте знать в комментариях и они будут добавлены. Ваши знания и опыт могут быть бесценными для других пользователей, сталкивающихся с аналогичными проблемами или ищущих качественные курсы программирования.

Вместе мы можем сделать образовательную среду более качественной.

Голосование за лучшие школы программирования 2023."'https://habrastorage.org/getpro/habr/upload_files/834/d30/cb2/834d30cb29c5faedb6e92a547a0d7b77.png'"['https://habrastorage.org/r/w48/getpro/habr/avatars/bc9/8de/cb7/bc98decb72f30f1427285b3e79053461.png', 'https://habrastorage.org/getpro/habr/upload_files/834/d30/cb2/834d30cb29c5faedb6e92a547a0d7b77.png', 'https://habrastorage.org/getpro/habr/avatars/bc9/8de/cb7/bc98decb72f30f1427285b3e79053461.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/2a4/efb/a3b/2a4efba3bdad90aa44ee7d323001ee29.jpeg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/3f2/934/580/3f2934580c53111690ab893fd7870686.jpeg']"
